/*! For license information please see vender~73eef8dc.7859555b.js.LICENSE.txt */
"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[7695],{70230:(e,n,t)=>{t.d(n,{Z:()=>L});var o=t(23114),a=t(93517),i=t(37337),r=t(54485),s=t(41780),l=t(20442),c=t(22874),d=t(71118),m=t(74366),p=t(1577),f=t(59434),u=t(38268),h=t(94413),v=t(61007),_=t(32463),g=t(13558),x=t(52193),C=t(87539),y=t(98196),T=t(18061),z=t(3582),E=t(90852);function b(){this.command=void 0,this.near=void 0,this.far=void 0}function A(e,n,t){const a=e.context;let i,r;a.depthTexture&&(i=new v.Z),e._useOIT&&a.depthTexture&&(r=new g.Z(a));const s=new f.Z(a);s.viewport=o.Z.clone(t),this.camera=n,this._cameraClone=u.Z.clone(n),this._cameraStartFired=!1,this._cameraMovedTime=void 0,this.viewport=t,this.passState=s,this.pickFramebuffer=new C.Z(a),this.pickDepthFramebuffer=new x.Z,this.sceneFramebuffer=new y.Z,this.globeDepth=i,this.globeTranslucencyFramebuffer=new _.Z,this.oit=r,this.translucentTileClassification=new E.Z(a),this.pickDepths=[],this.frustumCommandsList=[],this.debugFrustumStatistics=void 0,this._commandExtents=[]}const S=new a.Z,D=new a.Z;function w(e,n,t){const o=1/Math.max(1,function(e,n){const t=Math.max(Math.abs(e.x),Math.abs(n.x)),o=Math.max(Math.abs(e.y),Math.abs(n.y)),a=Math.max(Math.abs(e.z),Math.abs(n.z));return Math.max(Math.max(t,o),a)}(e.position,n.position));return a.Z.multiplyByScalar(e.position,o,S),a.Z.multiplyByScalar(n.position,o,D),a.Z.equalsEpsilon(S,D,t)&&a.Z.equalsEpsilon(e.direction,n.direction,t)&&a.Z.equalsEpsilon(e.up,n.up,t)&&a.Z.equalsEpsilon(e.right,n.right,t)&&d.Z.equalsEpsilon(e.transform,n.transform,t)&&e.frustum.equalsEpsilon(n.frustum,t)}function P(e,n,t,o,a){n.debugShowFrustums&&(t.debugOverlappingFrustums=0);const i=e.frustumCommandsList,s=i.length;for(let e=0;e<s;++e){const r=i[e],s=r.near;if(o>r.far)continue;if(a<s)break;const l=t.pass,c=r.indices[l]++;if(r.commands[l][c]=t,n.debugShowFrustums&&(t.debugOverlappingFrustums|=1<<e),t.executeInClosestFrustum)break}if(n.debugShowFrustums){const n=e.debugFrustumStatistics.commandsInFrustums;n[t.debugOverlappingFrustums]=(0,r.Z)(n[t.debugOverlappingFrustums])?n[t.debugOverlappingFrustums]+1:1,++e.debugFrustumStatistics.totalCommands}n.updateDerivedCommands(t)}A.prototype.checkForCameraUpdates=function(e){const n=this.camera,t=this._cameraClone;return w(n,t,c.Z.EPSILON15)?(this._cameraStartFired&&(0,s.Z)()-this._cameraMovedTime>e.cameraEventWaitTime&&(n.moveEnd.raiseEvent(),this._cameraStartFired=!1),!1):(this._cameraStartFired||(n.moveStart.raiseEvent(),this._cameraStartFired=!0),this._cameraMovedTime=(0,s.Z)(),u.Z.clone(n,t),!0)};const I=new i.Z,F=new l.Z;A.prototype.createPotentiallyVisibleSet=function(e){const n=e.frameState,t=n.camera,o=t.directionWC,a=t.positionWC,i=e._computeCommandList,s=e._overlayCommandList,l=n.commandList;e.debugShowFrustums&&(this.debugFrustumStatistics={totalCommands:0,commandsInFrustums:{}});const d=this.frustumCommandsList,f=d.length,u=p.Z.NUMBER_OF_PASSES;for(let e=0;e<f;++e)for(let n=0;n<u;++n)d[e].indices[n]=0;i.length=0,s.length=0;const v=this._commandExtents,_=v.length;let g=0,x=+Number.MAX_VALUE,C=-Number.MAX_VALUE;const y=n.shadowState.shadowsEnabled;let E=+Number.MAX_VALUE,A=-Number.MAX_VALUE,S=Number.MAX_VALUE;const D=n.mode===T.Z.SCENE3D?n.occluder:void 0;let w=n.cullingVolume;const L=I.planes;for(let e=0;e<5;++e)L[e]=w.planes[e];w=I;const N=l.length;for(let n=0;n<N;++n){const c=l[n],d=c.pass;if(d===p.Z.COMPUTE)i.push(c);else if(d===p.Z.OVERLAY)s.push(c);else{let n,i;const s=c.boundingVolume;if((0,r.Z)(s)){if(!e.isVisible(c,w,D))continue;const t=s.computePlaneDistances(a,o,F);if(n=t.start,i=t.stop,x=Math.min(x,n),C=Math.max(C,i),y&&c.receiveShadows&&n<z.Z.MAXIMUM_DISTANCE&&!(d===p.Z.GLOBE&&n<-100&&i>100)){const e=i-n;d!==p.Z.GLOBE&&n<100&&(S=Math.min(S,e)),E=Math.min(E,n),A=Math.max(A,i)}}else c instanceof m.Z?(n=t.frustum.near,i=t.frustum.far):(n=t.frustum.near,i=t.frustum.far,x=Math.min(x,n),C=Math.max(C,i));let l=v[g];(0,r.Z)(l)||(l=v[g]=new b),l.command=c,l.near=n,l.far=i,g++}}let R,O;for(y&&(E=Math.min(Math.max(E,t.frustum.near),t.frustum.far),A=Math.max(Math.min(A,t.frustum.far),E)),y&&(n.shadowState.nearPlane=E,n.shadowState.farPlane=A,n.shadowState.closestObjectSize=S),function(e,n,t,o){const a=n.frameState,i=a.camera,s=a.useLogDepth?n.logarithmicDepthFarToNearRatio:n.farToNearRatio,l=n.mode===T.Z.SCENE2D,d=n.nearToFarDistance2D;let m;o*=1+c.Z.EPSILON2,t=Math.min(Math.max(t,i.frustum.near),i.frustum.far),o=Math.max(Math.min(o,i.frustum.far),t),l?(o=Math.min(o,i.position.z+n.nearToFarDistance2D),t=Math.min(t,o),m=Math.ceil(Math.max(1,o-t)/n.nearToFarDistance2D)):m=Math.ceil(Math.log(o/t)/Math.log(s));const p=e.frustumCommandsList;p.length=m;for(let e=0;e<m;++e){let n,a;l?(n=Math.min(o-d,t+e*d),a=Math.min(o,n+d)):(n=Math.max(t,Math.pow(s,e)*t),a=Math.min(o,s*n));let i=p[e];(0,r.Z)(i)?(i.near=n,i.far=a):i=p[e]=new h.Z(n,a)}}(this,e,x,C),R=0;R<g;R++)O=v[R],P(this,e,O.command,O.near,O.far);if(g<_)for(R=g;R<_&&(O=v[R],(0,r.Z)(O.command));R++)O.command=void 0;const M=d.length,Z=n.frustumSplits;Z.length=M+1;for(let e=0;e<M;++e)Z[e]=d[e].near,e===M-1&&(Z[e+1]=d[e].far)},A.prototype.destroy=function(){let e;this.pickFramebuffer=this.pickFramebuffer&&this.pickFramebuffer.destroy(),this.pickDepthFramebuffer=this.pickDepthFramebuffer&&this.pickDepthFramebuffer.destroy(),this.sceneFramebuffer=this.sceneFramebuffer&&this.sceneFramebuffer.destroy(),this.globeDepth=this.globeDepth&&this.globeDepth.destroy(),this.oit=this.oit&&this.oit.destroy(),this.translucentTileClassification=this.translucentTileClassification&&this.translucentTileClassification.destroy(),this.globeTranslucencyFramebuffer=this.globeTranslucencyFramebuffer&&this.globeTranslucencyFramebuffer.destroy();const n=this.pickDepths,t=n.length;for(e=0;e<t;++e)n[e].destroy()};const L=A},92896:(e,n,t)=>{t.d(n,{Z:()=>h});var o=t(23114),a=t(6785),i=t(54485),r=t(90332),s=t(20176),l=t(1577),c=t(74064),d=t(7048),m=t(53247),p=t(995),f=t(7063);function u(e,n){this.show=!0,(0,i.Z)(e)||(e=new o.Z),this.rectangle=o.Z.clone(e),(0,i.Z)(n)||(n=f.Z.fromType(f.Z.ColorType,{color:new a.Z(1,1,1,1)})),this.material=n,this._material=void 0,this._overlayCommand=void 0,this._rs=void 0}u.prototype.update=function(e){if(!this.show)return;if(!(0,i.Z)(this.material))throw new s.Z("this.material must be defined.");if(!(0,i.Z)(this.rectangle))throw new s.Z("this.rectangle must be defined.");const n=this._rs;(0,i.Z)(n)&&o.Z.equals(n.viewport,this.rectangle)||(this._rs=c.Z.fromCache({blending:p.Z.ALPHA_BLEND,viewport:this.rectangle}));if(e.passes.render){const n=e.context;if(this._material!==this.material||!(0,i.Z)(this._overlayCommand)){this._material=this.material,(0,i.Z)(this._overlayCommand)&&this._overlayCommand.shaderProgram.destroy();const e=new d.Z({sources:[this._material.shaderSource,m.Z]});this._overlayCommand=n.createViewportQuadCommand(e,{renderState:this._rs,uniformMap:this._material._uniforms,owner:this}),this._overlayCommand.pass=l.Z.OVERLAY}this._material.update(n),this._overlayCommand.renderState=this._rs,this._overlayCommand.uniformMap=this._material._uniforms,e.commandList.push(this._overlayCommand)}},u.prototype.isDestroyed=function(){return!1},u.prototype.destroy=function(){return(0,i.Z)(this._overlayCommand)&&(this._overlayCommand.shaderProgram=this._overlayCommand.shaderProgram&&this._overlayCommand.shaderProgram.destroy()),(0,r.Z)(this)};const h=u},57946:(e,n,t)=>{t.d(n,{Z:()=>_});var o=t(88779),a=t(54485),i=t(20176),r=t(96507),s=t(67197),l=t(65412),c=t(29489),d=t(35815),m=t(85933);const p=[3034,3035,3042,3043,3044],f=[4471,4559];function u(e){if(e=(0,o.Z)(e,o.Z.EMPTY_OBJECT),!(0,a.Z)(e.url))throw new i.Z("options.url is required.");if(!(0,a.Z)(e.layers))throw new i.Z("options.layers is required.");if((0,a.Z)(e.times)&&!(0,a.Z)(e.clock))throw new i.Z("options.times was specified, so options.clock is required.");this.defaultAlpha=void 0,this.defaultNightAlpha=void 0,this.defaultDayAlpha=void 0,this.defaultBrightness=void 0,this.defaultContrast=void 0,this.defaultHue=void 0,this.defaultSaturation=void 0,this.defaultGamma=void 0,this.defaultMinificationFilter=void 0,this.defaultMagnificationFilter=void 0,this._getFeatureInfoUrl=(0,o.Z)(e.getFeatureInfoUrl,e.url);const n=s.Z.createIfNeeded(e.url),t=s.Z.createIfNeeded(this._getFeatureInfoUrl);n.setQueryParameters(u.DefaultParameters,!0),t.setQueryParameters(u.GetFeatureInfoDefaultParameters,!0),(0,a.Z)(e.parameters)&&n.setQueryParameters(v(e.parameters)),(0,a.Z)(e.getFeatureInfoParameters)&&t.setQueryParameters(v(e.getFeatureInfoParameters));const c=this;this._reload=void 0,(0,a.Z)(e.times)&&(this._timeDynamicImagery=new d.Z({clock:e.clock,times:e.times,requestImageFunction:function(e,n,t,o,a){return h(c,e,n,t,o,a)},reloadFunction:function(){(0,a.Z)(c._reload)&&c._reload()}}));const _={};if(_.layers=e.layers,_.bbox="{westProjected},{southProjected},{eastProjected},{northProjected}",_.width="{width}",_.height="{height}",parseFloat(n.queryParameters.version)>=1.3){_.crs=(0,o.Z)(e.crs,e.tilingScheme&&e.tilingScheme.projection instanceof l.Z?"EPSG:3857":"CRS:84");const n=_.crs.split(":");if("EPSG"===n[0]&&2===n.length){const e=Number(n[1]);(e>=4e3&&e<5e3&&!f.includes(e)||p.includes(e))&&(_.bbox="{southProjected},{westProjected},{northProjected},{eastProjected}")}}else _.srs=(0,o.Z)(e.srs,e.tilingScheme&&e.tilingScheme.projection instanceof l.Z?"EPSG:3857":"EPSG:4326");n.setQueryParameters(_,!0),t.setQueryParameters(_,!0);const g={query_layers:e.layers,info_format:"{format}"};parseFloat(t.queryParameters.version)>=1.3?(g.i="{i}",g.j="{j}"):(g.x="{i}",g.y="{j}"),t.setQueryParameters(g,!0),this._resource=n,this._pickFeaturesResource=t,this._layers=e.layers,this._tileProvider=new m.Z({url:n,pickFeaturesUrl:t,tilingScheme:(0,o.Z)(e.tilingScheme,new r.Z({ellipsoid:e.ellipsoid})),rectangle:e.rectangle,tileWidth:e.tileWidth,tileHeight:e.tileHeight,minimumLevel:e.minimumLevel,maximumLevel:e.maximumLevel,subdomains:e.subdomains,tileDiscardPolicy:e.tileDiscardPolicy,credit:e.credit,getFeatureInfoFormats:(0,o.Z)(e.getFeatureInfoFormats,u.DefaultGetFeatureInfoFormats),enablePickFeatures:e.enablePickFeatures})}function h(e,n,t,o,i,r){const s=(0,a.Z)(r)?r.data:void 0,l=e._tileProvider;return(0,a.Z)(s)&&l._resource.setQueryParameters(s),l.requestImage(n,t,o,i)}function v(e){const n={};for(const t in e)e.hasOwnProperty(t)&&(n[t.toLowerCase()]=e[t]);return n}Object.defineProperties(u.prototype,{url:{get:function(){return this._resource._url}},proxy:{get:function(){return this._resource.proxy}},layers:{get:function(){return this._layers}},tileWidth:{get:function(){return this._tileProvider.tileWidth}},tileHeight:{get:function(){return this._tileProvider.tileHeight}},maximumLevel:{get:function(){return this._tileProvider.maximumLevel}},minimumLevel:{get:function(){return this._tileProvider.minimumLevel}},tilingScheme:{get:function(){return this._tileProvider.tilingScheme}},rectangle:{get:function(){return this._tileProvider.rectangle}},tileDiscardPolicy:{get:function(){return this._tileProvider.tileDiscardPolicy}},errorEvent:{get:function(){return this._tileProvider.errorEvent}},ready:{get:function(){return this._tileProvider.ready}},readyPromise:{get:function(){return this._tileProvider.readyPromise}},credit:{get:function(){return this._tileProvider.credit}},hasAlphaChannel:{get:function(){return this._tileProvider.hasAlphaChannel}},enablePickFeatures:{get:function(){return this._tileProvider.enablePickFeatures},set:function(e){this._tileProvider.enablePickFeatures=e}},clock:{get:function(){return this._timeDynamicImagery.clock},set:function(e){this._timeDynamicImagery.clock=e}},times:{get:function(){return this._timeDynamicImagery.times},set:function(e){this._timeDynamicImagery.times=e}},getFeatureInfoUrl:{get:function(){return this._getFeatureInfoUrl}}}),u.prototype.getTileCredits=function(e,n,t){return this._tileProvider.getTileCredits(e,n,t)},u.prototype.requestImage=function(e,n,t,o){let i;const r=this._timeDynamicImagery;let s;return(0,a.Z)(r)&&(s=r.currentInterval,i=r.getFromCache(e,n,t,o)),(0,a.Z)(i)||(i=h(this,e,n,t,o,s)),(0,a.Z)(i)&&(0,a.Z)(r)&&r.checkApproachingInterval(e,n,t,o),i},u.prototype.pickFeatures=function(e,n,t,o,i){const r=this._timeDynamicImagery;return function(e,n,t,o,i,r,s){const l=(0,a.Z)(s)?s.data:void 0,c=e._tileProvider;return(0,a.Z)(l)&&c._pickFeaturesResource.setQueryParameters(l),c.pickFeatures(n,t,o,i,r)}(this,e,n,t,o,i,(0,a.Z)(r)?r.currentInterval:void 0)},u.DefaultParameters=Object.freeze({service:"WMS",version:"1.1.1",request:"GetMap",styles:"",format:"image/jpeg"}),u.GetFeatureInfoDefaultParameters=Object.freeze({service:"WMS",version:"1.1.1",request:"GetFeatureInfo"}),u.DefaultGetFeatureInfoFormats=Object.freeze([Object.freeze(new c.Z("json","application/json")),Object.freeze(new c.Z("xml","text/xml")),Object.freeze(new c.Z("text","text/html"))]);const _=u},11320:(e,n,t)=>{t.d(n,{Z:()=>_});var o=t(51138),a=t(78505),i=t(88779),r=t(54485),s=t(20176),l=t(92893),c=t(34152),d=t(67197),m=t(67561),p=t(20709),f=t(35815);const u=Object.freeze({service:"WMTS",version:"1.0.0",request:"GetTile"});function h(e){if(e=(0,i.Z)(e,i.Z.EMPTY_OBJECT),!(0,r.Z)(e.url))throw new s.Z("options.url is required.");if(!(0,r.Z)(e.layer))throw new s.Z("options.layer is required.");if(!(0,r.Z)(e.style))throw new s.Z("options.style is required.");if(!(0,r.Z)(e.tileMatrixSetID))throw new s.Z("options.tileMatrixSetID is required.");if((0,r.Z)(e.times)&&!(0,r.Z)(e.clock))throw new s.Z("options.times was specified, so options.clock is required.");this.defaultAlpha=void 0,this.defaultNightAlpha=void 0,this.defaultDayAlpha=void 0,this.defaultBrightness=void 0,this.defaultContrast=void 0,this.defaultHue=void 0,this.defaultSaturation=void 0,this.defaultGamma=void 0,this.defaultMinificationFilter=void 0,this.defaultMagnificationFilter=void 0;const n=d.Z.createIfNeeded(e.url),t=e.style,o=e.tileMatrixSetID,p=n.url,h=p.match(/{/g);if(!(0,r.Z)(h)||1===h.length&&/{s}/.test(p))n.setQueryParameters(u),this._useKvp=!0;else{const e={style:t,Style:t,TileMatrixSet:o};n.setTemplateValues(e),this._useKvp=!1}this._resource=n,this._layer=e.layer,this._style=t,this._tileMatrixSetID=o,this._tileMatrixLabels=e.tileMatrixLabels,this._format=(0,i.Z)(e.format,"image/jpeg"),this._tileDiscardPolicy=e.tileDiscardPolicy,this._tilingScheme=(0,r.Z)(e.tilingScheme)?e.tilingScheme:new m.Z({ellipsoid:e.ellipsoid}),this._tileWidth=(0,i.Z)(e.tileWidth,256),this._tileHeight=(0,i.Z)(e.tileHeight,256),this._minimumLevel=(0,i.Z)(e.minimumLevel,0),this._maximumLevel=e.maximumLevel,this._rectangle=(0,i.Z)(e.rectangle,this._tilingScheme.rectangle),this._dimensions=e.dimensions;const _=this;this._reload=void 0,(0,r.Z)(e.times)&&(this._timeDynamicImagery=new f.Z({clock:e.clock,times:e.times,requestImageFunction:function(e,n,t,o,a){return v(_,e,n,t,o,a)},reloadFunction:function(){(0,r.Z)(_._reload)&&_._reload()}})),this._readyPromise=Promise.resolve(!0);const g=this._tilingScheme.positionToTileXY(c.Z.southwest(this._rectangle),this._minimumLevel),x=this._tilingScheme.positionToTileXY(c.Z.northeast(this._rectangle),this._minimumLevel),C=(Math.abs(x.x-g.x)+1)*(Math.abs(x.y-g.y)+1);if(C>4)throw new s.Z(`The imagery provider's rectangle and minimumLevel indicate that there are ${C} tiles at the minimum level. Imagery providers with more than four tiles at the minimum level are not supported.`);this._errorEvent=new l.Z;const y=e.credit;this._credit="string"==typeof y?new a.Z(y):y,this._subdomains=e.subdomains,Array.isArray(this._subdomains)?this._subdomains=this._subdomains.slice():(0,r.Z)(this._subdomains)&&this._subdomains.length>0?this._subdomains=this._subdomains.split(""):this._subdomains=["a","b","c"]}function v(e,n,t,a,i,s){const l=e._tileMatrixLabels,c=(0,r.Z)(l)?l[a]:a.toString(),d=e._subdomains,m=e._dimensions,f=(0,r.Z)(s)?s.data:void 0;let u,h;if(e._useKvp){let s={};s.tilematrix=c,s.layer=e._layer,s.style=e._style,s.tilerow=t,s.tilecol=n,s.tilematrixset=e._tileMatrixSetID,s.format=e._format,(0,r.Z)(m)&&(s=(0,o.Z)(s,m)),(0,r.Z)(f)&&(s=(0,o.Z)(s,f)),h={s:d[(n+t+a)%d.length]},u=e._resource.getDerivedResource({queryParameters:s,request:i}),u.setTemplateValues(h)}else h={TileMatrix:c,TileRow:t.toString(),TileCol:n.toString(),s:d[(n+t+a)%d.length]},u=e._resource.getDerivedResource({request:i}),u.setTemplateValues(h),(0,r.Z)(m)&&u.setTemplateValues(m),(0,r.Z)(f)&&u.setTemplateValues(f);return p.Z.loadImage(e,u)}Object.defineProperties(h.prototype,{url:{get:function(){return this._resource.url}},proxy:{get:function(){return this._resource.proxy}},tileWidth:{get:function(){return this._tileWidth}},tileHeight:{get:function(){return this._tileHeight}},maximumLevel:{get:function(){return this._maximumLevel}},minimumLevel:{get:function(){return this._minimumLevel}},tilingScheme:{get:function(){return this._tilingScheme}},rectangle:{get:function(){return this._rectangle}},tileDiscardPolicy:{get:function(){return this._tileDiscardPolicy}},errorEvent:{get:function(){return this._errorEvent}},format:{get:function(){return this._format}},ready:{value:!0},readyPromise:{get:function(){return this._readyPromise}},credit:{get:function(){return this._credit}},hasAlphaChannel:{get:function(){return!0}},clock:{get:function(){return this._timeDynamicImagery.clock},set:function(e){this._timeDynamicImagery.clock=e}},times:{get:function(){return this._timeDynamicImagery.times},set:function(e){this._timeDynamicImagery.times=e}},dimensions:{get:function(){return this._dimensions},set:function(e){this._dimensions!==e&&(this._dimensions=e,(0,r.Z)(this._reload)&&this._reload())}}}),h.prototype.getTileCredits=function(e,n,t){},h.prototype.requestImage=function(e,n,t,o){let a;const i=this._timeDynamicImagery;let s;return(0,r.Z)(i)&&(s=i.currentInterval,a=i.getFromCache(e,n,t,o)),(0,r.Z)(a)||(a=v(this,e,n,t,o,s)),(0,r.Z)(a)&&(0,r.Z)(i)&&i.checkApproachingInterval(e,n,t,o),a},h.prototype.pickFeatures=function(e,n,t,o,a){};const _=h},66840:(e,n,t)=>{t.d(n,{Z:()=>l});var o=t(54485),a=t(34152),i=t(19221),r=t(18061);function s(e,n){const t=n.terrainProvider,i=n.mapProjection,l=i.ellipsoid;let c;const d=n.camera.getRectangleCameraCoordinates(e);return c=n.mode===r.Z.SCENE3D?l.cartesianToCartographic(d):i.unproject(d),(0,o.Z)(t)?t.readyPromise.then((function(){const i=t.availability;if(!(0,o.Z)(i)||n.mode===r.Z.SCENE2D)return c;const l=[a.Z.center(e),a.Z.southeast(e),a.Z.southwest(e),a.Z.northeast(e),a.Z.northwest(e)];return s._sampleTerrainMostDetailed(t,l).then((function(e){const n=e.reduce((function(e,n){return Math.max(n.height,e)}),-Number.MAX_VALUE),t=c;return t.height+=n,t}))})):Promise.resolve(c)}s._sampleTerrainMostDetailed=i.Z;const l=s},24158:(e,n,t)=>{t.d(n,{Z:()=>o});const o=function(e,n,t,o,a){return function(){const i=document.createElement("canvas"),r=a+2*o;i.height=i.width=r;const s=i.getContext("2d");return s.clearRect(0,0,r,r),0!==o&&(s.beginPath(),s.arc(r/2,r/2,r/2,0,2*Math.PI,!0),s.closePath(),s.fillStyle=t,s.fill(),e<1&&(s.save(),s.globalCompositeOperation="destination-out",s.beginPath(),s.arc(r/2,r/2,a/2,0,2*Math.PI,!0),s.closePath(),s.fillStyle="black",s.fill(),s.restore())),s.beginPath(),s.arc(r/2,r/2,a/2,0,2*Math.PI,!0),s.closePath(),s.fillStyle=n,s.fill(),i}}},14076:(e,n,t)=>{t.d(n,{Z:()=>P});var o=t(90868),a=t(22874),i=t(17497),r=t(6785),s=t(88779),l=t(54485),c=t(20176),d=t(93988),m=t(91166),p=t(27400),f=t(28696),u=t(47334),h=t(92106),v=t(48867),_=t(91373),g=t(7063);const x=new r.Z,C=new r.Z,y=new r.Z,T=new r.Z,z=new o.Z,E=new Uint8Array(4);function b(e,n,t,o){const a=n.height===t.height?0:(e-n.height)/(t.height-n.height);return r.Z.lerp(n.color,t.color,a,o)}function A(e,n){return{height:e,color:r.Z.clone(n)}}function S(e){return e=(e=(e=e.filter((function(e,n,t){const o=n>0,a=n<t.length-1,i=!o||e.height===t[n-1].height,r=!a||e.height===t[n+1].height;return!i||!r}))).filter((function(e,n,t){const o=n>0,a=n<t.length-1,i=!!o&&r.Z.equals(e.color,t[n-1].color),s=!!a&&r.Z.equals(e.color,t[n+1].color);return!i||!s}))).filter((function(e,n,t){const o=n>0,a=!!o&&r.Z.equals(e.color,t[n-1].color),i=!o||e.height===t[n-1].height;return!a||!i}))}function D(e){const n=function(e){let n,t;const o=[],i=e.length;for(n=0;n<i;n++){const i=e[n],m=i.entries,p=m.length;if(!Array.isArray(m)||0===p)throw new c.Z("entries must be an array with size > 0.");let f=[];for(t=0;t<p;t++){const e=m[t];if(!(0,l.Z)(e.height))throw new c.Z("entry requires a height.");if(!(0,l.Z)(e.color))throw new c.Z("entry requires a color.");const n=a.Z.clamp(e.height,w._minimumHeight,w._maximumHeight),o=r.Z.clone(e.color,x);o.red*=o.alpha,o.green*=o.alpha,o.blue*=o.alpha,f.push(A(n,o))}let u=!0,h=!0;for(t=0;t<p-1;t++){const e=f[t+0],n=f[t+1];u=u&&e.height<=n.height,h=h&&e.height>=n.height}h?f=f.reverse():u||(0,d.Z)(f,(function(e,n){return a.Z.sign(e.height-n.height)}));let v=(0,s.Z)(i.extendDownwards,!1),_=(0,s.Z)(i.extendUpwards,!1);1!==f.length||v||_||(v=!0,_=!0),v&&f.splice(0,0,A(w._minimumHeight,f[0].color)),_&&f.splice(f.length,0,A(w._maximumHeight,f[f.length-1].color)),f=S(f),o.push(f)}return o}(e);let t,o=[],i=[];function m(e,n){o.push(A(e,n))}function p(e,n,t){let o=r.Z.multiplyByScalar(t,1-n.alpha,T);o=r.Z.add(o,n,o),m(e,o)}const f=n.length;for(t=0;t<f;t++){const e=n[t];let a=0,r=0;i=o,o=[];const s=e.length,c=i.length;for(;a<s||r<c;){const n=a<s?e[a]:void 0,t=a>0?e[a-1]:void 0,o=a<s-1?e[a+1]:void 0,d=r<c?i[r]:void 0,f=r>0?i[r-1]:void 0,u=r<c-1?i[r+1]:void 0;if((0,l.Z)(n)&&(0,l.Z)(d)&&n.height===d.height){const e=(0,l.Z)(u)&&d.height===u.height,i=!(0,l.Z)(f),s=!(0,l.Z)(u),c=(0,l.Z)(o)&&n.height===o.height,h=!(0,l.Z)(t),v=!(0,l.Z)(o);e?c?(p(n.height,n.color,d.color),p(n.height,o.color,u.color)):h?(m(n.height,d.color),p(n.height,n.color,u.color)):v?(p(n.height,n.color,d.color),m(n.height,u.color)):(p(n.height,n.color,d.color),p(n.height,n.color,u.color)):i?c?(m(n.height,n.color),p(n.height,o.color,d.color)):v?(m(n.height,n.color),m(n.height,d.color)):(h||m(n.height,n.color),p(n.height,n.color,d.color)):s?c?(p(n.height,n.color,d.color),m(n.height,o.color)):h?(m(n.height,d.color),m(n.height,n.color)):v?p(n.height,n.color,d.color):(p(n.height,n.color,d.color),m(n.height,n.color)):c?(p(n.height,n.color,d.color),p(n.height,o.color,d.color)):h?(m(n.height,d.color),p(n.height,n.color,d.color)):v?(p(n.height,n.color,d.color),m(n.height,d.color)):p(n.height,n.color,d.color),a+=c?2:1,r+=e?2:1}else if((0,l.Z)(n)&&(0,l.Z)(d)&&(0,l.Z)(f)&&n.height<d.height){const e=b(n.height,f,d,y);(0,l.Z)(t)?(0,l.Z)(o)?p(n.height,n.color,e):(p(n.height,n.color,e),m(n.height,e)):(m(n.height,e),p(n.height,n.color,e)),a++}else if((0,l.Z)(d)&&(0,l.Z)(n)&&(0,l.Z)(t)&&d.height<n.height){const e=b(d.height,t,n,C);(0,l.Z)(f)?(0,l.Z)(u)?p(d.height,e,d.color):(p(d.height,e,d.color),m(d.height,e)):(m(d.height,e),p(d.height,e,d.color)),r++}else(0,l.Z)(n)&&(!(0,l.Z)(d)||n.height<d.height)?(!(0,l.Z)(d)||(0,l.Z)(f)||(0,l.Z)(o)?((0,l.Z)(d)||!(0,l.Z)(f)||(0,l.Z)(t)||(m(f.height,w._emptyColor),m(n.height,w._emptyColor)),m(n.height,n.color)):(m(n.height,n.color),m(n.height,w._emptyColor),m(d.height,w._emptyColor)),a++):(0,l.Z)(d)&&(!(0,l.Z)(n)||d.height<n.height)&&(m(d.height,d.color),r++)}}return S(o)}function w(e){const n=(e=(0,s.Z)(e,s.Z.EMPTY_OBJECT)).scene,t=e.layers;i.Z.typeOf.object("options.scene",n),i.Z.defined("options.layers",t),i.Z.typeOf.number.greaterThan("options.layers.length",t.length,0);const a=D(t),r=a.length;let l,c,d,x;if(!w._useFloatTexture(n.context))for(d=p.Z.UNSIGNED_BYTE,x=m.Z.RGBA,c=new Uint8Array(4*r),l=0;l<r;l++)o.Z.packFloat(a[l].height,z),o.Z.pack(z,c,4*l);else for(d=p.Z.FLOAT,x=m.Z.LUMINANCE,c=new Float32Array(r),l=0;l<r;l++)c[l]=a[l].height;const C=u.Z.create({context:n.context,pixelFormat:x,pixelDatatype:d,source:{arrayBufferView:c,width:r,height:1},sampler:new f.Z({wrapS:_.Z.CLAMP_TO_EDGE,wrapT:_.Z.CLAMP_TO_EDGE,minificationFilter:v.Z.NEAREST,magnificationFilter:h.Z.NEAREST})}),y=new Uint8Array(4*r);for(l=0;l<r;l++){a[l].color.toBytes(E),y[4*l+0]=E[0],y[4*l+1]=E[1],y[4*l+2]=E[2],y[4*l+3]=E[3]}const T=u.Z.create({context:n.context,pixelFormat:m.Z.RGBA,pixelDatatype:p.Z.UNSIGNED_BYTE,source:{arrayBufferView:y,width:r,height:1},sampler:new f.Z({wrapS:_.Z.CLAMP_TO_EDGE,wrapT:_.Z.CLAMP_TO_EDGE,minificationFilter:v.Z.LINEAR,magnificationFilter:h.Z.LINEAR})});return g.Z.fromType("ElevationBand",{heights:C,colors:T})}w._useFloatTexture=function(e){return e.floatingPointTexture},w._maximumHeight=5906376425472,w._minimumHeight=-5906376425472,w._emptyColor=new r.Z(0,0,0,0);const P=w},8743:(e,n,t)=>{t.d(n,{Z:()=>d});var o=t(6785),a=t(51138),i=t(88779),r=t(54485),s=t(33556),l=t(66207),c=t(20993);const d=function(e){e=(0,a.Z)(e,{url:s.Z.fromAssetId(96188)});const n=new l.Z(e);let t=e.style;if(!(0,r.Z)(t)){const n=(0,i.Z)(e.defaultColor,o.Z.WHITE).toCssColorString();t=new c.Z({color:`Boolean(\${feature['cesium#color']}) ? color(\${feature['cesium#color']}) : ${n}`})}return n.style=t,n}},16040:(e,n,t)=>{t.d(n,{Z:()=>p});var o=t(41631),a=t(88779),i=t(54485),r=t(20176),s=t(78224),l=t(45050),c=t(71118),d=t(73020),m=t(27401);const p=function(e){const n=[];let t=(e=(0,a.Z)(e,a.Z.EMPTY_OBJECT)).geometry;if(!(0,i.Z)(t))throw new r.Z("options.geometry is required.");(0,i.Z)(t.attributes)&&(0,i.Z)(t.primitiveType)||(t=t.constructor.createGeometry(t));const p=t.attributes,f=c.Z.clone((0,a.Z)(e.modelMatrix,c.Z.IDENTITY)),u=(0,a.Z)(e.length,1e4);if((0,i.Z)(p.normal)&&n.push(new s.Z({geometry:l.Z.createLineSegmentsForVectors(t,"normal",u),attributes:{color:new o.Z(1,0,0,1)},modelMatrix:f})),(0,i.Z)(p.tangent)&&n.push(new s.Z({geometry:l.Z.createLineSegmentsForVectors(t,"tangent",u),attributes:{color:new o.Z(0,1,0,1)},modelMatrix:f})),(0,i.Z)(p.bitangent)&&n.push(new s.Z({geometry:l.Z.createLineSegmentsForVectors(t,"bitangent",u),attributes:{color:new o.Z(0,0,1,1)},modelMatrix:f})),n.length>0)return new m.Z({asynchronous:!1,geometryInstances:n,appearance:new d.Z({flat:!0,translucent:!1})})}},85122:(e,n,t)=>{t.d(n,{Z:()=>r});var o=t(88779),a=t(54085),i=t(14615);const r=function(e){e=(0,o.Z)(e,o.Z.EMPTY_OBJECT);const n=(0,o.Z)(e.style,i.Z.AERIAL);return new a.Z({assetId:n})}},48836:(e,n,t)=>{t.d(n,{Z:()=>c});var o=t(6356),a=t(88779),i=t(54485),r=t(30271),s=t(53513);function l(e,n){const t=(0,r.Z)(n,"3DTILES_metadata")?n.extensions["3DTILES_metadata"]:n.metadata;if(!(0,i.Z)(t))return;if(!(0,i.Z)(e.schema))return void l._oneTimeWarning("findContentMetadata-missing-root-schema","Could not find a metadata schema for content metadata. For tilesets that contain external tilesets, make sure the schema is added to the root tileset.json.");const s=(0,a.Z)(e.schema.classes,a.Z.EMPTY_OBJECT);if((0,i.Z)(t.class)){const e=s[t.class];return new o.Z({content:t,class:e})}}l._oneTimeWarning=s.Z;const c=l},97738:(e,n,t)=>{t.d(n,{Z:()=>i});var o=t(54485),a=t(30271);function i(e,n){const t=e.metadataExtension;if(!(0,o.Z)(t))return;const i=t.groups,r=(0,a.Z)(n,"3DTILES_metadata")?n.extensions["3DTILES_metadata"].group:n.group;if("number"==typeof r)return i[r];const s=t.groupIds.findIndex((function(e){return e===r}));return s>=0?i[s]:void 0}},62318:(e,n,t)=>{t.d(n,{Z:()=>c});var o=t(88779),a=t(54485),i=t(30271),r=t(73385),s=t(53513);function l(e,n){const t=(0,i.Z)(n,"3DTILES_metadata")?n.extensions["3DTILES_metadata"]:n.metadata;if(!(0,a.Z)(t))return;if(!(0,a.Z)(e.schema))return void l._oneTimeWarning("findTileMetadata-missing-root-schema","Could not find a metadata schema for tile metadata. For tilesets that contain external tilesets, make sure the schema is added to the root tileset.json.");const s=(0,o.Z)(e.schema.classes,o.Z.EMPTY_OBJECT);if((0,a.Z)(t.class)){const e=s[t.class];return new r.Z({tile:t,class:e})}}l._oneTimeWarning=s.Z;const c=l},52314:(e,n,t)=>{t.d(n,{Z:()=>p});var o=t(59015),a=t(93517),i=t(90868),r=t(44990),s=t(40734),l=t(39109),c=t(71118);const d={SCALAR:1,VEC2:2,VEC3:3,VEC4:4,MAT2:4,MAT3:9,MAT4:16},m={SCALAR:void 0,VEC2:o.Z,VEC3:a.Z,VEC4:i.Z,MAT2:s.Z,MAT3:l.Z,MAT4:c.Z};const p=function(e){const n=e.componentType;let t;t="string"==typeof n?r.Z.fromName(n):n;const o=d[e.type],a=m[e.type];return{componentsPerAttribute:o,classType:a,createArrayBufferView:function(e,n,a){return r.Z.createArrayBufferView(t,e,n,o*a)}}}},95189:(e,n,t)=>{t.d(n,{Z:()=>a});var o=t(17497);const a=function(e,n,t){return o.Z.typeOf.string("samplerUniformName",e),o.Z.typeOf.string("matrixUniformName",n),o.Z.typeOf.string("styleUniformName",t),`    float clipDistance = clip(gl_FragCoord, ${e}, ${n}); \n    vec4 clippingPlanesEdgeColor = vec4(1.0); \n    clippingPlanesEdgeColor.rgb = ${t}.rgb; \n    float clippingPlanesEdgeWidth = ${t}.a; \n    if (clipDistance > 0.0 && clipDistance < clippingPlanesEdgeWidth) \n    { \n        gl_FragColor = clippingPlanesEdgeColor;\n    } \n`}},44804:(e,n,t)=>{t.d(n,{Z:()=>s});var o=t(59015),a=t(17497),i=t(53425);const r=new o.Z;const s=function(e,n){a.Z.typeOf.object("clippingPlaneCollection",e),a.Z.typeOf.object("context",n);const t=e.unionClippingRegions,o=e.length,s=i.Z.useFloatTexture(n),l=i.Z.getTextureResolution(e,n,r),c=l.x,d=l.y;let m=s?function(e,n){const t=1/n;let o=""+1/e;-1===o.indexOf(".")&&(o+=".0");let a=`${t}`;-1===a.indexOf(".")&&(a+=".0");return`vec4 getClippingPlane(highp sampler2D packedClippingPlanes, int clippingPlaneNumber, mat4 transform)\n{\n    int pixY = clippingPlaneNumber / ${e};\n    int pixX = clippingPlaneNumber - (pixY * ${e});\n    float u = (float(pixX) + 0.5) * ${o};\n    float v = (float(pixY) + 0.5) * ${a};\n    vec4 plane = texture2D(packedClippingPlanes, vec2(u, v));\n    return czm_transformPlane(plane, transform);\n}\n`}(c,d):function(e,n){const t=1/n;let o=""+1/e;-1===o.indexOf(".")&&(o+=".0");let a=`${t}`;-1===a.indexOf(".")&&(a+=".0");return`vec4 getClippingPlane(highp sampler2D packedClippingPlanes, int clippingPlaneNumber, mat4 transform)\n{\n    int clippingPlaneStartIndex = clippingPlaneNumber * 2;\n    int pixY = clippingPlaneStartIndex / ${e};\n    int pixX = clippingPlaneStartIndex - (pixY * ${e});\n    float u = (float(pixX) + 0.5) * ${o};\n    float v = (float(pixY) + 0.5) * ${a};\n    vec4 oct32 = texture2D(packedClippingPlanes, vec2(u, v)) * 255.0;\n    vec2 oct = vec2(oct32.x * 256.0 + oct32.y, oct32.z * 256.0 + oct32.w);\n    vec4 plane;\n    plane.xyz = czm_octDecode(oct, 65535.0);\n    plane.w = czm_unpackFloat(texture2D(packedClippingPlanes, vec2(u + ${o}, v)));\n    return czm_transformPlane(plane, transform);\n}\n`}(c,d);return m+="\n",m+=t?function(e){return`float clip(vec4 fragCoord, sampler2D clippingPlanes, mat4 clippingPlanesMatrix)\n{\n    vec4 position = czm_windowToEyeCoordinates(fragCoord);\n    vec3 clipNormal = vec3(0.0);\n    vec3 clipPosition = vec3(0.0);\n    float clipAmount;\n    float pixelWidth = czm_metersPerPixel(position);\n    bool breakAndDiscard = false;\n    for (int i = 0; i < ${e}; ++i)\n    {\n        vec4 clippingPlane = getClippingPlane(clippingPlanes, i, clippingPlanesMatrix);\n        clipNormal = clippingPlane.xyz;\n        clipPosition = -clippingPlane.w * clipNormal;\n        float amount = dot(clipNormal, (position.xyz - clipPosition)) / pixelWidth;\n        clipAmount = czm_branchFreeTernary(i == 0, amount, min(amount, clipAmount));\n        if (amount <= 0.0)\n        {\n           breakAndDiscard = true;\n           break;\n        }\n    }\n    if (breakAndDiscard) {\n        discard;\n    }\n    return clipAmount;\n}\n`}(o):function(e){return`float clip(vec4 fragCoord, sampler2D clippingPlanes, mat4 clippingPlanesMatrix)\n{\n    bool clipped = true;\n    vec4 position = czm_windowToEyeCoordinates(fragCoord);\n    vec3 clipNormal = vec3(0.0);\n    vec3 clipPosition = vec3(0.0);\n    float clipAmount = 0.0;\n    float pixelWidth = czm_metersPerPixel(position);\n    for (int i = 0; i < ${e}; ++i)\n    {\n        vec4 clippingPlane = getClippingPlane(clippingPlanes, i, clippingPlanesMatrix);\n        clipNormal = clippingPlane.xyz;\n        clipPosition = -clippingPlane.w * clipNormal;\n        float amount = dot(clipNormal, (position.xyz - clipPosition)) / pixelWidth;\n        clipAmount = max(amount, clipAmount);\n        clipped = clipped && (amount <= 0.0);\n    }\n    if (clipped)\n    {\n        discard;\n    }\n    return clipAmount;\n}\n`}(o),m}},30271:(e,n,t)=>{t.d(n,{Z:()=>a});var o=t(54485);function a(e,n){return(0,o.Z)(e)&&(0,o.Z)(e.extensions)&&(0,o.Z)(e.extensions[n])}},62524:(e,n,t)=>{t.d(n,{Z:()=>h});var o=t(17497),a=t(54485),i=t(34971),r=t(21514),s=t(44674),l=t(2087),c=t(41184),d=t(52314),m=t(92728),p=t(41519),f=t(45262),u=t(24206);function h(e){o.Z.typeOf.number("options.count",e.count),o.Z.typeOf.object("options.batchTable",e.batchTable);const n=e.count,t=e.batchTable,i=e.binaryBody,_=function(e){const n=e.HIERARCHY,t=e.extras,o=e.extensions;let i;(0,a.Z)(n)?(h._deprecationWarning("batchTableHierarchyExtension","The batch table HIERARCHY property has been moved to an extension. Use extensions.3DTILES_batch_table_hierarchy instead."),i=n):(0,a.Z)(o)&&(i=o["3DTILES_batch_table_hierarchy"]);const r={},s={};for(const n in e){if(!e.hasOwnProperty(n)||"HIERARCHY"===n||"extensions"===n||"extras"===n)continue;const t=e[n];Array.isArray(t)?r[n]=t:s[n]=t}return{binaryProperties:s,jsonProperties:r,hierarchy:i,extras:t,extensions:o}}(t),g=new m.Z({count:n,properties:_.jsonProperties}),x=function(e,n){if((0,a.Z)(e))return new s.Z({extension:e,binaryBody:n});return}(_.hierarchy,i),C=function(e,n,t,o){const i={},s={},l={};let c=0;for(const n in t){if(!t.hasOwnProperty(n))continue;if(!(0,a.Z)(o))throw new r.Z(`Property ${n} requires a batch table binary.`);const m=t[n],p=(0,d.Z)(m);s[n]={bufferView:c},i[n]=v(m),l[c]=p.createArrayBufferView(o.buffer,o.byteOffset+m.byteOffset,e),c++}const m={classes:{}};m.classes[n]={properties:i};const p=new f.Z(m);return{featureTableJson:{class:n,count:e,properties:s},bufferViewsU8:l,transcodedSchema:p,transcodedClass:p.classes[n]}}(n,p.Z.BATCH_TABLE_CLASS_NAME,_.binaryProperties,i),y=C.featureTableJson,T=new u.Z({count:y.count,properties:y.properties,class:C.transcodedClass,bufferViews:C.bufferViewsU8}),z=new c.Z({id:0,name:"Batch Table",count:y.count,metadataTable:T,jsonMetadataTable:g,batchTableHierarchy:x});return new l.Z({schema:C.transcodedSchema,propertyTables:[z],extensions:_.extensions,extras:_.extras})}function v(e){const n=function(e){switch(e){case"BYTE":return"INT8";case"UNSIGNED_BYTE":return"UINT8";case"SHORT":return"INT16";case"UNSIGNED_SHORT":return"UINT16";case"INT":return"INT32";case"UNSIGNED_INT":return"UINT32";case"FLOAT":return"FLOAT32";case"DOUBLE":return"FLOAT64"}}(e.componentType);return{type:e.type,componentType:n}}h._deprecationWarning=i.Z},6717:(e,n,t)=>{t.d(n,{Z:()=>i});var o=t(17497),a=t(54485);function i(e){return o.Z.typeOf.object("tileMetadata",e),{tile:{boundingVolume:r("TILE",e),minimumHeight:s("TILE",e),maximumHeight:l("TILE",e)},content:{boundingVolume:r("CONTENT",e),minimumHeight:s("CONTENT",e),maximumHeight:l("CONTENT",e)}}}function r(e,n){const t=`${e}_BOUNDING_BOX`,o=n.getPropertyBySemantic(t);if((0,a.Z)(o))return{box:o};const i=`${e}_BOUNDING_REGION`,r=n.getPropertyBySemantic(i);if((0,a.Z)(r))return{region:r};const s=`${e}_BOUNDING_SPHERE`,l=n.getPropertyBySemantic(s);return(0,a.Z)(l)?{sphere:l}:void 0}function s(e,n){const t=`${e}_MINIMUM_HEIGHT`;return n.getPropertyBySemantic(t)}function l(e,n){const t=`${e}_MAXIMUM_HEIGHT`;return n.getPropertyBySemantic(t)}},29457:(e,n,t)=>{t.d(n,{Z:()=>m});var o=t(17497),a=t(51138),i=t(88779),r=t(54485),s=t(41184),l=t(5512),c=t(2087),d=t(24206);function m(e){const n=(e=(0,i.Z)(e,i.Z.EMPTY_OBJECT)).extension,t=e.schema;let a;o.Z.typeOf.object("options.extension",n),o.Z.typeOf.object("options.schema",t);const m=[];let f;if((0,r.Z)(n.featureTables))for(f=Object.keys(n.featureTables).sort(),a=0;a<f.length;a++){const o=f[a],i=n.featureTables[o],r=t.classes[i.class],l=new d.Z({count:i.count,properties:i.properties,class:r,bufferViews:e.bufferViews});m.push(new s.Z({id:o,count:i.count,metadataTable:l,extras:i.extras,extensions:i.extensions}))}const u=[];if((0,r.Z)(n.featureTextures))for(f=Object.keys(n.featureTextures).sort(),a=0;a<f.length;a++){const o=f[a],i=n.featureTextures[o];u.push(new l.Z({id:o,propertyTexture:p(i),class:t.classes[i.class],textures:e.textures}))}return new c.Z({schema:t,propertyTables:m,propertyTextures:u,statistics:n.statistics,extras:n.extras,extensions:n.extensions})}function p(e){const n={class:e.class,properties:{}},t=e.properties;for(const e in t)if(t.hasOwnProperty(e)){const o=t[e],i={channels:f(o.channels),extras:o.extras,extensions:o.extensions};n.properties[e]=(0,a.Z)(o.texture,i,!0)}return n}function f(e){const n=e.length,t=new Array(n);for(let o=0;o<n;o++)t[o]="rgba".indexOf(e[o]);return t}},20573:(e,n,t)=>{t.d(n,{Z:()=>m});var o=t(17497),a=t(88779),i=t(54485),r=t(41184),s=t(5512),l=t(87335),c=t(2087),d=t(24206);function m(e){const n=(e=(0,a.Z)(e,a.Z.EMPTY_OBJECT)).extension,t=e.schema;o.Z.typeOf.object("options.extension",n),o.Z.typeOf.object("options.schema",t);const m=[];if((0,i.Z)(n.propertyTables))for(let o=0;o<n.propertyTables.length;o++){const a=n.propertyTables[o],i=t.classes[a.class],s=new d.Z({count:a.count,properties:a.properties,class:i,bufferViews:e.bufferViews});m.push(new r.Z({id:o,name:a.name,count:a.count,metadataTable:s,extras:a.extras,extensions:a.extensions}))}const p=[];if((0,i.Z)(n.propertyTextures))for(let o=0;o<n.propertyTextures.length;o++){const a=n.propertyTextures[o];p.push(new s.Z({id:o,name:a.name,propertyTexture:a,class:t.classes[a.class],textures:e.textures}))}const f=[];if((0,i.Z)(n.propertyAttributes))for(let e=0;e<n.propertyAttributes.length;e++){const o=n.propertyAttributes[e];f.push(new l.Z({id:e,name:o.name,class:t.classes[o.class],propertyAttribute:o}))}return new c.Z({schema:t,propertyTables:m,propertyTextures:p,propertyAttributes:f,statistics:n.statistics,extras:n.extras,extensions:n.extensions})}},41783:(e,n,t)=>{t.d(n,{Z:()=>l});var o=t(54485),a=t(7219),i=t(52312),r=t(21514),s=t(72060);function l(e){const n=new Uint8Array(e);let t=(0,i.Z)(n);if("glTF"===t&&(t="glb"),s.Z.isBinaryFormat(t))return{contentType:t,binaryPayload:n};const l=function(e){let n;try{n=(0,a.Z)(e)}catch(e){throw new r.Z("Invalid tile content.")}return n}(n);if((0,o.Z)(l.root))return{contentType:s.Z.EXTERNAL_TILESET,jsonPayload:l};if((0,o.Z)(l.asset))return{contentType:s.Z.GLTF,jsonPayload:l};if((0,o.Z)(l.tileAvailability))return{contentType:s.Z.IMPLICIT_SUBTREE_JSON,jsonPayload:l};if((0,o.Z)(l.type))return{contentType:s.Z.GEOJSON,jsonPayload:l};throw new r.Z("Invalid tile content.")}},35550:(e,n,t)=>{t.d(n,{Z:()=>p});var o=t(88779),a=t(54485),i=t(95411),r=t(44606),s=t(75143),l=t(45813),c=t(90289),d=t(11487);function m(e,n){let t;switch(t=(0,a.Z)(n.value)?n.value:(0,a.Z)(n.index)?[n.index]:n,e){case"ambient":case"diffuse":case"emission":case"specular":return 1===t.length?i.Z.SAMPLER_2D:i.Z.FLOAT_VEC4;case"shininess":case"transparency":return i.Z.FLOAT;case"transparent":case"doubleSided":return i.Z.BOOL}}const p=function(e,n){if(n=(0,o.Z)(n,o.Z.EMPTY_OBJECT),!(0,a.Z)(e))return;if(!(0,c.Z)(e,"KHR_materials_common"))return;(0,c.Z)(e,"KHR_techniques_webgl")||((0,a.Z)(e.extensions)||(e.extensions={}),e.extensions.KHR_techniques_webgl={programs:[],shaders:[],techniques:[]},e.extensionsUsed.push("KHR_techniques_webgl"),e.extensionsRequired.push("KHR_techniques_webgl"));const t=e.extensions.KHR_techniques_webgl;!function(e){const n=e.extensions.KHR_materials_common;if(!(0,a.Z)(n)||!(0,a.Z)(n.lights))return;const t=n.lights,i=t.length;for(let e=0;e<i;e++){const n=t[e];if("ambient"===n.type){(0,a.Z)(n.ambient)||(n.ambient={});const e=n.ambient;(0,a.Z)(e.color)||(e.color=[1,1,1])}else if("directional"===n.type){(0,a.Z)(n.directional)||(n.directional={});const e=n.directional;(0,a.Z)(e.color)||(e.color=[1,1,1])}else if("point"===n.type){(0,a.Z)(n.point)||(n.point={});const e=n.point;(0,a.Z)(e.color)||(e.color=[1,1,1]),e.constantAttenuation=(0,o.Z)(e.constantAttenuation,1),e.linearAttenuation=(0,o.Z)(e.linearAttenuation,0),e.quadraticAttenuation=(0,o.Z)(e.quadraticAttenuation,0)}else if("spot"===n.type){(0,a.Z)(n.spot)||(n.spot={});const e=n.spot;(0,a.Z)(e.color)||(e.color=[1,1,1]),e.constantAttenuation=(0,o.Z)(e.constantAttenuation,1),e.fallOffAngle=(0,o.Z)(e.fallOffAngle,3.14159265),e.fallOffExponent=(0,o.Z)(e.fallOffExponent,0),e.linearAttenuation=(0,o.Z)(e.linearAttenuation,0),e.quadraticAttenuation=(0,o.Z)(e.quadraticAttenuation,0)}}}(e);const p=function(e){const n={};let t;(0,a.Z)(e.extensions)&&(0,a.Z)(e.extensions.KHR_materials_common)&&(t=e.extensions.KHR_materials_common.lights);if((0,a.Z)(t)){const o=e.nodes;for(const e in o)if(o.hasOwnProperty(e)){const n=o[e];if((0,a.Z)(n.extensions)&&(0,a.Z)(n.extensions.KHR_materials_common)){const o=n.extensions.KHR_materials_common.light;(0,a.Z)(o)&&(0,a.Z)(t[o])&&(t[o].node=e),delete n.extensions.KHR_materials_common}}let r=0;for(const e in t)if(t.hasOwnProperty(e)){const o=t[e],s=o.type;if("ambient"!==s&&!(0,a.Z)(o.node)){delete t[e];continue}const l=`light${r.toString()}`;let c,d,m,p;switch(o.baseName=l,s){case"ambient":c=o.ambient,n[`${l}Color`]={type:i.Z.FLOAT_VEC3,value:c.color};break;case"directional":d=o.directional,n[`${l}Color`]={type:i.Z.FLOAT_VEC3,value:d.color},(0,a.Z)(o.node)&&(n[`${l}Transform`]={node:o.node,semantic:"MODELVIEW",type:i.Z.FLOAT_MAT4});break;case"point":m=o.point,n[`${l}Color`]={type:i.Z.FLOAT_VEC3,value:m.color},(0,a.Z)(o.node)&&(n[`${l}Transform`]={node:o.node,semantic:"MODELVIEW",type:i.Z.FLOAT_MAT4}),n[`${l}Attenuation`]={type:i.Z.FLOAT_VEC3,value:[m.constantAttenuation,m.linearAttenuation,m.quadraticAttenuation]};break;case"spot":p=o.spot,n[`${l}Color`]={type:i.Z.FLOAT_VEC3,value:p.color},(0,a.Z)(o.node)&&(n[`${l}Transform`]={node:o.node,semantic:"MODELVIEW",type:i.Z.FLOAT_MAT4},n[`${l}InverseTransform`]={node:o.node,semantic:"MODELVIEWINVERSE",type:i.Z.FLOAT_MAT4,useInFragment:!0}),n[`${l}Attenuation`]={type:i.Z.FLOAT_VEC3,value:[p.constantAttenuation,p.linearAttenuation,p.quadraticAttenuation]},n[`${l}FallOff`]={type:i.Z.FLOAT_VEC2,value:[p.fallOffAngle,p.fallOffExponent]}}++r}}return n}(e),f=d.Z.splitIncompatibleMaterials(e),u={};let h=!1;return l.Z.material(e,(function(l,d){if((0,a.Z)(l.extensions)&&(0,a.Z)(l.extensions.KHR_materials_common)){const v=l.extensions.KHR_materials_common,_=f[d],g=function(e,n){let t="";t+=`technique:${e.technique};`;const i=e.values,r=Object.keys(i).sort(),s=r.length;for(let e=0;e<s;++e){const n=r[e];i.hasOwnProperty(n)&&(t+=`${n}:${m(n,i[n])}`,t+=";")}const l=(0,o.Z)(e.jointCount,0);if(t+=`${l.toString()};`,(0,a.Z)(n)){const e=n.skinning;l>0&&(t+=`${e.type};`),t+=n.hasVertexColors}return t}(v,_);let x=u[g];(0,a.Z)(x)||(x=function(e,n,t,l,d,p){(0,a.Z)(l)||(l={});p=(0,o.Z)(p,!1);const f=n.techniques,u=n.shaders,h=n.programs,v=l.technique.toUpperCase();let _;(0,a.Z)(e.extensions)&&(0,a.Z)(e.extensions.KHR_materials_common)&&(_=e.extensions.KHR_materials_common.lights);const g=l.values,x=(0,o.Z)(l.jointCount,0);let C,y=!1,T=!1;(0,a.Z)(t)&&(C=t.skinning,y=C.skinned,T=t.hasVertexColors);let z="precision highp float;\n",E="precision highp float;\n";const b="CONSTANT"!==v,A={u_modelViewMatrix:{semantic:(0,c.Z)(e,"CESIUM_RTC")?"CESIUM_RTC_MODELVIEW":"MODELVIEW",type:i.Z.FLOAT_MAT4},u_projectionMatrix:{semantic:"PROJECTION",type:i.Z.FLOAT_MAT4}};b&&(A.u_normalMatrix={semantic:"MODELVIEWINVERSETRANSPOSE",type:i.Z.FLOAT_MAT3});y&&(A.u_jointMatrix={count:x,semantic:"JOINTMATRIX",type:i.Z.FLOAT_MAT4});let S,D=!1;for(const e in g)if(g.hasOwnProperty(e)&&"transparent"!==e&&"doubleSided"!==e){const n=m(e,g[e]);S=`u_${e.toLowerCase()}`,D||n!==i.Z.SAMPLER_2D||(D=!0),A[S]={type:n}}(0,a.Z)(A.u_diffuse)&&(A.u_diffuse.semantic="_3DTILESDIFFUSE");if((0,a.Z)(d))for(const e in d)d.hasOwnProperty(e)&&(S=`u_${e}`,A[S]=d[e]);for(S in A)if(A.hasOwnProperty(S)){const e=A[S],n=(0,a.Z)(e.count)?`[${e.count}]`:"";e.type!==i.Z.FLOAT_MAT3&&e.type!==i.Z.FLOAT_MAT4||e.useInFragment?(E+=`uniform ${(0,r.Z)(e.type)} ${S}${n};\n`,delete e.useInFragment):z+=`uniform ${(0,r.Z)(e.type)} ${S}${n};\n`}let w="";y&&(w+="    mat4 skinMatrix =\n        a_weight.x * u_jointMatrix[int(a_joint.x)] +\n        a_weight.y * u_jointMatrix[int(a_joint.y)] +\n        a_weight.z * u_jointMatrix[int(a_joint.z)] +\n        a_weight.w * u_jointMatrix[int(a_joint.w)];\n");const P={a_position:{semantic:"POSITION"}};z+="attribute vec3 a_position;\n",z+="varying vec3 v_positionEC;\n",w+=y?"  vec4 pos = u_modelViewMatrix * skinMatrix * vec4(a_position,1.0);\n":"  vec4 pos = u_modelViewMatrix * vec4(a_position,1.0);\n";w+="  v_positionEC = pos.xyz;\n",w+="  gl_Position = u_projectionMatrix * pos;\n",E+="varying vec3 v_positionEC;\n",b&&(P.a_normal={semantic:"NORMAL"},z+="attribute vec3 a_normal;\n",z+="varying vec3 v_normal;\n",w+=y?"  v_normal = u_normalMatrix * mat3(skinMatrix) * a_normal;\n":"  v_normal = u_normalMatrix * a_normal;\n",E+="varying vec3 v_normal;\n");let I;D&&(P.a_texcoord_0={semantic:"TEXCOORD_0"},I="v_texcoord_0",z+="attribute vec2 a_texcoord_0;\n",z+=`varying vec2 ${I};\n`,w+=`  ${I} = a_texcoord_0;\n`,E+=`varying vec2 ${I};\n`);y&&(P.a_joint={semantic:"JOINTS_0"},P.a_weight={semantic:"WEIGHTS_0"},z+="attribute vec4 a_joint;\n",z+="attribute vec4 a_weight;\n");T&&(P.a_vertexColor={semantic:"COLOR_0"},z+="attribute vec4 a_vertexColor;\n",z+="varying vec4 v_vertexColor;\n",w+="  v_vertexColor = a_vertexColor;\n",E+="varying vec4 v_vertexColor;\n");p&&(P.a_batchId={semantic:"_BATCHID"},z+="attribute float a_batchId;\n");const F=b&&("BLINN"===v||"PHONG"===v)&&(0,a.Z)(A.u_specular)&&(0,a.Z)(A.u_shininess)&&A.u_shininess>0;let L=!1,N=!1,R="";for(const e in _)if(_.hasOwnProperty(e)){const n=_[e],t=n.type.toLowerCase(),o=n.baseName;R+="  {\n";const a=`u_${o}Color`;if("ambient"===t)N=!0,R+=`    ambientLight += ${a};\n`;else if(b){L=!0;const e=`v_${o}Direction`,n=`v_${o}Position`;"point"!==t&&(z+=`varying vec3 ${e};\n`,E+=`varying vec3 ${e};\n`,w+=`  ${e} = mat3(u_${o}Transform) * vec3(0.,0.,1.);\n`,"directional"===t&&(R+=`    vec3 l = normalize(${e});\n`)),"directional"!==t?(z+=`varying vec3 ${n};\n`,E+=`varying vec3 ${n};\n`,w+=`  ${n} = u_${o}Transform[3].xyz;\n`,R+=`    vec3 VP = ${n} - v_positionEC;\n`,R+="    vec3 l = normalize(VP);\n",R+="    float range = length(VP);\n",R+=`    float attenuation = 1.0 / (u_${o}Attenuation.x + `,R+=`(u_${o}Attenuation.y * range) + `,R+=`(u_${o}Attenuation.z * range * range));\n`):R+="    float attenuation = 1.0;\n","spot"===t&&(R+=`    float spotDot = dot(l, normalize(${e}));\n`,R+=`    if (spotDot < cos(u_${o}FallOff.x * 0.5))\n`,R+="    {\n",R+="      attenuation = 0.0;\n",R+="    }\n",R+="    else\n",R+="    {\n",R+=`        attenuation *= max(0.0, pow(spotDot, u_${o}FallOff.y));\n`,R+="    }\n"),R+=`    diffuseLight += ${a}* max(dot(normal,l), 0.) * attenuation;\n`,F&&("BLINN"===v?(R+="    vec3 h = normalize(l + viewDir);\n",R+="    float specularIntensity = max(0., pow(max(dot(normal, h), 0.), u_shininess)) * attenuation;\n"):(R+="    vec3 reflectDir = reflect(-l, normal);\n",R+="    float specularIntensity = max(0., pow(max(dot(reflectDir, viewDir), 0.), u_shininess)) * attenuation;\n"),R+=`    specularLight += ${a} * specularIntensity;\n`)}R+="  }\n"}N||(R+="  ambientLight += vec3(0.2, 0.2, 0.2);\n");if(!L&&"CONSTANT"!==v){E+="#ifdef USE_CUSTOM_LIGHT_COLOR \n",E+="uniform vec3 gltf_lightColor; \n",E+="#endif \n",R+="#ifndef USE_CUSTOM_LIGHT_COLOR \n",R+="    vec3 lightColor = czm_lightColor;\n",R+="#else \n",R+="    vec3 lightColor = gltf_lightColor;\n",R+="#endif \n",R+="  vec3 l = normalize(czm_lightDirectionEC);\n";R+=`  diffuseLight += lightColor * max(dot(normal,l), ${"0.2"});\n`,F&&("BLINN"===v?(R+="  vec3 h = normalize(l + viewDir);\n",R+="  float specularIntensity = max(0., pow(max(dot(normal, h), 0.), u_shininess));\n"):(R+="  vec3 reflectDir = reflect(-l, normal);\n",R+="  float specularIntensity = max(0., pow(max(dot(reflectDir, viewDir), 0.), u_shininess));\n"),R+="  specularLight += lightColor * specularIntensity;\n")}z+="void main(void) {\n",z+=w,z+="}\n",E+="void main(void) {\n";let O,M="  vec3 color = vec3(0.0, 0.0, 0.0);\n";b&&(E+="  vec3 normal = normalize(v_normal);\n",l.doubleSided&&(E+="  if (czm_backFacing())\n",E+="  {\n",E+="    normal = -normal;\n",E+="  }\n"));"CONSTANT"!==v?((0,a.Z)(A.u_diffuse)&&(A.u_diffuse.type===i.Z.SAMPLER_2D?E+=`  vec4 diffuse = texture2D(u_diffuse, ${I});\n`:E+="  vec4 diffuse = u_diffuse;\n",E+="  vec3 diffuseLight = vec3(0.0, 0.0, 0.0);\n",M+="  color += diffuse.rgb * diffuseLight;\n"),F&&(A.u_specular.type===i.Z.SAMPLER_2D?E+=`  vec3 specular = texture2D(u_specular, ${I}).rgb;\n`:E+="  vec3 specular = u_specular.rgb;\n",E+="  vec3 specularLight = vec3(0.0, 0.0, 0.0);\n",M+="  color += specular * specularLight;\n"),O=(0,a.Z)(A.u_transparency)?"  gl_FragColor = vec4(color * diffuse.a * u_transparency, diffuse.a * u_transparency);\n":"  gl_FragColor = vec4(color * diffuse.a, diffuse.a);\n"):O=(0,a.Z)(A.u_transparency)?"  gl_FragColor = vec4(color * u_transparency, u_transparency);\n":"  gl_FragColor = vec4(color, 1.0);\n";T&&(M+="  color *= v_vertexColor.rgb;\n");(0,a.Z)(A.u_emission)&&(A.u_emission.type===i.Z.SAMPLER_2D?E+=`  vec3 emission = texture2D(u_emission, ${I}).rgb;\n`:E+="  vec3 emission = u_emission.rgb;\n",M+="  color += emission;\n");((0,a.Z)(A.u_ambient)||"CONSTANT"!==v)&&((0,a.Z)(A.u_ambient)?A.u_ambient.type===i.Z.SAMPLER_2D?E+=`  vec3 ambient = texture2D(u_ambient, ${I}).rgb;\n`:E+="  vec3 ambient = u_ambient.rgb;\n":E+="  vec3 ambient = diffuse.rgb;\n",M+="  color += ambient * ambientLight;\n");E+="  vec3 viewDir = -normalize(v_positionEC);\n",E+="  vec3 ambientLight = vec3(0.0, 0.0, 0.0);\n",E+=R,E+=M,E+=O,E+="}\n";const Z=(0,s.Z)(u,{type:i.Z.VERTEX_SHADER,extras:{_pipeline:{source:z,extension:".glsl"}}}),H=(0,s.Z)(u,{type:i.Z.FRAGMENT_SHADER,extras:{_pipeline:{source:E,extension:".glsl"}}}),G=(0,s.Z)(h,{fragmentShader:H,vertexShader:Z});return(0,s.Z)(f,{attributes:P,program:G,uniforms:A})}(e,t,_,v,p,n.addBatchIdToGeneratedShaders),u[g]=x,h=!0);const C={},y=v.values;let T;for(const e in y)y.hasOwnProperty(e)&&"transparent"!==e&&"doubleSided"!==e&&(T=`u_${e.toLowerCase()}`,C[T]=y[e]);l.extensions.KHR_techniques_webgl={technique:x,values:C},l.alphaMode="OPAQUE",v.transparent&&(l.alphaMode="BLEND"),v.doubleSided&&(l.doubleSided=!0)}})),h?(d.Z.ensureSemanticExistence(e),e):e}},91507:(e,n,t)=>{t.d(n,{Z:()=>_});var o=t(88779),a=t(54485),i=t(95411),r=t(44606),s=t(75143),l=t(45813),c=t(90289),d=t(11487);function m(e,n,t,o,i){let r;const s=t[n];return(0,a.Z)(s)&&(0,a.Z)(s.texCoord)&&1===s.texCoord&&(o=o.replace("0","1")),(0,a.Z)(t[`${n}Offset`])?(r=`${n}Coord`,i.fragmentShaderMain+=`    vec2 ${r} = computeTexCoord(${o}, ${n}Offset, ${n}Rotation, ${n}Scale);\n`):r=o,r}const p=[0,0],f=[0],u=[1,1];function h(e,n,t){if(-1===e.indexOf("Texture")||!(0,a.Z)(n.extensions)||!(0,a.Z)(n.extensions.KHR_texture_transform))return;const i=`u_${e}`,r=n.extensions.KHR_texture_transform;t[`${i}Offset`]=(0,o.Z)(r.offset,p),t[`${i}Rotation`]=(0,o.Z)(r.rotation,f),t[`${i}Scale`]=(0,o.Z)(r.scale,u),(0,a.Z)(n.texCoord)&&(0,a.Z)(r.texCoord)&&(t[i].texCoord=r.texCoord)}function v(e){if(-1!==e.indexOf("Offset"))return i.Z.FLOAT_VEC2;if(-1!==e.indexOf("Rotation"))return i.Z.FLOAT;if(-1!==e.indexOf("Scale"))return i.Z.FLOAT_VEC2;if(-1!==e.indexOf("Texture"))return i.Z.SAMPLER_2D;switch(e){case"u_baseColorFactor":case"u_diffuseFactor":return i.Z.FLOAT_VEC4;case"u_metallicFactor":case"u_roughnessFactor":case"u_glossinessFactor":return i.Z.FLOAT;case"u_emissiveFactor":case"u_specularFactor":return i.Z.FLOAT_VEC3}}const _=function(e,n){if(n=(0,o.Z)(n,o.Z.EMPTY_OBJECT),(0,c.Z)(e,"KHR_techniques_webgl"))return e;if(!(0,a.Z)(e.materials)||0===e.materials.length)return e;(0,a.Z)(e.extensions)||(e.extensions={}),(0,a.Z)(e.extensionsUsed)||(e.extensionsUsed=[]),(0,a.Z)(e.extensionsRequired)||(e.extensionsRequired=[]),e.extensions.KHR_techniques_webgl={programs:[],shaders:[],techniques:[]},e.extensionsUsed.push("KHR_techniques_webgl"),e.extensionsRequired.push("KHR_techniques_webgl");const t=d.Z.splitIncompatibleMaterials(e);return l.Z.material(e,(function(d,p){const f={},u=function(e,n,t,d,p,f){const u=(0,o.Z)(f.addBatchIdToGeneratedShaders,!1),_=e.extensions.KHR_techniques_webgl,g=_.techniques,x=_.shaders,C=_.programs,y=function(e){return(0,a.Z)(e.extensions)&&(0,a.Z)(e.extensions.KHR_materials_pbrSpecularGlossiness)}(n);let T,z,E;if(!y){const e=n.pbrMetallicRoughness;if((0,a.Z)(e))for(z in e)e.hasOwnProperty(z)&&(E=e[z],T=`u_${z}`,d[T]=E,h(z,E,d));else d.u_baseColorFactor=[1,1,1,1]}if(y){const e=n.extensions.KHR_materials_pbrSpecularGlossiness;for(z in e)e.hasOwnProperty(z)&&(E=e[z],T=`u_${z}`,d[T]=E,h(z,E,d))}for(const e in n)n.hasOwnProperty(e)&&(e.indexOf("Texture")>=0||e.indexOf("Factor")>=0)&&(E=n[e],T=`u_${e}`,d[T]=E,h(e,E,d));let b,A="precision highp float;\n",S="precision highp float;\n";(0,a.Z)(e.skins)&&(b=e.skins[0]);const D=(0,a.Z)(b)?b.joints:[],w=D.length,P=p[t];let I,F,L=!1,N=!1,R=!1,O=!1,M=!1,Z=!1,H=!1,G=!1,U=!1;(0,a.Z)(P)&&(I=P.skinning,L=I.skinned&&D.length>0,N=P.hasVertexColors,R=P.hasMorphTargets,O=P.hasNormals,M=P.hasTangents,Z=P.hasTexCoords,H=P.hasTexCoord1,G=P.hasOutline);R&&l.Z.mesh(e,(function(e){l.Z.meshPrimitive(e,(function(e){if(e.material===t){const n=e.targets;(0,a.Z)(n)&&(F=n)}}))}));const W={u_modelViewMatrix:{semantic:(0,c.Z)(e,"CESIUM_RTC")?"CESIUM_RTC_MODELVIEW":"MODELVIEW",type:i.Z.FLOAT_MAT4},u_projectionMatrix:{semantic:"PROJECTION",type:i.Z.FLOAT_MAT4}};(0,a.Z)(n.extensions)&&(0,a.Z)(n.extensions.KHR_materials_unlit)&&(U=!0);O&&(W.u_normalMatrix={semantic:"MODELVIEWINVERSETRANSPOSE",type:i.Z.FLOAT_MAT3});L&&(W.u_jointMatrix={count:w,semantic:"JOINTMATRIX",type:i.Z.FLOAT_MAT4});R&&(W.u_morphWeights={count:F.length,semantic:"MORPHWEIGHTS",type:i.Z.FLOAT});const B=n.alphaMode;(0,a.Z)(B)&&"MASK"===B&&(W.u_alphaCutoff={semantic:"ALPHACUTOFF",type:i.Z.FLOAT});for(T in d)d.hasOwnProperty(T)&&(W[T]={type:v(T)});const V=(0,o.Z)(W.u_baseColorTexture,W.u_baseColorFactor);(0,a.Z)(V)&&(V.semantic="_3DTILESDIFFUSE");for(T in W)if(W.hasOwnProperty(T)){const e=W[T],n=(0,a.Z)(e.count)?`[${e.count}]`:"";e.type!==i.Z.FLOAT_MAT3&&e.type!==i.Z.FLOAT_MAT4&&"u_morphWeights"!==T||e.useInFragment?(S+=`uniform ${(0,r.Z)(e.type)} ${T}${n};\n`,delete e.useInFragment):A+=`uniform ${(0,r.Z)(e.type)} ${T}${n};\n`}G&&(S+="uniform sampler2D u_outlineTexture;\n");let X="";L&&(X+="    mat4 skinMatrix =\n        a_weight.x * u_jointMatrix[int(a_joint.x)] +\n        a_weight.y * u_jointMatrix[int(a_joint.y)] +\n        a_weight.z * u_jointMatrix[int(a_joint.z)] +\n        a_weight.w * u_jointMatrix[int(a_joint.w)];\n");const k={a_position:{semantic:"POSITION"}};G&&(k.a_outlineCoordinates={semantic:"_OUTLINE_COORDINATES"});A+="attribute vec3 a_position;\n",O&&(A+="varying vec3 v_positionEC;\n");G&&(A+="attribute vec3 a_outlineCoordinates;\n",A+="varying vec3 v_outlineCoordinates;\n");X+="    vec3 weightedPosition = a_position;\n",O&&(X+="    vec3 weightedNormal = a_normal;\n");M&&(X+="    vec4 weightedTangent = a_tangent;\n");if(R)for(let e=0;e<F.length;e++){const n=F[e];for(const t in n)if(n.hasOwnProperty(t)&&"extras"!==t){const n=`a_${t}_${e}`;k[n]={semantic:`${t}_${e}`},A+=`attribute vec3 ${n};\n`,"POSITION"===t?X+=`    weightedPosition += u_morphWeights[${e}] * ${n};\n`:"NORMAL"===t?X+=`    weightedNormal += u_morphWeights[${e}] * ${n};\n`:M&&"TANGENT"===t&&(X+=`    weightedTangent.xyz += u_morphWeights[${e}] * ${n};\n`)}}X+=L?"    vec4 position = skinMatrix * vec4(weightedPosition, 1.0);\n":"    vec4 position = vec4(weightedPosition, 1.0);\n";X+="    position = u_modelViewMatrix * position;\n",O&&(X+="    v_positionEC = position.xyz;\n");X+="    gl_Position = u_projectionMatrix * position;\n",G&&(X+="    v_outlineCoordinates = a_outlineCoordinates;\n");O&&(k.a_normal={semantic:"NORMAL"},A+="attribute vec3 a_normal;\n",U||(A+="varying vec3 v_normal;\n",X+=L?"    v_normal = u_normalMatrix * mat3(skinMatrix) * weightedNormal;\n":"    v_normal = u_normalMatrix * weightedNormal;\n",S+="varying vec3 v_normal;\n"),S+="varying vec3 v_positionEC;\n");M&&(k.a_tangent={semantic:"TANGENT"},A+="attribute vec4 a_tangent;\n",A+="varying vec4 v_tangent;\n",X+="    v_tangent.xyz = u_normalMatrix * weightedTangent.xyz;\n",X+="    v_tangent.w = weightedTangent.w;\n",S+="varying vec4 v_tangent;\n");G&&(S+="varying vec3 v_outlineCoordinates;\n");let Y,q,Q,j,$,K,J,ee,ne="";if(Z){if(k.a_texcoord_0={semantic:"TEXCOORD_0"},Y="v_texcoord_0",A+="attribute vec2 a_texcoord_0;\n",A+=`varying vec2 ${Y};\n`,X+=`    ${Y} = a_texcoord_0;\n`,S+=`varying vec2 ${Y};\n`,H){k.a_texcoord_1={semantic:"TEXCOORD_1"};const e=Y.replace("0","1");A+="attribute vec2 a_texcoord_1;\n",A+=`varying vec2 ${e};\n`,X+=`    ${e} = a_texcoord_1;\n`,S+=`varying vec2 ${e};\n`}const n={fragmentShaderMain:ne};q=m(e,"u_normalTexture",d,Y,n),Q=m(e,"u_baseColorTexture",d,Y,n),j=m(e,"u_specularGlossinessTexture",d,Y,n),$=m(e,"u_diffuseTexture",d,Y,n),K=m(e,"u_metallicRoughnessTexture",d,Y,n),J=m(e,"u_occlusionTexture",d,Y,n),ee=m(e,"u_emissiveTexture",d,Y,n),ne=n.fragmentShaderMain}L&&(k.a_joint={semantic:"JOINTS_0"},k.a_weight={semantic:"WEIGHTS_0"},A+="attribute vec4 a_joint;\n",A+="attribute vec4 a_weight;\n");N&&(k.a_vertexColor={semantic:"COLOR_0"},A+="attribute vec4 a_vertexColor;\n",A+="varying vec4 v_vertexColor;\n",X+="  v_vertexColor = a_vertexColor;\n",S+="varying vec4 v_vertexColor;\n");u&&(k.a_batchId={semantic:"_BATCHID"},A+="attribute float a_batchId;\n");A+="void main(void) \n{\n",A+=X,A+="}\n",O&&!U&&(S+="const float M_PI = 3.141592653589793;\n",S+="vec3 lambertianDiffuse(vec3 diffuseColor) \n{\n    return diffuseColor / M_PI;\n}\n\n",S+="vec3 fresnelSchlick2(vec3 f0, vec3 f90, float VdotH) \n{\n    return f0 + (f90 - f0) * pow(clamp(1.0 - VdotH, 0.0, 1.0), 5.0);\n}\n\n",S+="vec3 fresnelSchlick(float metalness, float VdotH) \n{\n    return metalness + (vec3(1.0) - metalness) * pow(1.0 - VdotH, 5.0);\n}\n\n",S+="float smithVisibilityG1(float NdotV, float roughness) \n{\n    float k = (roughness + 1.0) * (roughness + 1.0) / 8.0;\n    return NdotV / (NdotV * (1.0 - k) + k);\n}\n\n",S+="float smithVisibilityGGX(float roughness, float NdotL, float NdotV) \n{\n    return smithVisibilityG1(NdotL, roughness) * smithVisibilityG1(NdotV, roughness);\n}\n\n",S+="float GGX(float roughness, float NdotH) \n{\n    float roughnessSquared = roughness * roughness;\n    float f = (NdotH * roughnessSquared - NdotH) * NdotH + 1.0;\n    return roughnessSquared / (M_PI * f * f);\n}\n\n");S+="vec3 SRGBtoLINEAR3(vec3 srgbIn) \n{\n    return pow(srgbIn, vec3(2.2));\n}\n\n",S+="vec4 SRGBtoLINEAR4(vec4 srgbIn) \n{\n    vec3 linearOut = pow(srgbIn.rgb, vec3(2.2));\n    return vec4(linearOut, srgbIn.a);\n}\n\n",S+="vec3 applyTonemapping(vec3 linearIn) \n{\n#ifndef HDR \n    return czm_acesTonemapping(linearIn);\n#else \n    return linearIn;\n#endif \n}\n\n",S+="vec3 LINEARtoSRGB(vec3 linearIn) \n{\n#ifndef HDR \n    return pow(linearIn, vec3(1.0/2.2));\n#else \n    return linearIn;\n#endif \n}\n\n",S+="vec2 computeTexCoord(vec2 texCoords, vec2 offset, float rotation, vec2 scale) \n{\n    rotation = -rotation; \n    mat3 transform = mat3(\n        cos(rotation) * scale.x, sin(rotation) * scale.x, 0.0, \n       -sin(rotation) * scale.y, cos(rotation) * scale.y, 0.0, \n        offset.x, offset.y, 1.0); \n    vec2 transformedTexCoords = (transform * vec3(fract(texCoords), 1.0)).xy; \n    return transformedTexCoords; \n}\n\n",S+="#ifdef USE_IBL_LIGHTING \n",S+="uniform vec2 gltf_iblFactor; \n",S+="#endif \n",S+="#ifdef USE_CUSTOM_LIGHT_COLOR \n",S+="uniform vec3 gltf_lightColor; \n",S+="#endif \n",S+="void main(void) \n{\n",S+=ne,O&&!U&&(S+="    vec3 ng = normalize(v_normal);\n",S+="    vec3 positionWC = vec3(czm_inverseView * vec4(v_positionEC, 1.0));\n",(0,a.Z)(d.u_normalTexture)?M?(S+="    vec3 t = normalize(v_tangent.xyz);\n",S+="    vec3 b = normalize(cross(ng, t) * v_tangent.w);\n",S+="    mat3 tbn = mat3(t, b, ng);\n",S+=`    vec3 n = texture2D(u_normalTexture, ${q}).rgb;\n`,S+="    n = normalize(tbn * (2.0 * n - 1.0));\n"):(S=`#ifdef GL_OES_standard_derivatives\n#extension GL_OES_standard_derivatives : enable\n#endif\n${S}`,S+="#ifdef GL_OES_standard_derivatives\n",S+="    vec3 pos_dx = dFdx(v_positionEC);\n",S+="    vec3 pos_dy = dFdy(v_positionEC);\n",S+=`    vec3 tex_dx = dFdx(vec3(${q},0.0));\n`,S+=`    vec3 tex_dy = dFdy(vec3(${q},0.0));\n`,S+="    vec3 t = (tex_dy.t * pos_dx - tex_dx.t * pos_dy) / (tex_dx.s * tex_dy.t - tex_dy.s * tex_dx.t);\n",S+="    t = normalize(t - ng * dot(ng, t));\n",S+="    vec3 b = normalize(cross(ng, t));\n",S+="    mat3 tbn = mat3(t, b, ng);\n",S+=`    vec3 n = texture2D(u_normalTexture, ${q}).rgb;\n`,S+="    n = normalize(tbn * (2.0 * n - 1.0));\n",S+="#else\n",S+="    vec3 n = ng;\n",S+="#endif\n"):S+="    vec3 n = ng;\n",n.doubleSided&&(S+="    if (czm_backFacing())\n",S+="    {\n",S+="        n = -n;\n",S+="    }\n"));(0,a.Z)(d.u_baseColorTexture)?(S+=`    vec4 baseColorWithAlpha = SRGBtoLINEAR4(texture2D(u_baseColorTexture, ${Q}));\n`,(0,a.Z)(d.u_baseColorFactor)&&(S+="    baseColorWithAlpha *= u_baseColorFactor;\n")):(0,a.Z)(d.u_baseColorFactor)?S+="    vec4 baseColorWithAlpha = u_baseColorFactor;\n":S+="    vec4 baseColorWithAlpha = vec4(1.0);\n";N&&(S+="    baseColorWithAlpha *= v_vertexColor;\n");S+="    vec3 baseColor = baseColorWithAlpha.rgb;\n",O&&!U?(y?((0,a.Z)(d.u_specularGlossinessTexture)?(S+=`    vec4 specularGlossiness = SRGBtoLINEAR4(texture2D(u_specularGlossinessTexture, ${j}));\n`,S+="    vec3 specular = specularGlossiness.rgb;\n",S+="    float glossiness = specularGlossiness.a;\n",(0,a.Z)(d.u_specularFactor)&&(S+="    specular *= u_specularFactor;\n"),(0,a.Z)(d.u_glossinessFactor)&&(S+="    glossiness *= u_glossinessFactor;\n")):((0,a.Z)(d.u_specularFactor)?S+="    vec3 specular = clamp(u_specularFactor, vec3(0.0), vec3(1.0));\n":S+="    vec3 specular = vec3(1.0);\n",(0,a.Z)(d.u_glossinessFactor)?S+="    float glossiness = clamp(u_glossinessFactor, 0.0, 1.0);\n":S+="    float glossiness = 1.0;\n"),(0,a.Z)(d.u_diffuseTexture)?(S+=`    vec4 diffuse = SRGBtoLINEAR4(texture2D(u_diffuseTexture, ${$}));\n`,(0,a.Z)(d.u_diffuseFactor)&&(S+="    diffuse *= u_diffuseFactor;\n")):(0,a.Z)(d.u_diffuseFactor)?S+="    vec4 diffuse = clamp(u_diffuseFactor, vec4(0.0), vec4(1.0));\n":S+="    vec4 diffuse = vec4(1.0);\n",S+="    baseColorWithAlpha.a = diffuse.a;\n"):(0,a.Z)(d.u_metallicRoughnessTexture)?(S+=`    vec3 metallicRoughness = texture2D(u_metallicRoughnessTexture, ${K}).rgb;\n`,S+="    float metalness = clamp(metallicRoughness.b, 0.0, 1.0);\n",S+="    float roughness = clamp(metallicRoughness.g, 0.04, 1.0);\n",(0,a.Z)(d.u_metallicFactor)&&(S+="    metalness *= u_metallicFactor;\n"),(0,a.Z)(d.u_roughnessFactor)&&(S+="    roughness *= u_roughnessFactor;\n")):((0,a.Z)(d.u_metallicFactor)?S+="    float metalness = clamp(u_metallicFactor, 0.0, 1.0);\n":S+="    float metalness = 1.0;\n",(0,a.Z)(d.u_roughnessFactor)?S+="    float roughness = clamp(u_roughnessFactor, 0.04, 1.0);\n":S+="    float roughness = 1.0;\n"),S+="    vec3 v = -normalize(v_positionEC);\n",S+="#ifndef USE_CUSTOM_LIGHT_COLOR \n",S+="    vec3 lightColorHdr = czm_lightColorHdr;\n",S+="#else \n",S+="    vec3 lightColorHdr = gltf_lightColor;\n",S+="#endif \n",S+="    vec3 l = normalize(czm_lightDirectionEC);\n",S+="    vec3 h = normalize(v + l);\n",S+="    float NdotL = clamp(dot(n, l), 0.001, 1.0);\n",S+="    float NdotV = abs(dot(n, v)) + 0.001;\n",S+="    float NdotH = clamp(dot(n, h), 0.0, 1.0);\n",S+="    float LdotH = clamp(dot(l, h), 0.0, 1.0);\n",S+="    float VdotH = clamp(dot(v, h), 0.0, 1.0);\n",S+="    vec3 f0 = vec3(0.04);\n",y?(S+="    float roughness = 1.0 - glossiness;\n",S+="    vec3 diffuseColor = diffuse.rgb * (1.0 - max(max(specular.r, specular.g), specular.b));\n",S+="    vec3 specularColor = specular;\n"):(S+="    vec3 diffuseColor = baseColor * (1.0 - metalness) * (1.0 - f0);\n",S+="    vec3 specularColor = mix(f0, baseColor, metalness);\n"),S+="    float alpha = roughness * roughness;\n",S+="    float reflectance = max(max(specularColor.r, specularColor.g), specularColor.b);\n",S+="    vec3 r90 = vec3(clamp(reflectance * 25.0, 0.0, 1.0));\n",S+="    vec3 r0 = specularColor.rgb;\n",S+="    vec3 F = fresnelSchlick2(r0, r90, VdotH);\n",S+="    float G = smithVisibilityGGX(alpha, NdotL, NdotV);\n",S+="    float D = GGX(alpha, NdotH);\n",S+="    vec3 diffuseContribution = (1.0 - F) * lambertianDiffuse(diffuseColor);\n",S+="    vec3 specularContribution = F * G * D / (4.0 * NdotL * NdotV);\n",S+="    vec3 color = NdotL * lightColorHdr * (diffuseContribution + specularContribution);\n",S+="#if defined(USE_IBL_LIGHTING) && !defined(DIFFUSE_IBL) && !defined(SPECULAR_IBL) \n",S+="    vec3 r = normalize(czm_inverseViewRotation * normalize(reflect(v, n)));\n",S+="    float vertexRadius = length(positionWC);\n",S+="    float horizonDotNadir = 1.0 - min(1.0, czm_ellipsoidRadii.x / vertexRadius);\n",S+="    float reflectionDotNadir = dot(r, normalize(positionWC));\n",S+="    r.x = -r.x;\n",S+="    r = -normalize(czm_temeToPseudoFixed * r);\n",S+="    r.x = -r.x;\n",S+="    float inverseRoughness = 1.04 - roughness;\n",S+="    inverseRoughness *= inverseRoughness;\n",S+="    vec3 sceneSkyBox = textureCube(czm_environmentMap, r).rgb * inverseRoughness;\n",S+="    float atmosphereHeight = 0.05;\n",S+="    float blendRegionSize = 0.1 * ((1.0 - inverseRoughness) * 8.0 + 1.1 - horizonDotNadir);\n",S+="    float blendRegionOffset = roughness * -1.0;\n",S+="    float farAboveHorizon = clamp(horizonDotNadir - blendRegionSize * 0.5 + blendRegionOffset, 1.0e-10 - blendRegionSize, 0.99999);\n",S+="    float aroundHorizon = clamp(horizonDotNadir + blendRegionSize * 0.5, 1.0e-10 - blendRegionSize, 0.99999);\n",S+="    float farBelowHorizon = clamp(horizonDotNadir + blendRegionSize * 1.5, 1.0e-10 - blendRegionSize, 0.99999);\n",S+="    float smoothstepHeight = smoothstep(0.0, atmosphereHeight, horizonDotNadir);\n",S+="    vec3 belowHorizonColor = mix(vec3(0.1, 0.15, 0.25), vec3(0.4, 0.7, 0.9), smoothstepHeight);\n",S+="    vec3 nadirColor = belowHorizonColor * 0.5;\n",S+="    vec3 aboveHorizonColor = mix(vec3(0.9, 1.0, 1.2), belowHorizonColor, roughness * 0.5);\n",S+="    vec3 blueSkyColor = mix(vec3(0.18, 0.26, 0.48), aboveHorizonColor, reflectionDotNadir * inverseRoughness * 0.5 + 0.75);\n",S+="    vec3 zenithColor = mix(blueSkyColor, sceneSkyBox, smoothstepHeight);\n",S+="    vec3 blueSkyDiffuseColor = vec3(0.7, 0.85, 0.9);\n",S+="    float diffuseIrradianceFromEarth = (1.0 - horizonDotNadir) * (reflectionDotNadir * 0.25 + 0.75) * smoothstepHeight;\n",S+="    float diffuseIrradianceFromSky = (1.0 - smoothstepHeight) * (1.0 - (reflectionDotNadir * 0.25 + 0.25));\n",S+="    vec3 diffuseIrradiance = blueSkyDiffuseColor * clamp(diffuseIrradianceFromEarth + diffuseIrradianceFromSky, 0.0, 1.0);\n",S+="    float notDistantRough = (1.0 - horizonDotNadir * roughness * 0.8);\n",S+="    vec3 specularIrradiance = mix(zenithColor, aboveHorizonColor, smoothstep(farAboveHorizon, aroundHorizon, reflectionDotNadir) * notDistantRough);\n",S+="    specularIrradiance = mix(specularIrradiance, belowHorizonColor, smoothstep(aroundHorizon, farBelowHorizon, reflectionDotNadir) * inverseRoughness);\n",S+="    specularIrradiance = mix(specularIrradiance, nadirColor, smoothstep(farBelowHorizon, 1.0, reflectionDotNadir) * inverseRoughness);\n",S+="#ifdef USE_SUN_LUMINANCE \n",S+="    float LdotZenith = clamp(dot(normalize(czm_inverseViewRotation * l), normalize(positionWC * -1.0)), 0.001, 1.0);\n",S+="    float S = acos(LdotZenith);\n",S+="    float NdotZenith = clamp(dot(normalize(czm_inverseViewRotation * n), normalize(positionWC * -1.0)), 0.001, 1.0);\n",S+="    float gamma = acos(NdotL);\n",S+="    float numerator = ((0.91 + 10.0 * exp(-3.0 * gamma) + 0.45 * pow(NdotL, 2.0)) * (1.0 - exp(-0.32 / NdotZenith)));\n",S+="    float denominator = (0.91 + 10.0 * exp(-3.0 * S) + 0.45 * pow(LdotZenith,2.0)) * (1.0 - exp(-0.32));\n",S+="    float luminance = gltf_luminanceAtZenith * (numerator / denominator);\n",S+="#endif \n",S+="    vec2 brdfLut = texture2D(czm_brdfLut, vec2(NdotV, roughness)).rg;\n",S+="    vec3 IBLColor = (diffuseIrradiance * diffuseColor * gltf_iblFactor.x) + (specularIrradiance * SRGBtoLINEAR3(specularColor * brdfLut.x + brdfLut.y) * gltf_iblFactor.y);\n",S+="    float maximumComponent = max(max(lightColorHdr.x, lightColorHdr.y), lightColorHdr.z);\n",S+="    vec3 lightColor = lightColorHdr / max(maximumComponent, 1.0);\n",S+="    IBLColor *= lightColor;\n",S+="#ifdef USE_SUN_LUMINANCE \n",S+="    color += IBLColor * luminance;\n",S+="#else \n",S+="    color += IBLColor; \n",S+="#endif \n",S+="#elif defined(DIFFUSE_IBL) || defined(SPECULAR_IBL) \n",S+="    const mat3 yUpToZUp = mat3(-1.0, 0.0, 0.0, 0.0, 0.0, -1.0, 0.0, 1.0, 0.0); \n",S+="    vec3 cubeDir = normalize(yUpToZUp * gltf_iblReferenceFrameMatrix * normalize(reflect(-v, n))); \n",S+="#ifdef DIFFUSE_IBL \n",S+="#ifdef CUSTOM_SPHERICAL_HARMONICS \n",S+="    vec3 diffuseIrradiance = czm_sphericalHarmonics(cubeDir, gltf_sphericalHarmonicCoefficients); \n",S+="#else \n",S+="    vec3 diffuseIrradiance = czm_sphericalHarmonics(cubeDir, czm_sphericalHarmonicCoefficients); \n",S+="#endif \n",S+="#else \n",S+="    vec3 diffuseIrradiance = vec3(0.0); \n",S+="#endif \n",S+="#ifdef SPECULAR_IBL \n",S+="    vec2 brdfLut = texture2D(czm_brdfLut, vec2(NdotV, roughness)).rg;\n",S+="#ifdef CUSTOM_SPECULAR_IBL \n",S+="    vec3 specularIBL = czm_sampleOctahedralProjection(gltf_specularMap, gltf_specularMapSize, cubeDir,  roughness * gltf_maxSpecularLOD, gltf_maxSpecularLOD);\n",S+="#else \n",S+="    vec3 specularIBL = czm_sampleOctahedralProjection(czm_specularEnvironmentMaps, czm_specularEnvironmentMapSize, cubeDir,  roughness * czm_specularEnvironmentMapsMaximumLOD, czm_specularEnvironmentMapsMaximumLOD);\n",S+="#endif \n",S+="    specularIBL *= F * brdfLut.x + brdfLut.y;\n",S+="#else \n",S+="    vec3 specularIBL = vec3(0.0); \n",S+="#endif \n",S+="    color += diffuseIrradiance * diffuseColor + specularColor * specularIBL;\n",S+="#endif \n"):S+="    vec3 color = baseColor;\n";U||((0,a.Z)(d.u_occlusionTexture)&&(S+=`    color *= texture2D(u_occlusionTexture, ${J}).r;\n`),(0,a.Z)(d.u_emissiveTexture)?(S+=`    vec3 emissive = SRGBtoLINEAR3(texture2D(u_emissiveTexture, ${ee}).rgb);\n`,(0,a.Z)(d.u_emissiveFactor)&&(S+="    emissive *= u_emissiveFactor;\n"),S+="    color += emissive;\n"):(0,a.Z)(d.u_emissiveFactor)&&(S+="    color += u_emissiveFactor;\n"));U||(S+="    color = applyTonemapping(color);\n");S+="    color = LINEARtoSRGB(color);\n",G&&(S+="    float outlineness = max(\n",S+="        texture2D(u_outlineTexture, vec2(v_outlineCoordinates.x, 0.5)).r,\n",S+="        max(\n",S+="          texture2D(u_outlineTexture, vec2(v_outlineCoordinates.y, 0.5)).r,\n",S+="          texture2D(u_outlineTexture, vec2(v_outlineCoordinates.z, 0.5)).r));\n",S+="    color = mix(color, vec3(0.0, 0.0, 0.0), outlineness);\n");(0,a.Z)(B)?"MASK"===B?(S+="    if (baseColorWithAlpha.a < u_alphaCutoff) {\n",S+="        discard;\n",S+="    }\n",S+="    gl_FragColor = vec4(color, 1.0);\n"):S+="BLEND"===B?"    gl_FragColor = vec4(color, baseColorWithAlpha.a);\n":"    gl_FragColor = vec4(color, 1.0);\n":S+="    gl_FragColor = vec4(color, 1.0);\n";S+="}\n";const te=(0,s.Z)(x,{type:i.Z.VERTEX_SHADER,extras:{_pipeline:{source:A,extension:".glsl"}}}),oe=(0,s.Z)(x,{type:i.Z.FRAGMENT_SHADER,extras:{_pipeline:{source:S,extension:".glsl"}}}),ae=(0,s.Z)(C,{fragmentShader:oe,vertexShader:te});return(0,s.Z)(g,{attributes:k,program:ae,uniforms:W})}(e,d,p,f,t,n);(0,a.Z)(d.extensions)||(d.extensions={}),d.extensions.KHR_techniques_webgl={values:f,technique:u}})),d.Z.ensureSemanticExistence(e),e}},99841:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef MRT\n#extension GL_EXT_draw_buffers : enable\n#endif\n\nuniform vec4 u_bgColor;\nuniform sampler2D u_depthTexture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    if (texture2D(u_depthTexture, v_textureCoordinates).r < 1.0)\n    {\n#ifdef MRT\n        gl_FragData[0] = u_bgColor;\n        gl_FragData[1] = vec4(u_bgColor.a);\n#else\n        gl_FragColor = u_bgColor;\n#endif\n        return;\n    }\n    \n    discard;\n}\n"},69001:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec3 v_positionEC;\nvarying vec3 v_normalEC;\nvarying vec3 v_tangentEC;\nvarying vec3 v_bitangentEC;\nvarying vec2 v_st;\n\nvoid main()\n{\n    vec3 positionToEyeEC = -v_positionEC;\n    mat3 tangentToEyeMatrix = czm_tangentToEyeSpaceMatrix(v_normalEC, v_tangentEC, v_bitangentEC);\n\n    vec3 normalEC = normalize(v_normalEC);\n#ifdef FACE_FORWARD\n    normalEC = faceforward(normalEC, vec3(0.0, 0.0, 1.0), -normalEC);\n#endif\n\n    czm_materialInput materialInput;\n    materialInput.normalEC = normalEC;\n    materialInput.tangentToEyeMatrix = tangentToEyeMatrix;\n    materialInput.positionToEyeEC = positionToEyeEC;\n    materialInput.st = v_st;\n    czm_material material = czm_getMaterial(materialInput);\n\n#ifdef FLAT\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n#else\n    gl_FragColor = czm_phong(normalize(positionToEyeEC), material, czm_lightDirectionEC);\n#endif\n}\n"},76852:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute vec3 normal;\nattribute vec3 tangent;\nattribute vec3 bitangent;\nattribute vec2 st;\nattribute float batchId;\n\nvarying vec3 v_positionEC;\nvarying vec3 v_normalEC;\nvarying vec3 v_tangentEC;\nvarying vec3 v_bitangentEC;\nvarying vec2 v_st;\n\nvoid main()\n{\n    vec4 p = czm_computePosition();\n\n    v_positionEC = (czm_modelViewRelativeToEye * p).xyz;      // position in eye coordinates\n    v_normalEC = czm_normal * normal;                         // normal in eye coordinates\n    v_tangentEC = czm_normal * tangent;                       // tangent in eye coordinates\n    v_bitangentEC = czm_normal * bitangent;                   // bitangent in eye coordinates\n    v_st = st;\n\n    gl_Position = czm_modelViewProjectionRelativeToEye * p;\n}\n"},54343:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec3 v_positionEC;\nvarying vec3 v_normalEC;\n\nvoid main()\n{\n    vec3 positionToEyeEC = -v_positionEC;\n\n    vec3 normalEC = normalize(v_normalEC);\n#ifdef FACE_FORWARD\n    normalEC = faceforward(normalEC, vec3(0.0, 0.0, 1.0), -normalEC);\n#endif\n\n    czm_materialInput materialInput;\n    materialInput.normalEC = normalEC;\n    materialInput.positionToEyeEC = positionToEyeEC;\n    czm_material material = czm_getMaterial(materialInput);\n\n#ifdef FLAT\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n#else\n    gl_FragColor = czm_phong(normalize(positionToEyeEC), material, czm_lightDirectionEC);\n#endif\n}\n"},73777:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute vec3 normal;\nattribute float batchId;\n\nvarying vec3 v_positionEC;\nvarying vec3 v_normalEC;\n\nvoid main()\n{\n    vec4 p = czm_computePosition();\n\n    v_positionEC = (czm_modelViewRelativeToEye * p).xyz;      // position in eye coordinates\n    v_normalEC = czm_normal * normal;                         // normal in eye coordinates\n\n    gl_Position = czm_modelViewProjectionRelativeToEye * p;\n}\n"},28232:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec3 v_positionMC;\nvarying vec3 v_positionEC;\nvarying vec2 v_st;\n\nvoid main()\n{\n    czm_materialInput materialInput;\n\n    vec3 normalEC = normalize(czm_normal3D * czm_geodeticSurfaceNormal(v_positionMC, vec3(0.0), vec3(1.0)));\n#ifdef FACE_FORWARD\n    normalEC = faceforward(normalEC, vec3(0.0, 0.0, 1.0), -normalEC);\n#endif\n\n    materialInput.s = v_st.s;\n    materialInput.st = v_st;\n    materialInput.str = vec3(v_st, 0.0);\n\n    // Convert tangent space material normal to eye space\n    materialInput.normalEC = normalEC;\n    materialInput.tangentToEyeMatrix = czm_eastNorthUpToEyeCoordinates(v_positionMC, materialInput.normalEC);\n\n    // Convert view vector to world space\n    vec3 positionToEyeEC = -v_positionEC;\n    materialInput.positionToEyeEC = positionToEyeEC;\n\n    czm_material material = czm_getMaterial(materialInput);\n\n#ifdef FLAT\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n#else\n    gl_FragColor = czm_phong(normalize(positionToEyeEC), material, czm_lightDirectionEC);\n#endif\n}\n"},20134:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute vec2 st;\nattribute float batchId;\n\nvarying vec3 v_positionMC;\nvarying vec3 v_positionEC;\nvarying vec2 v_st;\n\nvoid main()\n{\n    vec4 p = czm_computePosition();\n\n    v_positionMC = position3DHigh + position3DLow;           // position in model coordinates\n    v_positionEC = (czm_modelViewRelativeToEye * p).xyz;     // position in eye coordinates\n    v_st = st;\n\n    gl_Position = czm_modelViewProjectionRelativeToEye * p;\n}\n"},99887:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec3 v_positionEC;\nvarying vec3 v_normalEC;\nvarying vec4 v_color;\n\nvoid main()\n{\n    vec3 positionToEyeEC = -v_positionEC;\n\n    vec3 normalEC = normalize(v_normalEC);\n#ifdef FACE_FORWARD\n    normalEC = faceforward(normalEC, vec3(0.0, 0.0, 1.0), -normalEC);\n#endif\n\n    vec4 color = czm_gammaCorrect(v_color);\n\n    czm_materialInput materialInput;\n    materialInput.normalEC = normalEC;\n    materialInput.positionToEyeEC = positionToEyeEC;\n    czm_material material = czm_getDefaultMaterial(materialInput);\n    material.diffuse = color.rgb;\n    material.alpha = color.a;\n\n    gl_FragColor = czm_phong(normalize(positionToEyeEC), material, czm_lightDirectionEC);\n}\n"},93365:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute vec3 normal;\nattribute vec4 color;\nattribute float batchId;\n\nvarying vec3 v_positionEC;\nvarying vec3 v_normalEC;\nvarying vec4 v_color;\n\nvoid main()\n{\n    vec4 p = czm_computePosition();\n\n    v_positionEC = (czm_modelViewRelativeToEye * p).xyz;      // position in eye coordinates\n    v_normalEC = czm_normal * normal;                         // normal in eye coordinates\n    v_color = color;\n\n    gl_Position = czm_modelViewProjectionRelativeToEye * p;\n}\n"},73175:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec4 v_color;\n\nvoid main()\n{\n    gl_FragColor = czm_gammaCorrect(v_color);\n}\n"},30431:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute vec4 color;\nattribute float batchId;\n\nvarying vec4 v_color;\n\nvoid main()\n{\n    vec4 p = czm_computePosition();\n\n    v_color = color;\n\n    gl_Position = czm_modelViewProjectionRelativeToEye * p;\n}\n"},11103:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute vec3 prevPosition3DHigh;\nattribute vec3 prevPosition3DLow;\nattribute vec3 nextPosition3DHigh;\nattribute vec3 nextPosition3DLow;\nattribute vec2 expandAndWidth;\nattribute vec4 color;\nattribute float batchId;\n\nvarying vec4 v_color;\n\nvoid main()\n{\n    float expandDir = expandAndWidth.x;\n    float width = abs(expandAndWidth.y) + 0.5;\n    bool usePrev = expandAndWidth.y < 0.0;\n\n    vec4 p = czm_computePosition();\n    vec4 prev = czm_computePrevPosition();\n    vec4 next = czm_computeNextPosition();\n\n    float angle;\n    vec4 positionWC = getPolylineWindowCoordinates(p, prev, next, expandDir, width, usePrev, angle);\n    gl_Position = czm_viewportOrthographic * positionWC;\n\n    v_color = color;\n}\n"},3159:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute vec3 prevPosition3DHigh;\nattribute vec3 prevPosition3DLow;\nattribute vec3 nextPosition3DHigh;\nattribute vec3 nextPosition3DLow;\nattribute vec2 expandAndWidth;\nattribute vec2 st;\nattribute float batchId;\n\nvarying float v_width;\nvarying vec2 v_st;\nvarying float v_polylineAngle;\n\nvoid main()\n{\n    float expandDir = expandAndWidth.x;\n    float width = abs(expandAndWidth.y) + 0.5;\n    bool usePrev = expandAndWidth.y < 0.0;\n\n    vec4 p = czm_computePosition();\n    vec4 prev = czm_computePrevPosition();\n    vec4 next = czm_computeNextPosition();\n\n    float angle;\n    vec4 positionWC = getPolylineWindowCoordinates(p, prev, next, expandDir, width, usePrev, angle);\n    gl_Position = czm_viewportOrthographic * positionWC;\n\n    v_width = width;\n    v_st.s = st.s;\n    v_st.t = czm_writeNonPerspective(st.t, gl_Position.w);\n    v_polylineAngle = angle;\n}\n"},87973:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec3 v_positionEC;\nvarying vec3 v_normalEC;\nvarying vec2 v_st;\n\nvoid main()\n{\n    vec3 positionToEyeEC = -v_positionEC;\n\n    vec3 normalEC = normalize(v_normalEC);\n#ifdef FACE_FORWARD\n    normalEC = faceforward(normalEC, vec3(0.0, 0.0, 1.0), -normalEC);\n#endif\n\n    czm_materialInput materialInput;\n    materialInput.normalEC = normalEC;\n    materialInput.positionToEyeEC = positionToEyeEC;\n    materialInput.st = v_st;\n    czm_material material = czm_getMaterial(materialInput);\n\n#ifdef FLAT\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n#else\n    gl_FragColor = czm_phong(normalize(positionToEyeEC), material, czm_lightDirectionEC);\n#endif\n}\n"},89809:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute vec3 normal;\nattribute vec2 st;\nattribute float batchId;\n\nvarying vec3 v_positionEC;\nvarying vec3 v_normalEC;\nvarying vec2 v_st;\n\nvoid main()\n{\n    vec4 p = czm_computePosition();\n\n    v_positionEC = (czm_modelViewRelativeToEye * p).xyz;      // position in eye coordinates\n    v_normalEC = czm_normal * normal;                         // normal in eye coordinates\n    v_st = st;\n\n    gl_Position = czm_modelViewProjectionRelativeToEye * p;\n}\n"},70444:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform vec3 u_radiiAndDynamicAtmosphereColor;\n\nuniform float u_atmosphereLightIntensity;\nuniform float u_atmosphereRayleighScaleHeight;\nuniform float u_atmosphereMieScaleHeight;\nuniform float u_atmosphereMieAnisotropy;\nuniform vec3 u_atmosphereRayleighCoefficient;\nuniform vec3 u_atmosphereMieCoefficient;\n\nconst float ATMOSPHERE_THICKNESS = 111e3; // The thickness of the atmosphere in meters.\nconst int PRIMARY_STEPS = 16; // Number of times the ray from the camera to the world position (primary ray) is sampled.\nconst int LIGHT_STEPS = 4; // Number of times the light is sampled from the light source's intersection with the atmosphere to a sample position on the primary ray.\n\n/**\n * This function computes the colors contributed by Rayliegh and Mie scattering on a given ray, as well as\n * the transmittance value for the ray.\n *\n * @param {czm_ray} primaryRay The ray from the camera to the position.\n * @param {float} primaryRayLength The length of the primary ray.\n * @param {vec3} lightDirection The direction of the light to calculate the scattering from.\n * @param {vec3} rayleighColor The variable the Rayleigh scattering will be written to.\n * @param {vec3} mieColor The variable the Mie scattering will be written to.\n * @param {float} opacity The variable the transmittance will be written to.\n * @glslFunction\n */\nvoid computeScattering(\n    czm_ray primaryRay,\n    float primaryRayLength,\n    vec3 lightDirection,\n    float atmosphereInnerRadius,\n    out vec3 rayleighColor,\n    out vec3 mieColor,\n    out float opacity\n) {\n\n    // Initialize the default scattering amounts to 0.\n    rayleighColor = vec3(0.0);\n    mieColor = vec3(0.0);\n    opacity = 0.0;\n\n    float atmosphereOuterRadius = atmosphereInnerRadius + ATMOSPHERE_THICKNESS;\n\n    vec3 origin = vec3(0.0);\n\n    // Calculate intersection from the camera to the outer ring of the atmosphere.\n    czm_raySegment primaryRayAtmosphereIntersect = czm_raySphereIntersectionInterval(primaryRay, origin, atmosphereOuterRadius);\n\n    // Return empty colors if no intersection with the atmosphere geometry.\n    if (primaryRayAtmosphereIntersect == czm_emptyRaySegment) {\n        return;\n    }\n\n    // The ray should start from the first intersection with the outer atmopshere, or from the camera position, if it is inside the atmosphere.\n    primaryRayAtmosphereIntersect.start = max(primaryRayAtmosphereIntersect.start, 0.0);\n    // The ray should end at the exit from the atmosphere or at the distance to the vertex, whichever is smaller.\n    primaryRayAtmosphereIntersect.stop = min(primaryRayAtmosphereIntersect.stop, length(primaryRayLength));\n\n    // Setup for sampling positions along the ray - starting from the intersection with the outer ring of the atmosphere.\n    float rayStepLength = (primaryRayAtmosphereIntersect.stop - primaryRayAtmosphereIntersect.start) / float(PRIMARY_STEPS);\n    float rayPositionLength = primaryRayAtmosphereIntersect.start;\n\n    vec3 rayleighAccumulation = vec3(0.0);\n    vec3 mieAccumulation = vec3(0.0);\n    vec2 opticalDepth = vec2(0.0);\n    vec2 heightScale = vec2(u_atmosphereRayleighScaleHeight, u_atmosphereMieScaleHeight);\n\n    // Sample positions on the primary ray.\n    for (int i = 0; i < PRIMARY_STEPS; i++) {\n        // Calculate sample position along viewpoint ray.\n        vec3 samplePosition = primaryRay.origin + primaryRay.direction * (rayPositionLength + rayStepLength);\n        \n        // Calculate height of sample position above ellipsoid.\n        float sampleHeight = length(samplePosition) - atmosphereInnerRadius;\n\n        // Calculate and accumulate density of particles at the sample position.\n        vec2 sampleDensity = exp(-sampleHeight / heightScale) * rayStepLength;\n        opticalDepth += sampleDensity;\n\n        // Generate ray from the sample position segment to the light source, up to the outer ring of the atmosphere.\n        czm_ray lightRay = czm_ray(samplePosition, lightDirection);\n        czm_raySegment lightRayAtmosphereIntersect = czm_raySphereIntersectionInterval(lightRay, origin, atmosphereOuterRadius);\n        \n        float lightStepLength = lightRayAtmosphereIntersect.stop / float(LIGHT_STEPS);\n        float lightPositionLength = 0.0;\n\n        vec2 lightOpticalDepth = vec2(0.0);\n\n        // Sample positions along the light ray, to accumulate incidence of light on the latest sample segment.\n        for (int j = 0; j < LIGHT_STEPS; j++) {\n\n            // Calculate sample position along light ray.\n            vec3 lightPosition = samplePosition + lightDirection * (lightPositionLength + lightStepLength * 0.5);\n\n            // Calculate height of the light sample position above ellipsoid.\n            float lightHeight = length(lightPosition) - atmosphereInnerRadius;\n\n            // Calculate density of photons at the light sample position.\n            lightOpticalDepth += exp(-lightHeight / heightScale) * lightStepLength;\n\n            // Increment distance on light ray.\n            lightPositionLength += lightStepLength;\n        }\n\n        // Compute attenuation via the primary ray and the light ray.\n        vec3 attenuation = exp(-((u_atmosphereMieCoefficient * (opticalDepth.y + lightOpticalDepth.y)) + (u_atmosphereRayleighCoefficient * (opticalDepth.x + lightOpticalDepth.x))));\n\n        // Accumulate the scattering.\n        rayleighAccumulation += sampleDensity.x * attenuation;\n        mieAccumulation += sampleDensity.y * attenuation;\n\n        // Increment distance on primary ray.\n        rayPositionLength += rayStepLength;\n    }\n\n    // Compute the scattering amount.\n    rayleighColor = u_atmosphereRayleighCoefficient * rayleighAccumulation;\n    mieColor = u_atmosphereMieCoefficient * mieAccumulation;\n\n    // Compute the transmittance i.e. how much light is passing through the atmosphere.\n    opacity = length(exp(-((u_atmosphereMieCoefficient * opticalDepth.y) + (u_atmosphereRayleighCoefficient * opticalDepth.x))));\n}\n\nvec4 computeAtmosphereColor(\n    vec3 positionWC,\n    vec3 lightDirection,\n    vec3 rayleighColor,\n    vec3 mieColor,\n    float opacity\n) {\n    // Setup the primary ray: from the camera position to the vertex position.\n    vec3 cameraToPositionWC = positionWC - czm_viewerPositionWC;\n    vec3 cameraToPositionWCDirection = normalize(cameraToPositionWC);\n\n    float cosAngle = dot(cameraToPositionWCDirection, lightDirection);\n    float cosAngleSq = cosAngle * cosAngle;\n\n    float G = u_atmosphereMieAnisotropy;\n    float GSq = G * G;\n\n    // The Rayleigh phase function.\n    float rayleighPhase = 3.0 / (50.2654824574) * (1.0 + cosAngleSq);\n    // The Mie phase function.\n    float miePhase = 3.0 / (25.1327412287) * ((1.0 - GSq) * (cosAngleSq + 1.0)) / (pow(1.0 + GSq - 2.0 * cosAngle * G, 1.5) * (2.0 + GSq));\n\n    // The final color is generated by combining the effects of the Rayleigh and Mie scattering.\n    vec3 rayleigh = rayleighPhase * rayleighColor;\n    vec3 mie = miePhase * mieColor;\n\n    vec3 color = (rayleigh + mie) * u_atmosphereLightIntensity;\n\n    return vec4(color, opacity);\n}\n"},92810:(e,n,t)=>{t.d(n,{Z:()=>o});const o='#ifdef GL_OES_standard_derivatives\n#extension GL_OES_standard_derivatives : enable\n#endif\n\nuniform sampler2D u_atlas;\n\n#ifdef VECTOR_TILE\nuniform vec4 u_highlightColor;\n#endif\n\nvarying vec2 v_textureCoordinates;\nvarying vec4 v_pickColor;\nvarying vec4 v_color;\n\n#ifdef SDF\nvarying vec4 v_outlineColor;\nvarying float v_outlineWidth;\n#endif\n\n#ifdef FRAGMENT_DEPTH_CHECK\nvarying vec4 v_textureCoordinateBounds;                  // the min and max x and y values for the texture coordinates\nvarying vec4 v_originTextureCoordinateAndTranslate;      // texture coordinate at the origin, billboard translate (used for label glyphs)\nvarying vec4 v_compressed;                               // x: eyeDepth, y: applyTranslate & enableDepthCheck, z: dimensions, w: imageSize\nvarying mat2 v_rotationMatrix;\n\nconst float SHIFT_LEFT12 = 4096.0;\nconst float SHIFT_LEFT1 = 2.0;\n\nconst float SHIFT_RIGHT12 = 1.0 / 4096.0;\nconst float SHIFT_RIGHT1 = 1.0 / 2.0;\n\nfloat getGlobeDepth(vec2 adjustedST, vec2 depthLookupST, bool applyTranslate, vec2 dimensions, vec2 imageSize)\n{\n    vec2 lookupVector = imageSize * (depthLookupST - adjustedST);\n    lookupVector = v_rotationMatrix * lookupVector;\n    vec2 labelOffset = (dimensions - imageSize) * (depthLookupST - vec2(0.0, v_originTextureCoordinateAndTranslate.y)); // aligns label glyph with bounding rectangle.  Will be zero for billboards because dimensions and imageSize will be equal\n\n    vec2 translation = v_originTextureCoordinateAndTranslate.zw;\n\n    if (applyTranslate)\n    {\n        // this is only needed for labels where the horizontal origin is not LEFT\n        // it moves the label back to where the "origin" should be since all label glyphs are set to HorizontalOrigin.LEFT\n        translation += (dimensions * v_originTextureCoordinateAndTranslate.xy * vec2(1.0, 0.0));\n    }\n\n    vec2 st = ((lookupVector - translation + labelOffset) + gl_FragCoord.xy) / czm_viewport.zw;\n    float logDepthOrDepth = czm_unpackDepth(texture2D(czm_globeDepthTexture, st));\n\n    if (logDepthOrDepth == 0.0)\n    {\n        return 0.0; // not on the globe\n    }\n\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(gl_FragCoord.xy, logDepthOrDepth);\n    return eyeCoordinate.z / eyeCoordinate.w;\n}\n#endif\n\n\n#ifdef SDF\n\n// Get the distance from the edge of a glyph at a given position sampling an SDF texture.\nfloat getDistance(vec2 position)\n{\n    return texture2D(u_atlas, position).r;\n}\n\n// Samples the sdf texture at the given position and produces a color based on the fill color and the outline.\nvec4 getSDFColor(vec2 position, float outlineWidth, vec4 outlineColor, float smoothing)\n{\n    float distance = getDistance(position);\n\n    if (outlineWidth > 0.0)\n    {\n        // Don\'t get the outline edge exceed the SDF_EDGE\n        float outlineEdge = clamp(SDF_EDGE - outlineWidth, 0.0, SDF_EDGE);\n        float outlineFactor = smoothstep(SDF_EDGE - smoothing, SDF_EDGE + smoothing, distance);\n        vec4 sdfColor = mix(outlineColor, v_color, outlineFactor);\n        float alpha = smoothstep(outlineEdge - smoothing, outlineEdge + smoothing, distance);\n        return vec4(sdfColor.rgb, sdfColor.a * alpha);\n    }\n    else\n    {\n        float alpha = smoothstep(SDF_EDGE - smoothing, SDF_EDGE + smoothing, distance);\n        return vec4(v_color.rgb, v_color.a * alpha);\n    }\n}\n#endif\n\nvoid main()\n{\n    vec4 color = texture2D(u_atlas, v_textureCoordinates);\n\n#ifdef SDF\n    float outlineWidth = v_outlineWidth;\n    vec4 outlineColor = v_outlineColor;\n\n    // Get the current distance\n    float distance = getDistance(v_textureCoordinates);\n\n#ifdef GL_OES_standard_derivatives\n    float smoothing = fwidth(distance);\n    // Get an offset that is approximately half the distance to the neighbor pixels\n    // 0.354 is approximately half of 1/sqrt(2)\n    vec2 sampleOffset = 0.354 * vec2(dFdx(v_textureCoordinates) + dFdy(v_textureCoordinates));\n\n    // Sample the center point\n    vec4 center = getSDFColor(v_textureCoordinates, outlineWidth, outlineColor, smoothing);\n\n    // Sample the 4 neighbors\n    vec4 color1 = getSDFColor(v_textureCoordinates + vec2(sampleOffset.x, sampleOffset.y), outlineWidth, outlineColor, smoothing);\n    vec4 color2 = getSDFColor(v_textureCoordinates + vec2(-sampleOffset.x, sampleOffset.y), outlineWidth, outlineColor, smoothing);\n    vec4 color3 = getSDFColor(v_textureCoordinates + vec2(-sampleOffset.x, -sampleOffset.y), outlineWidth, outlineColor, smoothing);\n    vec4 color4 = getSDFColor(v_textureCoordinates + vec2(sampleOffset.x, -sampleOffset.y), outlineWidth, outlineColor, smoothing);\n\n    // Equally weight the center sample and the 4 neighboring samples\n    color = (center + color1 + color2 + color3 + color4)/5.0;\n#else\n    // Just do a single sample\n    float smoothing = 1.0/32.0;\n    color = getSDFColor(v_textureCoordinates, outlineWidth, outlineColor, smoothing);\n#endif\n\n    color = czm_gammaCorrect(color);\n#else\n    color = czm_gammaCorrect(color);\n    color *= czm_gammaCorrect(v_color);\n#endif\n\n// Fully transparent parts of the billboard are not pickable.\n#if !defined(OPAQUE) && !defined(TRANSLUCENT)\n    if (color.a < 0.005)   // matches 0/255 and 1/255\n    {\n        discard;\n    }\n#else\n// The billboard is rendered twice. The opaque pass discards translucent fragments\n// and the translucent pass discards opaque fragments.\n#ifdef OPAQUE\n    if (color.a < 0.995)   // matches < 254/255\n    {\n        discard;\n    }\n#else\n    if (color.a >= 0.995)  // matches 254/255 and 255/255\n    {\n        discard;\n    }\n#endif\n#endif\n\n#ifdef VECTOR_TILE\n    color *= u_highlightColor;\n#endif\n    gl_FragColor = color;\n\n#ifdef LOG_DEPTH\n    czm_writeLogDepth();\n#endif\n\n#ifdef FRAGMENT_DEPTH_CHECK\n    float temp = v_compressed.y;\n\n    temp = temp * SHIFT_RIGHT1;\n\n    float temp2 = (temp - floor(temp)) * SHIFT_LEFT1;\n    bool enableDepthTest = temp2 != 0.0;\n    bool applyTranslate = floor(temp) != 0.0;\n\n    if (enableDepthTest) {\n        temp = v_compressed.z;\n        temp = temp * SHIFT_RIGHT12;\n\n        vec2 dimensions;\n        dimensions.y = (temp - floor(temp)) * SHIFT_LEFT12;\n        dimensions.x = floor(temp);\n\n        temp = v_compressed.w;\n        temp = temp * SHIFT_RIGHT12;\n\n        vec2 imageSize;\n        imageSize.y = (temp - floor(temp)) * SHIFT_LEFT12;\n        imageSize.x = floor(temp);\n\n        vec2 adjustedST = v_textureCoordinates - v_textureCoordinateBounds.xy;\n        adjustedST = adjustedST / vec2(v_textureCoordinateBounds.z - v_textureCoordinateBounds.x, v_textureCoordinateBounds.w - v_textureCoordinateBounds.y);\n\n        float epsilonEyeDepth = v_compressed.x + czm_epsilon1;\n        float globeDepth1 = getGlobeDepth(adjustedST, v_originTextureCoordinateAndTranslate.xy, applyTranslate, dimensions, imageSize);\n\n        // negative values go into the screen\n        if (globeDepth1 != 0.0 && globeDepth1 > epsilonEyeDepth)\n        {\n            float globeDepth2 = getGlobeDepth(adjustedST, vec2(0.0, 1.0), applyTranslate, dimensions, imageSize); // top left corner\n            if (globeDepth2 != 0.0 && globeDepth2 > epsilonEyeDepth)\n            {\n                float globeDepth3 = getGlobeDepth(adjustedST, vec2(1.0, 1.0), applyTranslate, dimensions, imageSize); // top right corner\n                if (globeDepth3 != 0.0 && globeDepth3 > epsilonEyeDepth)\n                {\n                    discard;\n                }\n            }\n        }\n    }\n#endif\n\n}\n'},60666:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef INSTANCED\nattribute vec2 direction;\n#endif\nattribute vec4 positionHighAndScale;\nattribute vec4 positionLowAndRotation;\nattribute vec4 compressedAttribute0;                       // pixel offset, translate, horizontal origin, vertical origin, show, direction, texture coordinates (texture offset)\nattribute vec4 compressedAttribute1;                       // aligned axis, translucency by distance, image width\nattribute vec4 compressedAttribute2;                       // label horizontal origin, image height, color, pick color, size in meters, valid aligned axis, 13 bits free\nattribute vec4 eyeOffset;                                  // eye offset in meters, 4 bytes free (texture range)\nattribute vec4 scaleByDistance;                            // near, nearScale, far, farScale\nattribute vec4 pixelOffsetScaleByDistance;                 // near, nearScale, far, farScale\nattribute vec4 compressedAttribute3;                       // distance display condition near, far, disableDepthTestDistance, dimensions\nattribute vec2 sdf;                                        // sdf outline color (rgb) and width (w)\n#if defined(VERTEX_DEPTH_CHECK) || defined(FRAGMENT_DEPTH_CHECK)\nattribute vec4 textureCoordinateBoundsOrLabelTranslate;    // the min and max x and y values for the texture coordinates\n#endif\n#ifdef VECTOR_TILE\nattribute float a_batchId;\n#endif\n\nvarying vec2 v_textureCoordinates;\n#ifdef FRAGMENT_DEPTH_CHECK\nvarying vec4 v_textureCoordinateBounds;\nvarying vec4 v_originTextureCoordinateAndTranslate;\nvarying vec4 v_compressed;                                 // x: eyeDepth, y: applyTranslate & enableDepthCheck, z: dimensions, w: imageSize\nvarying mat2 v_rotationMatrix;\n#endif\n\nvarying vec4 v_pickColor;\nvarying vec4 v_color;\n#ifdef SDF\nvarying vec4 v_outlineColor;\nvarying float v_outlineWidth;\n#endif\n\nconst float UPPER_BOUND = 32768.0;\n\nconst float SHIFT_LEFT16 = 65536.0;\nconst float SHIFT_LEFT12 = 4096.0;\nconst float SHIFT_LEFT8 = 256.0;\nconst float SHIFT_LEFT7 = 128.0;\nconst float SHIFT_LEFT5 = 32.0;\nconst float SHIFT_LEFT3 = 8.0;\nconst float SHIFT_LEFT2 = 4.0;\nconst float SHIFT_LEFT1 = 2.0;\n\nconst float SHIFT_RIGHT12 = 1.0 / 4096.0;\nconst float SHIFT_RIGHT8 = 1.0 / 256.0;\nconst float SHIFT_RIGHT7 = 1.0 / 128.0;\nconst float SHIFT_RIGHT5 = 1.0 / 32.0;\nconst float SHIFT_RIGHT3 = 1.0 / 8.0;\nconst float SHIFT_RIGHT2 = 1.0 / 4.0;\nconst float SHIFT_RIGHT1 = 1.0 / 2.0;\n\nvec4 addScreenSpaceOffset(vec4 positionEC, vec2 imageSize, float scale, vec2 direction, vec2 origin, vec2 translate, vec2 pixelOffset, vec3 alignedAxis, bool validAlignedAxis, float rotation, bool sizeInMeters, out mat2 rotationMatrix, out float mpp)\n{\n    // Note the halfSize cannot be computed in JavaScript because it is sent via\n    // compressed vertex attributes that coerce it to an integer.\n    vec2 halfSize = imageSize * scale * 0.5;\n    halfSize *= ((direction * 2.0) - 1.0);\n\n    vec2 originTranslate = origin * abs(halfSize);\n\n#if defined(ROTATION) || defined(ALIGNED_AXIS)\n    if (validAlignedAxis || rotation != 0.0)\n    {\n        float angle = rotation;\n        if (validAlignedAxis)\n        {\n            vec4 projectedAlignedAxis = czm_modelViewProjection * vec4(alignedAxis, 0.0);\n            angle += sign(-projectedAlignedAxis.x) * acos(sign(projectedAlignedAxis.y) * (projectedAlignedAxis.y * projectedAlignedAxis.y) /\n                    (projectedAlignedAxis.x * projectedAlignedAxis.x + projectedAlignedAxis.y * projectedAlignedAxis.y));\n        }\n\n        float cosTheta = cos(angle);\n        float sinTheta = sin(angle);\n        rotationMatrix = mat2(cosTheta, sinTheta, -sinTheta, cosTheta);\n        halfSize = rotationMatrix * halfSize;\n    }\n    else\n    {\n        rotationMatrix = mat2(1.0, 0.0, 0.0, 1.0);\n    }\n#endif\n\n    mpp = czm_metersPerPixel(positionEC);\n    positionEC.xy += (originTranslate + halfSize) * czm_branchFreeTernary(sizeInMeters, 1.0, mpp);\n    positionEC.xy += (translate + pixelOffset) * mpp;\n\n    return positionEC;\n}\n\n#ifdef VERTEX_DEPTH_CHECK\nfloat getGlobeDepth(vec4 positionEC)\n{\n    vec4 posWC = czm_eyeToWindowCoordinates(positionEC);\n\n    float globeDepth = czm_unpackDepth(texture2D(czm_globeDepthTexture, posWC.xy / czm_viewport.zw));\n\n    if (globeDepth == 0.0)\n    {\n        return 0.0; // not on the globe\n    }\n\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(posWC.xy, globeDepth);\n    return eyeCoordinate.z / eyeCoordinate.w;\n}\n#endif\nvoid main()\n{\n    // Modifying this shader may also require modifications to Billboard._computeScreenSpacePosition\n\n    // unpack attributes\n    vec3 positionHigh = positionHighAndScale.xyz;\n    vec3 positionLow = positionLowAndRotation.xyz;\n    float scale = positionHighAndScale.w;\n\n#if defined(ROTATION) || defined(ALIGNED_AXIS)\n    float rotation = positionLowAndRotation.w;\n#else\n    float rotation = 0.0;\n#endif\n\n    float compressed = compressedAttribute0.x;\n\n    vec2 pixelOffset;\n    pixelOffset.x = floor(compressed * SHIFT_RIGHT7);\n    compressed -= pixelOffset.x * SHIFT_LEFT7;\n    pixelOffset.x -= UPPER_BOUND;\n\n    vec2 origin;\n    origin.x = floor(compressed * SHIFT_RIGHT5);\n    compressed -= origin.x * SHIFT_LEFT5;\n\n    origin.y = floor(compressed * SHIFT_RIGHT3);\n    compressed -= origin.y * SHIFT_LEFT3;\n\n#ifdef FRAGMENT_DEPTH_CHECK\n    vec2 depthOrigin = origin.xy;\n#endif\n    origin -= vec2(1.0);\n\n    float show = floor(compressed * SHIFT_RIGHT2);\n    compressed -= show * SHIFT_LEFT2;\n\n#ifdef INSTANCED\n    vec2 textureCoordinatesBottomLeft = czm_decompressTextureCoordinates(compressedAttribute0.w);\n    vec2 textureCoordinatesRange = czm_decompressTextureCoordinates(eyeOffset.w);\n    vec2 textureCoordinates = textureCoordinatesBottomLeft + direction * textureCoordinatesRange;\n#else\n    vec2 direction;\n    direction.x = floor(compressed * SHIFT_RIGHT1);\n    direction.y = compressed - direction.x * SHIFT_LEFT1;\n\n    vec2 textureCoordinates = czm_decompressTextureCoordinates(compressedAttribute0.w);\n#endif\n\n    float temp = compressedAttribute0.y  * SHIFT_RIGHT8;\n    pixelOffset.y = -(floor(temp) - UPPER_BOUND);\n\n    vec2 translate;\n    translate.y = (temp - floor(temp)) * SHIFT_LEFT16;\n\n    temp = compressedAttribute0.z * SHIFT_RIGHT8;\n    translate.x = floor(temp) - UPPER_BOUND;\n\n    translate.y += (temp - floor(temp)) * SHIFT_LEFT8;\n    translate.y -= UPPER_BOUND;\n\n    temp = compressedAttribute1.x * SHIFT_RIGHT8;\n    float temp2 = floor(compressedAttribute2.w * SHIFT_RIGHT2);\n\n    vec2 imageSize = vec2(floor(temp), temp2);\n\n#ifdef FRAGMENT_DEPTH_CHECK\n    float labelHorizontalOrigin = floor(compressedAttribute2.w - (temp2 * SHIFT_LEFT2));\n    float applyTranslate = 0.0;\n    if (labelHorizontalOrigin != 0.0) // is a billboard, so set apply translate to false\n    {\n        applyTranslate = 1.0;\n        labelHorizontalOrigin -= 2.0;\n        depthOrigin.x = labelHorizontalOrigin + 1.0;\n    }\n\n    depthOrigin = vec2(1.0) - (depthOrigin * 0.5);\n#endif\n\n#ifdef EYE_DISTANCE_TRANSLUCENCY\n    vec4 translucencyByDistance;\n    translucencyByDistance.x = compressedAttribute1.z;\n    translucencyByDistance.z = compressedAttribute1.w;\n\n    translucencyByDistance.y = ((temp - floor(temp)) * SHIFT_LEFT8) / 255.0;\n\n    temp = compressedAttribute1.y * SHIFT_RIGHT8;\n    translucencyByDistance.w = ((temp - floor(temp)) * SHIFT_LEFT8) / 255.0;\n#endif\n\n#if defined(VERTEX_DEPTH_CHECK) || defined(FRAGMENT_DEPTH_CHECK)\n    temp = compressedAttribute3.w;\n    temp = temp * SHIFT_RIGHT12;\n\n    vec2 dimensions;\n    dimensions.y = (temp - floor(temp)) * SHIFT_LEFT12;\n    dimensions.x = floor(temp);\n#endif\n\n#ifdef ALIGNED_AXIS\n    vec3 alignedAxis = czm_octDecode(floor(compressedAttribute1.y * SHIFT_RIGHT8));\n    temp = compressedAttribute2.z * SHIFT_RIGHT5;\n    bool validAlignedAxis = (temp - floor(temp)) * SHIFT_LEFT1 > 0.0;\n#else\n    vec3 alignedAxis = vec3(0.0);\n    bool validAlignedAxis = false;\n#endif\n\n    vec4 pickColor;\n    vec4 color;\n\n    temp = compressedAttribute2.y;\n    temp = temp * SHIFT_RIGHT8;\n    pickColor.b = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    pickColor.g = (temp - floor(temp)) * SHIFT_LEFT8;\n    pickColor.r = floor(temp);\n\n    temp = compressedAttribute2.x;\n    temp = temp * SHIFT_RIGHT8;\n    color.b = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    color.g = (temp - floor(temp)) * SHIFT_LEFT8;\n    color.r = floor(temp);\n\n    temp = compressedAttribute2.z * SHIFT_RIGHT8;\n    bool sizeInMeters = floor((temp - floor(temp)) * SHIFT_LEFT7) > 0.0;\n    temp = floor(temp) * SHIFT_RIGHT8;\n\n    pickColor.a = (temp - floor(temp)) * SHIFT_LEFT8;\n    pickColor /= 255.0;\n\n    color.a = floor(temp);\n    color /= 255.0;\n\n    ///////////////////////////////////////////////////////////////////////////\n\n    vec4 p = czm_translateRelativeToEye(positionHigh, positionLow);\n    vec4 positionEC = czm_modelViewRelativeToEye * p;\n\n#if defined(FRAGMENT_DEPTH_CHECK) || defined(VERTEX_DEPTH_CHECK)\n    float eyeDepth = positionEC.z;\n#endif\n\n    positionEC = czm_eyeOffset(positionEC, eyeOffset.xyz);\n    positionEC.xyz *= show;\n\n    ///////////////////////////////////////////////////////////////////////////\n\n#if defined(EYE_DISTANCE_SCALING) || defined(EYE_DISTANCE_TRANSLUCENCY) || defined(EYE_DISTANCE_PIXEL_OFFSET) || defined(DISTANCE_DISPLAY_CONDITION) || defined(DISABLE_DEPTH_DISTANCE)\n    float lengthSq;\n    if (czm_sceneMode == czm_sceneMode2D)\n    {\n        // 2D camera distance is a special case\n        // treat all billboards as flattened to the z=0.0 plane\n        lengthSq = czm_eyeHeight2D.y;\n    }\n    else\n    {\n        lengthSq = dot(positionEC.xyz, positionEC.xyz);\n    }\n#endif\n\n#ifdef EYE_DISTANCE_SCALING\n    float distanceScale = czm_nearFarScalar(scaleByDistance, lengthSq);\n    scale *= distanceScale;\n    translate *= distanceScale;\n    // push vertex behind near plane for clipping\n    if (scale == 0.0)\n    {\n        positionEC.xyz = vec3(0.0);\n    }\n#endif\n\n    float translucency = 1.0;\n#ifdef EYE_DISTANCE_TRANSLUCENCY\n    translucency = czm_nearFarScalar(translucencyByDistance, lengthSq);\n    // push vertex behind near plane for clipping\n    if (translucency == 0.0)\n    {\n        positionEC.xyz = vec3(0.0);\n    }\n#endif\n\n#ifdef EYE_DISTANCE_PIXEL_OFFSET\n    float pixelOffsetScale = czm_nearFarScalar(pixelOffsetScaleByDistance, lengthSq);\n    pixelOffset *= pixelOffsetScale;\n#endif\n\n#ifdef DISTANCE_DISPLAY_CONDITION\n    float nearSq = compressedAttribute3.x;\n    float farSq = compressedAttribute3.y;\n    if (lengthSq < nearSq || lengthSq > farSq)\n    {\n        positionEC.xyz = vec3(0.0);\n    }\n#endif\n\n    mat2 rotationMatrix;\n    float mpp;\n\n#ifdef DISABLE_DEPTH_DISTANCE\n    float disableDepthTestDistance = compressedAttribute3.z;\n#endif\n\n#ifdef VERTEX_DEPTH_CHECK\nif (lengthSq < disableDepthTestDistance) {\n    float depthsilon = 10.0;\n\n    vec2 labelTranslate = textureCoordinateBoundsOrLabelTranslate.xy;\n    vec4 pEC1 = addScreenSpaceOffset(positionEC, dimensions, scale, vec2(0.0), origin, labelTranslate, pixelOffset, alignedAxis, validAlignedAxis, rotation, sizeInMeters, rotationMatrix, mpp);\n    float globeDepth1 = getGlobeDepth(pEC1);\n\n    if (globeDepth1 != 0.0 && pEC1.z + depthsilon < globeDepth1)\n    {\n        vec4 pEC2 = addScreenSpaceOffset(positionEC, dimensions, scale, vec2(0.0, 1.0), origin, labelTranslate, pixelOffset, alignedAxis, validAlignedAxis, rotation, sizeInMeters, rotationMatrix, mpp);\n        float globeDepth2 = getGlobeDepth(pEC2);\n\n        if (globeDepth2 != 0.0 && pEC2.z + depthsilon < globeDepth2)\n        {\n            vec4 pEC3 = addScreenSpaceOffset(positionEC, dimensions, scale, vec2(1.0), origin, labelTranslate, pixelOffset, alignedAxis, validAlignedAxis, rotation, sizeInMeters, rotationMatrix, mpp);\n            float globeDepth3 = getGlobeDepth(pEC3);\n            if (globeDepth3 != 0.0 && pEC3.z + depthsilon < globeDepth3)\n            {\n                positionEC.xyz = vec3(0.0);\n            }\n        }\n    }\n}\n#endif\n\n    positionEC = addScreenSpaceOffset(positionEC, imageSize, scale, direction, origin, translate, pixelOffset, alignedAxis, validAlignedAxis, rotation, sizeInMeters, rotationMatrix, mpp);\n    gl_Position = czm_projection * positionEC;\n    v_textureCoordinates = textureCoordinates;\n\n#ifdef LOG_DEPTH\n    czm_vertexLogDepth();\n#endif\n\n#ifdef DISABLE_DEPTH_DISTANCE\n    if (disableDepthTestDistance == 0.0 && czm_minimumDisableDepthTestDistance != 0.0)\n    {\n        disableDepthTestDistance = czm_minimumDisableDepthTestDistance;\n    }\n\n    if (disableDepthTestDistance != 0.0)\n    {\n        // Don't try to \"multiply both sides\" by w.  Greater/less-than comparisons won't work for negative values of w.\n        float zclip = gl_Position.z / gl_Position.w;\n        bool clipped = (zclip < -1.0 || zclip > 1.0);\n        if (!clipped && (disableDepthTestDistance < 0.0 || (lengthSq > 0.0 && lengthSq < disableDepthTestDistance)))\n        {\n            // Position z on the near plane.\n            gl_Position.z = -gl_Position.w;\n#ifdef LOG_DEPTH\n            v_depthFromNearPlusOne = 1.0;\n#endif\n        }\n    }\n#endif\n\n#ifdef FRAGMENT_DEPTH_CHECK\n    if (sizeInMeters) {\n        translate /= mpp;\n        dimensions /= mpp;\n        imageSize /= mpp;\n    }\n\n#if defined(ROTATION) || defined(ALIGNED_AXIS)\n    v_rotationMatrix = rotationMatrix;\n#else\n    v_rotationMatrix = mat2(1.0, 0.0, 0.0, 1.0);\n#endif\n\n    float enableDepthCheck = 0.0;\n    if (lengthSq < disableDepthTestDistance)\n    {\n        enableDepthCheck = 1.0;\n    }\n\n    float dw = floor(clamp(dimensions.x, 0.0, SHIFT_LEFT12));\n    float dh = floor(clamp(dimensions.y, 0.0, SHIFT_LEFT12));\n\n    float iw = floor(clamp(imageSize.x, 0.0, SHIFT_LEFT12));\n    float ih = floor(clamp(imageSize.y, 0.0, SHIFT_LEFT12));\n\n    v_compressed.x = eyeDepth;\n    v_compressed.y = applyTranslate * SHIFT_LEFT1 + enableDepthCheck;\n    v_compressed.z = dw * SHIFT_LEFT12 + dh;\n    v_compressed.w = iw * SHIFT_LEFT12 + ih;\n    v_originTextureCoordinateAndTranslate.xy = depthOrigin;\n    v_originTextureCoordinateAndTranslate.zw = translate;\n    v_textureCoordinateBounds = textureCoordinateBoundsOrLabelTranslate;\n\n#endif\n\n#ifdef SDF\n    vec4 outlineColor;\n    float outlineWidth;\n\n    temp = sdf.x;\n    temp = temp * SHIFT_RIGHT8;\n    outlineColor.b = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    outlineColor.g = (temp - floor(temp)) * SHIFT_LEFT8;\n    outlineColor.r = floor(temp);\n\n    temp = sdf.y;\n    temp = temp * SHIFT_RIGHT8;\n    float temp3 = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    outlineWidth = (temp - floor(temp)) * SHIFT_LEFT8;\n    outlineColor.a = floor(temp);\n    outlineColor /= 255.0;\n\n    v_outlineWidth = outlineWidth / 255.0;\n    v_outlineColor = outlineColor;\n    v_outlineColor.a *= translucency;\n#endif\n\n    v_pickColor = pickColor;\n\n    v_color = color;\n    v_color.a *= translucency;\n\n}\n"},59375:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec2 v_textureCoordinates;\nconst float M_PI = 3.141592653589793;\n\nfloat vdcRadicalInverse(int i)\n{\n    float r;\n    float base = 2.0;\n    float value = 0.0;\n    float invBase = 1.0 / base;\n    float invBi = invBase;\n    for (int x = 0; x < 100; x++)\n    {\n        if (i <= 0)\n        {\n            break;\n        }\n        r = mod(float(i), base);\n        value += r * invBi;\n        invBi *= invBase;\n        i = int(float(i) * invBase);\n    }\n    return value;\n}\n\nvec2 hammersley2D(int i, int N)\n{\n    return vec2(float(i) / float(N), vdcRadicalInverse(i));\n}\n\nvec3 importanceSampleGGX(vec2 xi, float roughness, vec3 N)\n{\n    float a = roughness * roughness;\n    float phi = 2.0 * M_PI * xi.x;\n    float cosTheta = sqrt((1.0 - xi.y) / (1.0 + (a * a - 1.0) * xi.y));\n    float sinTheta = sqrt(1.0 - cosTheta * cosTheta);\n    vec3 H = vec3(sinTheta * cos(phi), sinTheta * sin(phi), cosTheta);\n    vec3 upVector = abs(N.z) < 0.999 ? vec3(0.0, 0.0, 1.0) : vec3(1.0, 0.0, 0.0);\n    vec3 tangentX = normalize(cross(upVector, N));\n    vec3 tangentY = cross(N, tangentX);\n    return tangentX * H.x + tangentY * H.y + N * H.z;\n}\n\nfloat G1_Smith(float NdotV, float k)\n{\n    return NdotV / (NdotV * (1.0 - k) + k);\n}\n\nfloat G_Smith(float roughness, float NdotV, float NdotL)\n{\n    float k = roughness * roughness / 2.0;\n    return G1_Smith(NdotV, k) * G1_Smith(NdotL, k);\n}\n\nvec2 integrateBrdf(float roughness, float NdotV)\n{\n    vec3 V = vec3(sqrt(1.0 - NdotV * NdotV), 0.0, NdotV);\n    float A = 0.0;\n    float B = 0.0;\n    const int NumSamples = 1024;\n    for (int i = 0; i < NumSamples; i++)\n    {\n        vec2 xi = hammersley2D(i, NumSamples);\n        vec3 H = importanceSampleGGX(xi, roughness, vec3(0.0, 0.0, 1.0));\n        vec3 L = 2.0 * dot(V, H) * H - V;\n        float NdotL = clamp(L.z, 0.0, 1.0);\n        float NdotH = clamp(H.z, 0.0, 1.0);\n        float VdotH = clamp(dot(V, H), 0.0, 1.0);\n        if (NdotL > 0.0)\n        {\n            float G = G_Smith(roughness, NdotV, NdotL);\n            float G_Vis = G * VdotH / (NdotH * NdotV);\n            float Fc = pow(1.0 - VdotH, 5.0);\n            A += (1.0 - Fc) * G_Vis;\n            B += Fc * G_Vis;\n        }\n    }\n    return vec2(A, B) / float(NumSamples);\n}\n\nvoid main()\n{\n    gl_FragColor = vec4(integrateBrdf(v_textureCoordinates.y, v_textureCoordinates.x), 0.0, 1.0);\n}\n"},17909:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * A built-in GLSL floating-point constant for converting radians to degrees.\n *\n * @alias czm_degreesPerRadian\n * @glslConstant\n *\n * @see CesiumMath.DEGREES_PER_RADIAN\n *\n * @example\n * // GLSL declaration\n * const float czm_degreesPerRadian = ...;\n *\n * // Example\n * float deg = czm_degreesPerRadian * rad;\n */\nconst float czm_degreesPerRadian = 57.29577951308232;\n"},28399:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * A built-in GLSL vec2 constant for defining the depth range.\n * This is a workaround to a bug where IE11 does not implement gl_DepthRange.\n *\n * @alias czm_depthRange\n * @glslConstant\n *\n * @example\n * // GLSL declaration\n * float depthRangeNear = czm_depthRange.near;\n * float depthRangeFar = czm_depthRange.far;\n *\n */\nconst czm_depthRangeStruct czm_depthRange = czm_depthRangeStruct(0.0, 1.0);\n"},75984:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * 0.1\n *\n * @name czm_epsilon1\n * @glslConstant\n */\nconst float czm_epsilon1 = 0.1;\n"},32398:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * 0.01\n *\n * @name czm_epsilon2\n * @glslConstant\n */\nconst float czm_epsilon2 = 0.01;\n"},71518:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * 0.001\n *\n * @name czm_epsilon3\n * @glslConstant\n */\nconst float czm_epsilon3 = 0.001;\n"},8128:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * 0.0001\n *\n * @name czm_epsilon4\n * @glslConstant\n */\nconst float czm_epsilon4 = 0.0001;\n"},62692:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * 0.00001\n *\n * @name czm_epsilon5\n * @glslConstant\n */\nconst float czm_epsilon5 = 0.00001;\n"},71753:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * 0.000001\n *\n * @name czm_epsilon6\n * @glslConstant\n */\nconst float czm_epsilon6 = 0.000001;\n"},43808:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * 0.0000001\n *\n * @name czm_epsilon7\n * @glslConstant\n */\nconst float czm_epsilon7 = 0.0000001;\n"},58709:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * DOC_TBA\n *\n * @name czm_infinity\n * @glslConstant\n */\nconst float czm_infinity = 5906376272000.0;  // Distance from the Sun to Pluto in meters.  TODO: What is best given lowp, mediump, and highp?\n"},94249:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * A built-in GLSL floating-point constant for <code>1/pi</code>.\n *\n * @alias czm_oneOverPi\n * @glslConstant\n *\n * @see CesiumMath.ONE_OVER_PI\n *\n * @example\n * // GLSL declaration\n * const float czm_oneOverPi = ...;\n *\n * // Example\n * float pi = 1.0 / czm_oneOverPi;\n */\nconst float czm_oneOverPi = 0.3183098861837907;\n"},13390:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * A built-in GLSL floating-point constant for <code>1/2pi</code>.\n *\n * @alias czm_oneOverTwoPi\n * @glslConstant\n *\n * @see CesiumMath.ONE_OVER_TWO_PI\n *\n * @example\n * // GLSL declaration\n * const float czm_oneOverTwoPi = ...;\n *\n * // Example\n * float pi = 2.0 * czm_oneOverTwoPi;\n */\nconst float czm_oneOverTwoPi = 0.15915494309189535;\n"},19384:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The automatic GLSL constant for {@link Pass#CESIUM_3D_TILE}\n *\n * @name czm_passCesium3DTile\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passCesium3DTile = 4.0;\n"},35554:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The automatic GLSL constant for {@link Pass#CESIUM_3D_TILE_CLASSIFICATION}\n *\n * @name czm_passCesium3DTileClassification\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passCesium3DTileClassification = 5.0;\n"},98877:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The automatic GLSL constant for {@link Pass#CESIUM_3D_TILE_CLASSIFICATION_IGNORE_SHOW}\n *\n * @name czm_passCesium3DTileClassificationIgnoreShow\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passCesium3DTileClassificationIgnoreShow = 6.0;\n"},70893:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The automatic GLSL constant for {@link Pass#CLASSIFICATION}\n *\n * @name czm_passClassification\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passClassification = 7.0;\n"},27225:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The automatic GLSL constant for {@link Pass#COMPUTE}\n *\n * @name czm_passCompute\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passCompute = 1.0;\n"},333:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The automatic GLSL constant for {@link Pass#ENVIRONMENT}\n *\n * @name czm_passEnvironment\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passEnvironment = 0.0;\n"},38666:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The automatic GLSL constant for {@link Pass#GLOBE}\n *\n * @name czm_passGlobe\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passGlobe = 2.0;\n"},14356:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The automatic GLSL constant for {@link Pass#OPAQUE}\n *\n * @name czm_passOpaque\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passOpaque = 7.0;\n"},40076:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The automatic GLSL constant for {@link Pass#OVERLAY}\n *\n * @name czm_passOverlay\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passOverlay = 9.0;\n"},42721:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The automatic GLSL constant for {@link Pass#TERRAIN_CLASSIFICATION}\n *\n * @name czm_passTerrainClassification\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passTerrainClassification = 3.0;\n"},26018:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The automatic GLSL constant for {@link Pass#TRANSLUCENT}\n *\n * @name czm_passTranslucent\n * @glslConstant\n *\n * @see czm_pass\n */\nconst float czm_passTranslucent = 8.0;\n"},25851:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * A built-in GLSL floating-point constant for <code>Math.PI</code>.\n *\n * @alias czm_pi\n * @glslConstant\n *\n * @see CesiumMath.PI\n *\n * @example\n * // GLSL declaration\n * const float czm_pi = ...;\n *\n * // Example\n * float twoPi = 2.0 * czm_pi;\n */\nconst float czm_pi = 3.141592653589793;\n"},77465:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * A built-in GLSL floating-point constant for <code>pi/4</code>.\n *\n * @alias czm_piOverFour\n * @glslConstant\n *\n * @see CesiumMath.PI_OVER_FOUR\n *\n * @example\n * // GLSL declaration\n * const float czm_piOverFour = ...;\n *\n * // Example\n * float pi = 4.0 * czm_piOverFour;\n */\nconst float czm_piOverFour = 0.7853981633974483;\n"},6859:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * A built-in GLSL floating-point constant for <code>pi/6</code>.\n *\n * @alias czm_piOverSix\n * @glslConstant\n *\n * @see CesiumMath.PI_OVER_SIX\n *\n * @example\n * // GLSL declaration\n * const float czm_piOverSix = ...;\n *\n * // Example\n * float pi = 6.0 * czm_piOverSix;\n */\nconst float czm_piOverSix = 0.5235987755982988;\n"},9571:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * A built-in GLSL floating-point constant for <code>pi/3</code>.\n *\n * @alias czm_piOverThree\n * @glslConstant\n *\n * @see CesiumMath.PI_OVER_THREE\n *\n * @example\n * // GLSL declaration\n * const float czm_piOverThree = ...;\n *\n * // Example\n * float pi = 3.0 * czm_piOverThree;\n */\nconst float czm_piOverThree = 1.0471975511965976;\n"},37744:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * A built-in GLSL floating-point constant for <code>pi/2</code>.\n *\n * @alias czm_piOverTwo\n * @glslConstant\n *\n * @see CesiumMath.PI_OVER_TWO\n *\n * @example\n * // GLSL declaration\n * const float czm_piOverTwo = ...;\n *\n * // Example\n * float pi = 2.0 * czm_piOverTwo;\n */\nconst float czm_piOverTwo = 1.5707963267948966;\n"},22056:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * A built-in GLSL floating-point constant for converting degrees to radians.\n *\n * @alias czm_radiansPerDegree\n * @glslConstant\n *\n * @see CesiumMath.RADIANS_PER_DEGREE\n *\n * @example\n * // GLSL declaration\n * const float czm_radiansPerDegree = ...;\n *\n * // Example\n * float rad = czm_radiansPerDegree * deg;\n */\nconst float czm_radiansPerDegree = 0.017453292519943295;\n"},74829:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The constant identifier for the 2D {@link SceneMode}\n *\n * @name czm_sceneMode2D\n * @glslConstant\n * @see czm_sceneMode\n * @see czm_sceneModeColumbusView\n * @see czm_sceneMode3D\n * @see czm_sceneModeMorphing\n */\nconst float czm_sceneMode2D = 2.0;\n"},48366:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The constant identifier for the 3D {@link SceneMode}\n *\n * @name czm_sceneMode3D\n * @glslConstant\n * @see czm_sceneMode\n * @see czm_sceneMode2D\n * @see czm_sceneModeColumbusView\n * @see czm_sceneModeMorphing\n */\nconst float czm_sceneMode3D = 3.0;\n"},74078:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The constant identifier for the Columbus View {@link SceneMode}\n *\n * @name czm_sceneModeColumbusView\n * @glslConstant\n * @see czm_sceneMode\n * @see czm_sceneMode2D\n * @see czm_sceneMode3D\n * @see czm_sceneModeMorphing\n */\nconst float czm_sceneModeColumbusView = 1.0;\n"},88933:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The constant identifier for the Morphing {@link SceneMode}\n *\n * @name czm_sceneModeMorphing\n * @glslConstant\n * @see czm_sceneMode\n * @see czm_sceneMode2D\n * @see czm_sceneModeColumbusView\n * @see czm_sceneMode3D\n */\nconst float czm_sceneModeMorphing = 0.0;\n"},6825:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * A built-in GLSL floating-point constant for one solar radius.\n *\n * @alias czm_solarRadius\n * @glslConstant\n *\n * @see CesiumMath.SOLAR_RADIUS\n *\n * @example\n * // GLSL declaration\n * const float czm_solarRadius = ...;\n */\nconst float czm_solarRadius = 695500000.0;\n"},64263:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * A built-in GLSL floating-point constant for <code>3pi/2</code>.\n *\n * @alias czm_threePiOver2\n * @glslConstant\n *\n * @see CesiumMath.THREE_PI_OVER_TWO\n *\n * @example\n * // GLSL declaration\n * const float czm_threePiOver2 = ...;\n *\n * // Example\n * float pi = (2.0 / 3.0) * czm_threePiOver2;\n */\nconst float czm_threePiOver2 = 4.71238898038469;\n"},49005:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * A built-in GLSL floating-point constant for <code>2pi</code>.\n *\n * @alias czm_twoPi\n * @glslConstant\n *\n * @see CesiumMath.TWO_PI\n *\n * @example\n * // GLSL declaration\n * const float czm_twoPi = ...;\n *\n * // Example\n * float pi = czm_twoPi / 2.0;\n */\nconst float czm_twoPi = 6.283185307179586;\n"},16770:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * The maximum latitude, in radians, both North and South, supported by a Web Mercator\n * (EPSG:3857) projection.  Technically, the Mercator projection is defined\n * for any latitude up to (but not including) 90 degrees, but it makes sense\n * to cut it off sooner because it grows exponentially with increasing latitude.\n * The logic behind this particular cutoff value, which is the one used by\n * Google Maps, Bing Maps, and Esri, is that it makes the projection\n * square.  That is, the rectangle is equal in the X and Y directions.\n *\n * The constant value is computed as follows:\n *   czm_pi * 0.5 - (2.0 * atan(exp(-czm_pi)))\n *\n * @name czm_webMercatorMaxLatitude\n * @glslConstant\n */\nconst float czm_webMercatorMaxLatitude = 1.4844222297453324;\n"},14191:(e,n,t)=>{t.d(n,{Z:()=>bn});var o=t(17909),a=t(28399),i=t(75984),r=t(32398),s=t(71518),l=t(8128),c=t(62692),d=t(71753),m=t(43808),p=t(58709),f=t(94249),u=t(13390),h=t(19384),v=t(35554),_=t(98877),g=t(70893),x=t(27225),C=t(333),y=t(38666),T=t(14356),z=t(40076),E=t(42721),b=t(26018),A=t(25851),S=t(77465),D=t(6859),w=t(9571),P=t(37744),I=t(22056),F=t(74829),L=t(48366),N=t(74078),R=t(88933),O=t(6825),M=t(64263),Z=t(49005),H=t(16770),G=t(42103),U=t(64808),W=t(56553),B=t(22106),V=t(92629),X=t(70193),k=t(39524),Y=t(5878),q=t(78531),Q=t(8652),j=t(13982),$=t(88984),K=t(16485),J=t(1260),ee=t(51403),ne=t(55292),te=t(39057),oe=t(25880),ae=t(68168),ie=t(90721),re=t(58453),se=t(73163),le=t(79984),ce=t(63491),de=t(82391),me=t(77147),pe=t(79917),fe=t(93922),ue=t(66310),he=t(62099),ve=t(6974),_e=t(26628),ge=t(53979),xe=t(74341),Ce=t(73963),ye=t(65177),Te=t(6129),ze=t(48192),Ee=t(78106),be=t(98490),Ae=t(34582),Se=t(88255),De=t(22060),we=t(89920),Pe=t(68550),Ie=t(75510),Fe=t(69871),Le=t(25666),Ne=t(7776),Re=t(25094),Oe=t(10093),Me=t(72996),Ze=t(56898),He=t(27392),Ge=t(23777),Ue=t(68130),We=t(66040),Be=t(37447),Ve=t(23782),Xe=t(57549),ke=t(50016),Ye=t(14576),qe=t(17578),Qe=t(56508),je=t(89479),$e=t(48297),Ke=t(2128),Je=t(61626),en=t(84308),nn=t(94351),tn=t(78866),on=t(58445),an=t(51679),rn=t(7205),sn=t(85724),ln=t(23582),cn=t(87370),dn=t(87446),mn=t(12275),pn=t(11471),fn=t(39391),un=t(78938),hn=t(40443),vn=t(38033),_n=t(21285),gn=t(32419),xn=t(30089),Cn=t(20355),yn=t(97283),Tn=t(37088),zn=t(5417),En=t(10548);const bn={czm_degreesPerRadian:o.Z,czm_depthRange:a.Z,czm_epsilon1:i.Z,czm_epsilon2:r.Z,czm_epsilon3:s.Z,czm_epsilon4:l.Z,czm_epsilon5:c.Z,czm_epsilon6:d.Z,czm_epsilon7:m.Z,czm_infinity:p.Z,czm_oneOverPi:f.Z,czm_oneOverTwoPi:u.Z,czm_passCesium3DTile:h.Z,czm_passCesium3DTileClassification:v.Z,czm_passCesium3DTileClassificationIgnoreShow:_.Z,czm_passClassification:g.Z,czm_passCompute:x.Z,czm_passEnvironment:C.Z,czm_passGlobe:y.Z,czm_passOpaque:T.Z,czm_passOverlay:z.Z,czm_passTerrainClassification:E.Z,czm_passTranslucent:b.Z,czm_pi:A.Z,czm_piOverFour:S.Z,czm_piOverSix:D.Z,czm_piOverThree:w.Z,czm_piOverTwo:P.Z,czm_radiansPerDegree:I.Z,czm_sceneMode2D:F.Z,czm_sceneMode3D:L.Z,czm_sceneModeColumbusView:N.Z,czm_sceneModeMorphing:R.Z,czm_solarRadius:O.Z,czm_threePiOver2:M.Z,czm_twoPi:Z.Z,czm_webMercatorMaxLatitude:H.Z,czm_depthRangeStruct:G.Z,czm_material:U.Z,czm_materialInput:W.Z,czm_modelMaterial:B.Z,czm_modelVertexOutput:V.Z,czm_pbrParameters:X.Z,czm_ray:k.Z,czm_raySegment:Y.Z,czm_shadowParameters:q.Z,czm_HSBToRGB:Q.Z,czm_HSLToRGB:j.Z,czm_RGBToHSB:$.Z,czm_RGBToHSL:K.Z,czm_RGBToXYZ:J.Z,czm_XYZToRGB:ee.Z,czm_acesTonemapping:ne.Z,czm_alphaWeight:te.Z,czm_antialias:oe.Z,czm_approximateSphericalCoordinates:ae.Z,czm_backFacing:ie.Z,czm_branchFreeTernary:re.Z,czm_cascadeColor:se.Z,czm_cascadeDistance:le.Z,czm_cascadeMatrix:ce.Z,czm_cascadeWeights:de.Z,czm_columbusViewMorph:me.Z,czm_computePosition:pe.Z,czm_cosineAndSine:fe.Z,czm_decompressTextureCoordinates:ue.Z,czm_defaultPbrMaterial:he.Z,czm_depthClamp:ve.Z,czm_eastNorthUpToEyeCoordinates:_e.Z,czm_ellipsoidContainsPoint:ge.Z,czm_ellipsoidWgs84TextureCoordinates:xe.Z,czm_equalsEpsilon:Ce.Z,czm_eyeOffset:ye.Z,czm_eyeToWindowCoordinates:Te.Z,czm_fastApproximateAtan:ze.Z,czm_fog:Ee.Z,czm_gammaCorrect:be.Z,czm_geodeticSurfaceNormal:Ae.Z,czm_getDefaultMaterial:Se.Z,czm_getLambertDiffuse:De.Z,czm_getSpecular:we.Z,czm_getWaterNoise:Pe.Z,czm_hue:Ie.Z,czm_inverseGamma:Fe.Z,czm_isEmpty:Le.Z,czm_isFull:Ne.Z,czm_latitudeToWebMercatorFraction:Re.Z,czm_lineDistance:Oe.Z,czm_linearToSrgb:Me.Z,czm_luminance:Ze.Z,czm_metersPerPixel:He.Z,czm_modelToWindowCoordinates:Ge.Z,czm_multiplyWithColorBalance:Ue.Z,czm_nearFarScalar:We.Z,czm_octDecode:Be.Z,czm_packDepth:Ve.Z,czm_pbrLighting:Xe.Z,czm_pbrMetallicRoughnessMaterial:ke.Z,czm_pbrSpecularGlossinessMaterial:Ye.Z,czm_phong:qe.Z,czm_planeDistance:Qe.Z,czm_pointAlongRay:je.Z,czm_rayEllipsoidIntersectionInterval:$e.Z,czm_raySphereIntersectionInterval:Ke.Z,czm_readDepth:Je.Z,czm_readNonPerspective:en.Z,czm_reverseLogDepth:nn.Z,czm_round:tn.Z,czm_sampleOctahedralProjection:on.Z,czm_saturation:an.Z,czm_shadowDepthCompare:rn.Z,czm_shadowVisibility:sn.Z,czm_signNotZero:ln.Z,czm_sphericalHarmonics:cn.Z,czm_srgbToLinear:dn.Z,czm_tangentToEyeSpaceMatrix:mn.Z,czm_transformPlane:pn.Z,czm_translateRelativeToEye:fn.Z,czm_translucentPhong:un.Z,czm_transpose:hn.Z,czm_unpackDepth:vn.Z,czm_unpackFloat:_n.Z,czm_unpackUint:gn.Z,czm_valueTransform:xn.Z,czm_vertexLogDepth:Cn.Z,czm_windowToEyeCoordinates:yn.Z,czm_writeDepthClamp:Tn.Z,czm_writeLogDepth:zn.Z,czm_writeNonPerspective:En.Z}},8652:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Converts an HSB color (hue, saturation, brightness) to RGB\n * HSB <-> RGB conversion with minimal branching: {@link http://lolengine.net/blog/2013/07/27/rgb-to-hsv-in-glsl}\n *\n * @name czm_HSBToRGB\n * @glslFunction\n * \n * @param {vec3} hsb The color in HSB.\n *\n * @returns {vec3} The color in RGB.\n *\n * @example\n * vec3 hsb = czm_RGBToHSB(rgb);\n * hsb.z *= 0.1;\n * rgb = czm_HSBToRGB(hsb);\n */\n\nconst vec4 K_HSB2RGB = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);\n\nvec3 czm_HSBToRGB(vec3 hsb)\n{\n    vec3 p = abs(fract(hsb.xxx + K_HSB2RGB.xyz) * 6.0 - K_HSB2RGB.www);\n    return hsb.z * mix(K_HSB2RGB.xxx, clamp(p - K_HSB2RGB.xxx, 0.0, 1.0), hsb.y);\n}\n"},13982:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Converts an HSL color (hue, saturation, lightness) to RGB\n * HSL <-> RGB conversion: {@link http://www.chilliant.com/rgb2hsv.html}\n *\n * @name czm_HSLToRGB\n * @glslFunction\n * \n * @param {vec3} rgb The color in HSL.\n *\n * @returns {vec3} The color in RGB.\n *\n * @example\n * vec3 hsl = czm_RGBToHSL(rgb);\n * hsl.z *= 0.1;\n * rgb = czm_HSLToRGB(hsl);\n */\n\nvec3 hueToRGB(float hue)\n{\n    float r = abs(hue * 6.0 - 3.0) - 1.0;\n    float g = 2.0 - abs(hue * 6.0 - 2.0);\n    float b = 2.0 - abs(hue * 6.0 - 4.0);\n    return clamp(vec3(r, g, b), 0.0, 1.0);\n}\n\nvec3 czm_HSLToRGB(vec3 hsl)\n{\n    vec3 rgb = hueToRGB(hsl.x);\n    float c = (1.0 - abs(2.0 * hsl.z - 1.0)) * hsl.y;\n    return (rgb - 0.5) * c + hsl.z;\n}\n"},88984:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Converts an RGB color to HSB (hue, saturation, brightness)\n * HSB <-> RGB conversion with minimal branching: {@link http://lolengine.net/blog/2013/07/27/rgb-to-hsv-in-glsl}\n *\n * @name czm_RGBToHSB\n * @glslFunction\n * \n * @param {vec3} rgb The color in RGB.\n *\n * @returns {vec3} The color in HSB.\n *\n * @example\n * vec3 hsb = czm_RGBToHSB(rgb);\n * hsb.z *= 0.1;\n * rgb = czm_HSBToRGB(hsb);\n */\n\nconst vec4 K_RGB2HSB = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);\n\nvec3 czm_RGBToHSB(vec3 rgb)\n{\n    vec4 p = mix(vec4(rgb.bg, K_RGB2HSB.wz), vec4(rgb.gb, K_RGB2HSB.xy), step(rgb.b, rgb.g));\n    vec4 q = mix(vec4(p.xyw, rgb.r), vec4(rgb.r, p.yzx), step(p.x, rgb.r));\n\n    float d = q.x - min(q.w, q.y);\n    return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + czm_epsilon7)), d / (q.x + czm_epsilon7), q.x);\n}\n"},16485:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Converts an RGB color to HSL (hue, saturation, lightness)\n * HSL <-> RGB conversion: {@link http://www.chilliant.com/rgb2hsv.html}\n *\n * @name czm_RGBToHSL\n * @glslFunction\n * \n * @param {vec3} rgb The color in RGB.\n *\n * @returns {vec3} The color in HSL.\n *\n * @example\n * vec3 hsl = czm_RGBToHSL(rgb);\n * hsl.z *= 0.1;\n * rgb = czm_HSLToRGB(hsl);\n */\n \nvec3 RGBtoHCV(vec3 rgb)\n{\n    // Based on work by Sam Hocevar and Emil Persson\n    vec4 p = (rgb.g < rgb.b) ? vec4(rgb.bg, -1.0, 2.0 / 3.0) : vec4(rgb.gb, 0.0, -1.0 / 3.0);\n    vec4 q = (rgb.r < p.x) ? vec4(p.xyw, rgb.r) : vec4(rgb.r, p.yzx);\n    float c = q.x - min(q.w, q.y);\n    float h = abs((q.w - q.y) / (6.0 * c + czm_epsilon7) + q.z);\n    return vec3(h, c, q.x);\n}\n\nvec3 czm_RGBToHSL(vec3 rgb)\n{\n    vec3 hcv = RGBtoHCV(rgb);\n    float l = hcv.z - hcv.y * 0.5;\n    float s = hcv.y / (1.0 - abs(l * 2.0 - 1.0) + czm_epsilon7);\n    return vec3(hcv.x, s, l);\n}\n"},1260:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Converts an RGB color to CIE Yxy.\n * <p>The conversion is described in\n * {@link http://content.gpwiki.org/index.php/D3DBook:High-Dynamic_Range_Rendering#Luminance_Transform|Luminance Transform}\n * </p>\n * \n * @name czm_RGBToXYZ\n * @glslFunction\n * \n * @param {vec3} rgb The color in RGB.\n *\n * @returns {vec3} The color in CIE Yxy.\n *\n * @example\n * vec3 xyz = czm_RGBToXYZ(rgb);\n * xyz.x = max(xyz.x - luminanceThreshold, 0.0);\n * rgb = czm_XYZToRGB(xyz);\n */\nvec3 czm_RGBToXYZ(vec3 rgb)\n{\n    const mat3 RGB2XYZ = mat3(0.4124, 0.2126, 0.0193,\n                              0.3576, 0.7152, 0.1192,\n                              0.1805, 0.0722, 0.9505);\n    vec3 xyz = RGB2XYZ * rgb;\n    vec3 Yxy;\n    Yxy.r = xyz.g;\n    float temp = dot(vec3(1.0), xyz);\n    Yxy.gb = xyz.rg / temp;\n    return Yxy;\n}\n"},51403:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Converts a CIE Yxy color to RGB.\n * <p>The conversion is described in\n * {@link http://content.gpwiki.org/index.php/D3DBook:High-Dynamic_Range_Rendering#Luminance_Transform|Luminance Transform}\n * </p>\n * \n * @name czm_XYZToRGB\n * @glslFunction\n * \n * @param {vec3} Yxy The color in CIE Yxy.\n *\n * @returns {vec3} The color in RGB.\n *\n * @example\n * vec3 xyz = czm_RGBToXYZ(rgb);\n * xyz.x = max(xyz.x - luminanceThreshold, 0.0);\n * rgb = czm_XYZToRGB(xyz);\n */\nvec3 czm_XYZToRGB(vec3 Yxy)\n{\n    const mat3 XYZ2RGB = mat3( 3.2405, -0.9693,  0.0556,\n                              -1.5371,  1.8760, -0.2040,\n                              -0.4985,  0.0416,  1.0572);\n    vec3 xyz;\n    xyz.r = Yxy.r * Yxy.g / Yxy.b;\n    xyz.g = Yxy.r;\n    xyz.b = Yxy.r * (1.0 - Yxy.g - Yxy.b) / Yxy.b;\n    \n    return XYZ2RGB * xyz;\n}\n"},55292:(e,n,t)=>{t.d(n,{Z:()=>o});const o="// See:\n//    https://knarkowicz.wordpress.com/2016/01/06/aces-filmic-tone-mapping-curve/\n\nvec3 czm_acesTonemapping(vec3 color) {\n    float g = 0.985;\n    float a = 0.065;\n    float b = 0.0001;\n    float c = 0.433;\n    float d = 0.238;\n\n    color = (color * (color + a) - b) / (color * (g * color + c) + d);\n\n    color = clamp(color, 0.0, 1.0);\n\n    return color;\n}\n"},39057:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * @private\n */\nfloat czm_alphaWeight(float a)\n{\n    float z = (gl_FragCoord.z - czm_viewportTransformation[3][2]) / czm_viewportTransformation[2][2];\n\n    // See Weighted Blended Order-Independent Transparency for examples of different weighting functions:\n    // http://jcgt.org/published/0002/02/09/\n    return pow(a + 0.01, 4.0) + max(1e-2, min(3.0 * 1e3, 0.003 / (1e-5 + pow(abs(z) / 200.0, 4.0))));\n}\n"},25880:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Procedural anti-aliasing by blurring two colors that meet at a sharp edge.\n *\n * @name czm_antialias\n * @glslFunction\n *\n * @param {vec4} color1 The color on one side of the edge.\n * @param {vec4} color2 The color on the other side of the edge.\n * @param {vec4} currentcolor The current color, either <code>color1</code> or <code>color2</code>.\n * @param {float} dist The distance to the edge in texture coordinates.\n * @param {float} [fuzzFactor=0.1] Controls the blurriness between the two colors.\n * @returns {vec4} The anti-aliased color.\n *\n * @example\n * // GLSL declarations\n * vec4 czm_antialias(vec4 color1, vec4 color2, vec4 currentColor, float dist, float fuzzFactor);\n * vec4 czm_antialias(vec4 color1, vec4 color2, vec4 currentColor, float dist);\n *\n * // get the color for a material that has a sharp edge at the line y = 0.5 in texture space\n * float dist = abs(textureCoordinates.t - 0.5);\n * vec4 currentColor = mix(bottomColor, topColor, step(0.5, textureCoordinates.t));\n * vec4 color = czm_antialias(bottomColor, topColor, currentColor, dist, 0.1);\n */\nvec4 czm_antialias(vec4 color1, vec4 color2, vec4 currentColor, float dist, float fuzzFactor)\n{\n    float val1 = clamp(dist / fuzzFactor, 0.0, 1.0);\n    float val2 = clamp((dist - 0.5) / fuzzFactor, 0.0, 1.0);\n    val1 = val1 * (1.0 - val2);\n    val1 = val1 * val1 * (3.0 - (2.0 * val1));\n    val1 = pow(val1, 0.5); //makes the transition nicer\n    \n    vec4 midColor = (color1 + color2) * 0.5;\n    return mix(midColor, currentColor, val1);\n}\n\nvec4 czm_antialias(vec4 color1, vec4 color2, vec4 currentColor, float dist)\n{\n    return czm_antialias(color1, color2, currentColor, dist, 0.1);\n}\n"},68168:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Approximately computes spherical coordinates given a normal.\n * Uses approximate inverse trigonometry for speed and consistency,\n * since inverse trigonometry can differ from vendor-to-vendor and when compared with the CPU.\n *\n * @name czm_approximateSphericalCoordinates\n * @glslFunction\n *\n * @param {vec3} normal arbitrary-length normal.\n *\n * @returns {vec2} Approximate latitude and longitude spherical coordinates.\n */\nvec2 czm_approximateSphericalCoordinates(vec3 normal) {\n    // Project into plane with vertical for latitude\n    float latitudeApproximation = czm_fastApproximateAtan(sqrt(normal.x * normal.x + normal.y * normal.y), normal.z);\n    float longitudeApproximation = czm_fastApproximateAtan(normal.x, normal.y);\n    return vec2(latitudeApproximation, longitudeApproximation);\n}\n"},90721:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Determines if the fragment is back facing\n *\n * @name czm_backFacing\n * @glslFunction \n * \n * @returns {bool} <code>true</code> if the fragment is back facing; otherwise, <code>false</code>.\n */\nbool czm_backFacing()\n{\n    // !gl_FrontFacing doesn't work as expected on Mac/Intel so use the more verbose form instead. See https://github.com/CesiumGS/cesium/pull/8494.\n    return gl_FrontFacing == false;\n}\n"},58453:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Branchless ternary operator to be used when it's inexpensive to explicitly\n * evaluate both possibilities for a float expression.\n *\n * @name czm_branchFreeTernary\n * @glslFunction\n *\n * @param {bool} comparison A comparison statement\n * @param {float} a Value to return if the comparison is true.\n * @param {float} b Value to return if the comparison is false.\n *\n * @returns {float} equivalent of comparison ? a : b\n */\nfloat czm_branchFreeTernary(bool comparison, float a, float b) {\n    float useA = float(comparison);\n    return a * useA + b * (1.0 - useA);\n}\n\n/**\n * Branchless ternary operator to be used when it's inexpensive to explicitly\n * evaluate both possibilities for a vec2 expression.\n *\n * @name czm_branchFreeTernary\n * @glslFunction\n *\n * @param {bool} comparison A comparison statement\n * @param {vec2} a Value to return if the comparison is true.\n * @param {vec2} b Value to return if the comparison is false.\n *\n * @returns {vec2} equivalent of comparison ? a : b\n */\nvec2 czm_branchFreeTernary(bool comparison, vec2 a, vec2 b) {\n    float useA = float(comparison);\n    return a * useA + b * (1.0 - useA);\n}\n\n/**\n * Branchless ternary operator to be used when it's inexpensive to explicitly\n * evaluate both possibilities for a vec3 expression.\n *\n * @name czm_branchFreeTernary\n * @glslFunction\n *\n * @param {bool} comparison A comparison statement\n * @param {vec3} a Value to return if the comparison is true.\n * @param {vec3} b Value to return if the comparison is false.\n *\n * @returns {vec3} equivalent of comparison ? a : b\n */\nvec3 czm_branchFreeTernary(bool comparison, vec3 a, vec3 b) {\n    float useA = float(comparison);\n    return a * useA + b * (1.0 - useA);\n}\n\n/**\n * Branchless ternary operator to be used when it's inexpensive to explicitly\n * evaluate both possibilities for a vec4 expression.\n *\n * @name czm_branchFreeTernary\n * @glslFunction\n *\n * @param {bool} comparison A comparison statement\n * @param {vec3} a Value to return if the comparison is true.\n * @param {vec3} b Value to return if the comparison is false.\n *\n * @returns {vec3} equivalent of comparison ? a : b\n */\nvec4 czm_branchFreeTernary(bool comparison, vec4 a, vec4 b) {\n    float useA = float(comparison);\n    return a * useA + b * (1.0 - useA);\n}\n"},73163:(e,n,t)=>{t.d(n,{Z:()=>o});const o="\nvec4 czm_cascadeColor(vec4 weights)\n{\n    return vec4(1.0, 0.0, 0.0, 1.0) * weights.x +\n           vec4(0.0, 1.0, 0.0, 1.0) * weights.y +\n           vec4(0.0, 0.0, 1.0, 1.0) * weights.z +\n           vec4(1.0, 0.0, 1.0, 1.0) * weights.w;\n}\n"},79984:(e,n,t)=>{t.d(n,{Z:()=>o});const o="\nuniform vec4 shadowMap_cascadeDistances;\n\nfloat czm_cascadeDistance(vec4 weights)\n{\n    return dot(shadowMap_cascadeDistances, weights);\n}\n"},63491:(e,n,t)=>{t.d(n,{Z:()=>o});const o="\nuniform mat4 shadowMap_cascadeMatrices[4];\n\nmat4 czm_cascadeMatrix(vec4 weights)\n{\n    return shadowMap_cascadeMatrices[0] * weights.x +\n           shadowMap_cascadeMatrices[1] * weights.y +\n           shadowMap_cascadeMatrices[2] * weights.z +\n           shadowMap_cascadeMatrices[3] * weights.w;\n}\n"},82391:(e,n,t)=>{t.d(n,{Z:()=>o});const o="\nuniform vec4 shadowMap_cascadeSplits[2];\n\nvec4 czm_cascadeWeights(float depthEye)\n{\n    // One component is set to 1.0 and all others set to 0.0.\n    vec4 near = step(shadowMap_cascadeSplits[0], vec4(depthEye));\n    vec4 far = step(depthEye, shadowMap_cascadeSplits[1]);\n    return near * far;\n}\n"},77147:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * DOC_TBA\n *\n * @name czm_columbusViewMorph\n * @glslFunction\n */\nvec4 czm_columbusViewMorph(vec4 position2D, vec4 position3D, float time)\n{\n    // Just linear for now.\n    vec3 p = mix(position2D.xyz, position3D.xyz, time);\n    return vec4(p, 1.0);\n}\n"},79917:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Returns a position in model coordinates relative to eye taking into\n * account the current scene mode: 3D, 2D, or Columbus view.\n * <p>\n * This uses standard position attributes, <code>position3DHigh</code>, \n * <code>position3DLow</code>, <code>position2DHigh</code>, and <code>position2DLow</code>, \n * and should be used when writing a vertex shader for an {@link Appearance}.\n * </p>\n *\n * @name czm_computePosition\n * @glslFunction\n *\n * @returns {vec4} The position relative to eye.\n *\n * @example\n * vec4 p = czm_computePosition();\n * v_positionEC = (czm_modelViewRelativeToEye * p).xyz;\n * gl_Position = czm_modelViewProjectionRelativeToEye * p;\n *\n * @see czm_translateRelativeToEye\n */\nvec4 czm_computePosition();\n"},93922:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * @private\n */\nvec2 cordic(float angle)\n{\n// Scale the vector by the appropriate factor for the 24 iterations to follow.\n    vec2 vector = vec2(6.0725293500888267e-1, 0.0);\n// Iteration 1\n    float sense = (angle < 0.0) ? -1.0 : 1.0;\n //   float factor = sense * 1.0;  // 2^-0\n    mat2 rotation = mat2(1.0, sense, -sense, 1.0);\n    vector = rotation * vector;\n    angle -= sense * 7.8539816339744828e-1;  // atan(2^-0)\n// Iteration 2\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    float factor = sense * 5.0e-1;  // 2^-1\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 4.6364760900080609e-1;  // atan(2^-1)\n// Iteration 3\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 2.5e-1;  // 2^-2\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 2.4497866312686414e-1;  // atan(2^-2)\n// Iteration 4\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.25e-1;  // 2^-3\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 1.2435499454676144e-1;  // atan(2^-3)\n// Iteration 5\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 6.25e-2;  // 2^-4\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 6.2418809995957350e-2;  // atan(2^-4)\n// Iteration 6\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 3.125e-2;  // 2^-5\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 3.1239833430268277e-2;  // atan(2^-5)\n// Iteration 7\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.5625e-2;  // 2^-6\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 1.5623728620476831e-2;  // atan(2^-6)\n// Iteration 8\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 7.8125e-3;  // 2^-7\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 7.8123410601011111e-3;  // atan(2^-7)\n// Iteration 9\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 3.90625e-3;  // 2^-8\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 3.9062301319669718e-3;  // atan(2^-8)\n// Iteration 10\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.953125e-3;  // 2^-9\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 1.9531225164788188e-3;  // atan(2^-9)\n// Iteration 11\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 9.765625e-4;  // 2^-10\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 9.7656218955931946e-4;  // atan(2^-10)\n// Iteration 12\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 4.8828125e-4;  // 2^-11\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 4.8828121119489829e-4;  // atan(2^-11)\n// Iteration 13\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 2.44140625e-4;  // 2^-12\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 2.4414062014936177e-4;  // atan(2^-12)\n// Iteration 14\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.220703125e-4;  // 2^-13\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 1.2207031189367021e-4;  // atan(2^-13)\n// Iteration 15\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 6.103515625e-5;  // 2^-14\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 6.1035156174208773e-5;  // atan(2^-14)\n// Iteration 16\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 3.0517578125e-5;  // 2^-15\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 3.0517578115526096e-5;  // atan(2^-15)\n// Iteration 17\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.52587890625e-5;  // 2^-16\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 1.5258789061315762e-5;  // atan(2^-16)\n// Iteration 18\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 7.62939453125e-6;  // 2^-17\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 7.6293945311019700e-6;  // atan(2^-17)\n// Iteration 19\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 3.814697265625e-6;  // 2^-18\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 3.8146972656064961e-6;  // atan(2^-18)\n// Iteration 20\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.9073486328125e-6;  // 2^-19\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 1.9073486328101870e-6;  // atan(2^-19)\n// Iteration 21\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 9.5367431640625e-7;  // 2^-20\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 9.5367431640596084e-7;  // atan(2^-20)\n// Iteration 22\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 4.76837158203125e-7;  // 2^-21\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 4.7683715820308884e-7;  // atan(2^-21)\n// Iteration 23\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 2.384185791015625e-7;  // 2^-22\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n    angle -= sense * 2.3841857910155797e-7;  // atan(2^-22)\n// Iteration 24\n    sense = (angle < 0.0) ? -1.0 : 1.0;\n    factor = sense * 1.1920928955078125e-7;  // 2^-23\n    rotation[0][1] = factor;\n    rotation[1][0] = -factor;\n    vector = rotation * vector;\n//    angle -= sense * 1.1920928955078068e-7;  // atan(2^-23)\n\n    return vector;\n}\n\n/**\n * Computes the cosine and sine of the provided angle using the CORDIC algorithm.\n *\n * @name czm_cosineAndSine\n * @glslFunction\n *\n * @param {float} angle The angle in radians.\n *\n * @returns {vec2} The resulting cosine of the angle (as the x coordinate) and sine of the angle (as the y coordinate).\n *\n * @example\n * vec2 v = czm_cosineAndSine(czm_piOverSix);\n * float cosine = v.x;\n * float sine = v.y;\n */\nvec2 czm_cosineAndSine(float angle)\n{\n    if (angle < -czm_piOverTwo || angle > czm_piOverTwo)\n    {\n        if (angle < 0.0)\n        {\n            return -cordic(angle + czm_pi);\n        }\n        else\n        {\n            return -cordic(angle - czm_pi);\n        }\n    }\n    else\n    {\n        return cordic(angle);\n    }\n}\n"},66310:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Decompresses texture coordinates that were packed into a single float.\n *\n * @name czm_decompressTextureCoordinates\n * @glslFunction\n *\n * @param {float} encoded The compressed texture coordinates.\n * @returns {vec2} The decompressed texture coordinates.\n */\n vec2 czm_decompressTextureCoordinates(float encoded)\n {\n    float temp = encoded / 4096.0;\n    float xZeroTo4095 = floor(temp);\n    float stx = xZeroTo4095 / 4095.0;\n    float sty = (encoded - xZeroTo4095 * 4096.0) / 4095.0;\n    return vec2(stx, sty);\n }\n"},62099:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Get default parameters for physically based rendering. These defaults\n * describe a rough dielectric (non-metal) surface (e.g. rough plastic).\n *\n * @return {czm_pbrParameters} Default parameters for {@link czm_pbrLighting}\n */\nczm_pbrParameters czm_defaultPbrMaterial()\n{\n    czm_pbrParameters results;\n    results.diffuseColor = vec3(1.0);\n    results.roughness = 1.0;\n\n    const vec3 REFLECTANCE_DIELECTRIC = vec3(0.04);\n    results.f0 = REFLECTANCE_DIELECTRIC;\n    return results;\n}\n"},6974:(e,n,t)=>{t.d(n,{Z:()=>o});const o="// emulated noperspective\n#if defined(GL_EXT_frag_depth) && !defined(LOG_DEPTH)\nvarying float v_WindowZ;\n#endif\n\n/**\n * Emulates GL_DEPTH_CLAMP, which is not available in WebGL 1 or 2.\n * GL_DEPTH_CLAMP clamps geometry that is outside the near and far planes, \n * capping the shadow volume. More information here: \n * https://www.khronos.org/registry/OpenGL/extensions/ARB/ARB_depth_clamp.txt.\n *\n * When GL_EXT_frag_depth is available we emulate GL_DEPTH_CLAMP by ensuring \n * no geometry gets clipped by setting the clip space z value to 0.0 and then\n * sending the unaltered screen space z value (using emulated noperspective\n * interpolation) to the frag shader where it is clamped to [0,1] and then\n * written with gl_FragDepth (see czm_writeDepthClamp). This technique is based on:\n * https://stackoverflow.com/questions/5960757/how-to-emulate-gl-depth-clamp-nv.\n *\n * When GL_EXT_frag_depth is not available, which is the case on some mobile \n * devices, we must attempt to fix this only in the vertex shader. \n * The approach is to clamp the z value to the far plane, which closes the \n * shadow volume but also distorts the geometry, so there can still be artifacts\n * on frustum seams.\n *\n * @name czm_depthClamp\n * @glslFunction\n *\n * @param {vec4} coords The vertex in clip coordinates.\n * @returns {vec4} The modified vertex.\n *\n * @example\n * gl_Position = czm_depthClamp(czm_modelViewProjection * vec4(position, 1.0));\n *\n * @see czm_writeDepthClamp\n */\nvec4 czm_depthClamp(vec4 coords)\n{\n#ifndef LOG_DEPTH\n#ifdef GL_EXT_frag_depth\n    v_WindowZ = (0.5 * (coords.z / coords.w) + 0.5) * coords.w;\n    coords.z = 0.0;\n#else\n    coords.z = min(coords.z, coords.w);\n#endif\n#endif\n    return coords;\n}\n"},26628:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Computes a 3x3 rotation matrix that transforms vectors from an ellipsoid's east-north-up coordinate system \n * to eye coordinates.  In east-north-up coordinates, x points east, y points north, and z points along the \n * surface normal.  East-north-up can be used as an ellipsoid's tangent space for operations such as bump mapping.\n * <br /><br />\n * The ellipsoid is assumed to be centered at the model coordinate's origin.\n *\n * @name czm_eastNorthUpToEyeCoordinates\n * @glslFunction\n *\n * @param {vec3} positionMC The position on the ellipsoid in model coordinates.\n * @param {vec3} normalEC The normalized ellipsoid surface normal, at <code>positionMC</code>, in eye coordinates.\n *\n * @returns {mat3} A 3x3 rotation matrix that transforms vectors from the east-north-up coordinate system to eye coordinates.\n *\n * @example\n * // Transform a vector defined in the east-north-up coordinate \n * // system, (0, 0, 1) which is the surface normal, to eye \n * // coordinates.\n * mat3 m = czm_eastNorthUpToEyeCoordinates(positionMC, normalEC);\n * vec3 normalEC = m * vec3(0.0, 0.0, 1.0);\n */\nmat3 czm_eastNorthUpToEyeCoordinates(vec3 positionMC, vec3 normalEC)\n{\n    vec3 tangentMC = normalize(vec3(-positionMC.y, positionMC.x, 0.0));  // normalized surface tangent in model coordinates\n    vec3 tangentEC = normalize(czm_normal3D * tangentMC);                // normalized surface tangent in eye coordiantes\n    vec3 bitangentEC = normalize(cross(normalEC, tangentEC));            // normalized surface bitangent in eye coordinates\n\n    return mat3(\n        tangentEC.x,   tangentEC.y,   tangentEC.z,\n        bitangentEC.x, bitangentEC.y, bitangentEC.z,\n        normalEC.x,    normalEC.y,    normalEC.z);\n}\n"},53979:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * DOC_TBA\n *\n * @name czm_ellipsoidContainsPoint\n * @glslFunction\n *\n */\nbool czm_ellipsoidContainsPoint(vec3 ellipsoid_inverseRadii, vec3 point)\n{\n    vec3 scaled = ellipsoid_inverseRadii * (czm_inverseModelView * vec4(point, 1.0)).xyz;\n    return (dot(scaled, scaled) <= 1.0);\n}\n"},74341:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * DOC_TBA\n *\n * @name czm_ellipsoidWgs84TextureCoordinates\n * @glslFunction\n */\nvec2 czm_ellipsoidWgs84TextureCoordinates(vec3 normal)\n{\n    return vec2(atan(normal.y, normal.x) * czm_oneOverTwoPi + 0.5, asin(normal.z) * czm_oneOverPi + 0.5);\n}\n"},73963:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Compares <code>left</code> and <code>right</code> componentwise. Returns <code>true</code>\n * if they are within <code>epsilon</code> and <code>false</code> otherwise. The inputs\n * <code>left</code> and <code>right</code> can be <code>float</code>s, <code>vec2</code>s,\n * <code>vec3</code>s, or <code>vec4</code>s.\n *\n * @name czm_equalsEpsilon\n * @glslFunction\n *\n * @param {} left The first vector.\n * @param {} right The second vector.\n * @param {float} epsilon The epsilon to use for equality testing.\n * @returns {bool} <code>true</code> if the components are within <code>epsilon</code> and <code>false</code> otherwise.\n *\n * @example\n * // GLSL declarations\n * bool czm_equalsEpsilon(float left, float right, float epsilon);\n * bool czm_equalsEpsilon(vec2 left, vec2 right, float epsilon);\n * bool czm_equalsEpsilon(vec3 left, vec3 right, float epsilon);\n * bool czm_equalsEpsilon(vec4 left, vec4 right, float epsilon);\n */\nbool czm_equalsEpsilon(vec4 left, vec4 right, float epsilon) {\n    return all(lessThanEqual(abs(left - right), vec4(epsilon)));\n}\n\nbool czm_equalsEpsilon(vec3 left, vec3 right, float epsilon) {\n    return all(lessThanEqual(abs(left - right), vec3(epsilon)));\n}\n\nbool czm_equalsEpsilon(vec2 left, vec2 right, float epsilon) {\n    return all(lessThanEqual(abs(left - right), vec2(epsilon)));\n}\n\nbool czm_equalsEpsilon(float left, float right, float epsilon) {\n    return (abs(left - right) <= epsilon);\n}\n"},65177:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * DOC_TBA\n *\n * @name czm_eyeOffset\n * @glslFunction\n *\n * @param {vec4} positionEC DOC_TBA.\n * @param {vec3} eyeOffset DOC_TBA.\n *\n * @returns {vec4} DOC_TBA.\n */\nvec4 czm_eyeOffset(vec4 positionEC, vec3 eyeOffset)\n{\n    // This equation is approximate in x and y.\n    vec4 p = positionEC;\n    vec4 zEyeOffset = normalize(p) * eyeOffset.z;\n    p.xy += eyeOffset.xy + zEyeOffset.xy;\n    p.z += zEyeOffset.z;\n    return p;\n}\n"},6129:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Transforms a position from eye to window coordinates.  The transformation\n * from eye to clip coordinates is done using {@link czm_projection}.\n * The transform from normalized device coordinates to window coordinates is\n * done using {@link czm_viewportTransformation}, which assumes a depth range\n * of <code>near = 0</code> and <code>far = 1</code>.\n * <br /><br />\n * This transform is useful when there is a need to manipulate window coordinates\n * in a vertex shader as done by {@link BillboardCollection}.\n *\n * @name czm_eyeToWindowCoordinates\n * @glslFunction\n *\n * @param {vec4} position The position in eye coordinates to transform.\n *\n * @returns {vec4} The transformed position in window coordinates.\n *\n * @see czm_modelToWindowCoordinates\n * @see czm_projection\n * @see czm_viewportTransformation\n * @see BillboardCollection\n *\n * @example\n * vec4 positionWC = czm_eyeToWindowCoordinates(positionEC);\n */\nvec4 czm_eyeToWindowCoordinates(vec4 positionEC)\n{\n    vec4 q = czm_projection * positionEC;                        // clip coordinates\n    q.xyz /= q.w;                                                // normalized device coordinates\n    q.xyz = (czm_viewportTransformation * vec4(q.xyz, 1.0)).xyz; // window coordinates\n    return q;\n}\n"},48192:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Approxiamtes atan over the range [0, 1]. Safe to flip output for negative input.\n *\n * Based on Michal Drobot's approximation from ShaderFastLibs, which in turn is based on\n * \"Efficient approximations for the arctangent function,\" Rajan, S. Sichun Wang Inkol, R. Joyal, A., May 2006.\n * Adapted from ShaderFastLibs under MIT License.\n *\n * Chosen for the following characteristics over range [0, 1]:\n * - basically no error at 0 and 1, important for getting around range limit (naive atan2 via atan requires infinite range atan)\n * - no visible artifacts from first-derivative discontinuities, unlike latitude via range-reduced sqrt asin approximations (at equator)\n *\n * The original code is x * (-0.1784 * abs(x) - 0.0663 * x * x + 1.0301);\n * Removed the abs() in here because it isn't needed, the input range is guaranteed as [0, 1] by how we're approximating atan2.\n *\n * @name czm_fastApproximateAtan\n * @glslFunction\n *\n * @param {float} x Value between 0 and 1 inclusive.\n *\n * @returns {float} Approximation of atan(x)\n */\nfloat czm_fastApproximateAtan(float x) {\n    return x * (-0.1784 * x - 0.0663 * x * x + 1.0301);\n}\n\n/**\n * Approximation of atan2.\n *\n * Range reduction math based on nvidia's cg reference implementation for atan2: http://developer.download.nvidia.com/cg/atan2.html\n * However, we replaced their atan curve with Michael Drobot's (see above).\n *\n * @name czm_fastApproximateAtan\n * @glslFunction\n *\n * @param {float} x Value between -1 and 1 inclusive.\n * @param {float} y Value between -1 and 1 inclusive.\n *\n * @returns {float} Approximation of atan2(x, y)\n */\nfloat czm_fastApproximateAtan(float x, float y) {\n    // atan approximations are usually only reliable over [-1, 1], or, in our case, [0, 1] due to modifications.\n    // So range-reduce using abs and by flipping whether x or y is on top.\n    float t = abs(x); // t used as swap and atan result.\n    float opposite = abs(y);\n    float adjacent = max(t, opposite);\n    opposite = min(t, opposite);\n\n    t = czm_fastApproximateAtan(opposite / adjacent);\n\n    // Undo range reduction\n    t = czm_branchFreeTernary(abs(y) > abs(x), czm_piOverTwo - t, t);\n    t = czm_branchFreeTernary(x < 0.0, czm_pi - t, t);\n    t = czm_branchFreeTernary(y < 0.0, -t, t);\n    return t;\n}\n"},78106:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Gets the color with fog at a distance from the camera.\n *\n * @name czm_fog\n * @glslFunction\n *\n * @param {float} distanceToCamera The distance to the camera in meters.\n * @param {vec3} color The original color.\n * @param {vec3} fogColor The color of the fog.\n *\n * @returns {vec3} The color adjusted for fog at the distance from the camera.\n */\nvec3 czm_fog(float distanceToCamera, vec3 color, vec3 fogColor)\n{\n    float scalar = distanceToCamera * czm_fogDensity;\n    float fog = 1.0 - exp(-(scalar * scalar));\n    return mix(color, fogColor, fog);\n}\n\n/**\n * Gets the color with fog at a distance from the camera.\n *\n * @name czm_fog\n * @glslFunction\n *\n * @param {float} distanceToCamera The distance to the camera in meters.\n * @param {vec3} color The original color.\n * @param {vec3} fogColor The color of the fog.\n * @param {float} fogModifierConstant A constant to modify the appearance of fog.\n *\n * @returns {vec3} The color adjusted for fog at the distance from the camera.\n */\nvec3 czm_fog(float distanceToCamera, vec3 color, vec3 fogColor, float fogModifierConstant)\n{\n    float scalar = distanceToCamera * czm_fogDensity;\n    float fog = 1.0 - exp(-((fogModifierConstant * scalar + fogModifierConstant) * (scalar * (1.0 + fogModifierConstant))));\n    return mix(color, fogColor, fog);\n}\n"},98490:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Converts a color from RGB space to linear space.\n *\n * @name czm_gammaCorrect\n * @glslFunction\n *\n * @param {vec3} color The color in RGB space.\n * @returns {vec3} The color in linear space.\n */\nvec3 czm_gammaCorrect(vec3 color) {\n#ifdef HDR\n    color = pow(color, vec3(czm_gamma));\n#endif\n    return color;\n}\n\nvec4 czm_gammaCorrect(vec4 color) {\n#ifdef HDR\n    color.rgb = pow(color.rgb, vec3(czm_gamma));\n#endif\n    return color;\n}\n"},34582:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * DOC_TBA\n *\n * @name czm_geodeticSurfaceNormal\n * @glslFunction\n *\n * @param {vec3} positionOnEllipsoid DOC_TBA\n * @param {vec3} ellipsoidCenter DOC_TBA\n * @param {vec3} oneOverEllipsoidRadiiSquared DOC_TBA\n * \n * @returns {vec3} DOC_TBA.\n */\nvec3 czm_geodeticSurfaceNormal(vec3 positionOnEllipsoid, vec3 ellipsoidCenter, vec3 oneOverEllipsoidRadiiSquared)\n{\n    return normalize((positionOnEllipsoid - ellipsoidCenter) * oneOverEllipsoidRadiiSquared);\n}\n"},88255:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * An czm_material with default values. Every material's czm_getMaterial\n * should use this default material as a base for the material it returns.\n * The default normal value is given by materialInput.normalEC.\n *\n * @name czm_getDefaultMaterial\n * @glslFunction\n *\n * @param {czm_materialInput} input The input used to construct the default material.\n *\n * @returns {czm_material} The default material.\n *\n * @see czm_materialInput\n * @see czm_material\n * @see czm_getMaterial\n */\nczm_material czm_getDefaultMaterial(czm_materialInput materialInput)\n{\n    czm_material material;\n    material.diffuse = vec3(0.0);\n    material.specular = 0.0;\n    material.shininess = 1.0;\n    material.normal = materialInput.normalEC;\n    material.emission = vec3(0.0);\n    material.alpha = 1.0;\n    return material;\n}\n"},22060:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Calculates the intensity of diffusely reflected light.\n *\n * @name czm_getLambertDiffuse\n * @glslFunction\n *\n * @param {vec3} lightDirectionEC Unit vector pointing to the light source in eye coordinates.\n * @param {vec3} normalEC The surface normal in eye coordinates.\n *\n * @returns {float} The intensity of the diffuse reflection.\n *\n * @see czm_phong\n *\n * @example\n * float diffuseIntensity = czm_getLambertDiffuse(lightDirectionEC, normalEC);\n * float specularIntensity = czm_getSpecular(lightDirectionEC, toEyeEC, normalEC, 200);\n * vec3 color = (diffuseColor * diffuseIntensity) + (specularColor * specularIntensity);\n */\nfloat czm_getLambertDiffuse(vec3 lightDirectionEC, vec3 normalEC)\n{\n    return max(dot(lightDirectionEC, normalEC), 0.0);\n}\n"},89920:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Calculates the specular intensity of reflected light.\n *\n * @name czm_getSpecular\n * @glslFunction\n *\n * @param {vec3} lightDirectionEC Unit vector pointing to the light source in eye coordinates.\n * @param {vec3} toEyeEC Unit vector pointing to the eye position in eye coordinates.\n * @param {vec3} normalEC The surface normal in eye coordinates.\n * @param {float} shininess The sharpness of the specular reflection.  Higher values create a smaller, more focused specular highlight.\n *\n * @returns {float} The intensity of the specular highlight.\n *\n * @see czm_phong\n *\n * @example\n * float diffuseIntensity = czm_getLambertDiffuse(lightDirectionEC, normalEC);\n * float specularIntensity = czm_getSpecular(lightDirectionEC, toEyeEC, normalEC, 200);\n * vec3 color = (diffuseColor * diffuseIntensity) + (specularColor * specularIntensity);\n */\nfloat czm_getSpecular(vec3 lightDirectionEC, vec3 toEyeEC, vec3 normalEC, float shininess)\n{\n    vec3 toReflectedLight = reflect(-lightDirectionEC, normalEC);\n    float specular = max(dot(toReflectedLight, toEyeEC), 0.0);\n\n    // pow has undefined behavior if both parameters <= 0.\n    // Prevent this by making sure shininess is at least czm_epsilon2.\n    return pow(specular, max(shininess, czm_epsilon2));\n}\n"},68550:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * @private\n */\nvec4 czm_getWaterNoise(sampler2D normalMap, vec2 uv, float time, float angleInRadians)\n{\n    float cosAngle = cos(angleInRadians);\n    float sinAngle = sin(angleInRadians);\n\n    // time dependent sampling directions\n    vec2 s0 = vec2(1.0/17.0, 0.0);\n    vec2 s1 = vec2(-1.0/29.0, 0.0);\n    vec2 s2 = vec2(1.0/101.0, 1.0/59.0);\n    vec2 s3 = vec2(-1.0/109.0, -1.0/57.0);\n\n    // rotate sampling direction by specified angle\n    s0 = vec2((cosAngle * s0.x) - (sinAngle * s0.y), (sinAngle * s0.x) + (cosAngle * s0.y));\n    s1 = vec2((cosAngle * s1.x) - (sinAngle * s1.y), (sinAngle * s1.x) + (cosAngle * s1.y));\n    s2 = vec2((cosAngle * s2.x) - (sinAngle * s2.y), (sinAngle * s2.x) + (cosAngle * s2.y));\n    s3 = vec2((cosAngle * s3.x) - (sinAngle * s3.y), (sinAngle * s3.x) + (cosAngle * s3.y));\n\n    vec2 uv0 = (uv/103.0) + (time * s0);\n    vec2 uv1 = uv/107.0 + (time * s1) + vec2(0.23);\n    vec2 uv2 = uv/vec2(897.0, 983.0) + (time * s2) + vec2(0.51);\n    vec2 uv3 = uv/vec2(991.0, 877.0) + (time * s3) + vec2(0.71);\n\n    uv0 = fract(uv0);\n    uv1 = fract(uv1);\n    uv2 = fract(uv2);\n    uv3 = fract(uv3);\n    vec4 noise = (texture2D(normalMap, uv0)) +\n                 (texture2D(normalMap, uv1)) +\n                 (texture2D(normalMap, uv2)) +\n                 (texture2D(normalMap, uv3));\n\n    // average and scale to between -1 and 1\n    return ((noise / 4.0) - 0.5) * 2.0;\n}\n"},75510:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Adjusts the hue of a color.\n * \n * @name czm_hue\n * @glslFunction\n * \n * @param {vec3} rgb The color.\n * @param {float} adjustment The amount to adjust the hue of the color in radians.\n *\n * @returns {float} The color with the hue adjusted.\n *\n * @example\n * vec3 adjustHue = czm_hue(color, czm_pi); // The same as czm_hue(color, -czm_pi)\n */\nvec3 czm_hue(vec3 rgb, float adjustment)\n{\n    const mat3 toYIQ = mat3(0.299,     0.587,     0.114,\n                            0.595716, -0.274453, -0.321263,\n                            0.211456, -0.522591,  0.311135);\n    const mat3 toRGB = mat3(1.0,  0.9563,  0.6210,\n                            1.0, -0.2721, -0.6474,\n                            1.0, -1.107,   1.7046);\n    \n    vec3 yiq = toYIQ * rgb;\n    float hue = atan(yiq.z, yiq.y) + adjustment;\n    float chroma = sqrt(yiq.z * yiq.z + yiq.y * yiq.y);\n    \n    vec3 color = vec3(yiq.x, chroma * cos(hue), chroma * sin(hue));\n    return toRGB * color;\n}\n"},69871:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Converts a color in linear space to RGB space.\n *\n * @name czm_inverseGamma\n * @glslFunction\n *\n * @param {vec3} color The color in linear space.\n * @returns {vec3} The color in RGB space.\n */\nvec3 czm_inverseGamma(vec3 color) {\n    return pow(color, vec3(1.0 / czm_gamma));\n}\n"},25666:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Determines if a time interval is empty.\n *\n * @name czm_isEmpty\n * @glslFunction \n * \n * @param {czm_raySegment} interval The interval to test.\n * \n * @returns {bool} <code>true</code> if the time interval is empty; otherwise, <code>false</code>.\n *\n * @example\n * bool b0 = czm_isEmpty(czm_emptyRaySegment);      // true\n * bool b1 = czm_isEmpty(czm_raySegment(0.0, 1.0)); // false\n * bool b2 = czm_isEmpty(czm_raySegment(1.0, 1.0)); // false, contains 1.0.\n */\nbool czm_isEmpty(czm_raySegment interval)\n{\n    return (interval.stop < 0.0);\n}\n"},7776:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Determines if a time interval is empty.\n *\n * @name czm_isFull\n * @glslFunction \n * \n * @param {czm_raySegment} interval The interval to test.\n * \n * @returns {bool} <code>true</code> if the time interval is empty; otherwise, <code>false</code>.\n *\n * @example\n * bool b0 = czm_isEmpty(czm_emptyRaySegment);      // true\n * bool b1 = czm_isEmpty(czm_raySegment(0.0, 1.0)); // false\n * bool b2 = czm_isEmpty(czm_raySegment(1.0, 1.0)); // false, contains 1.0.\n */\nbool czm_isFull(czm_raySegment interval)\n{\n    return (interval.start == 0.0 && interval.stop == czm_infinity);\n}\n"},25094:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Computes the fraction of a Web Wercator rectangle at which a given geodetic latitude is located.\n *\n * @name czm_latitudeToWebMercatorFraction\n * @glslFunction\n *\n * @param {float} latitude The geodetic latitude, in radians.\n * @param {float} southMercatorY The Web Mercator coordinate of the southern boundary of the rectangle.\n * @param {float} oneOverMercatorHeight The total height of the rectangle in Web Mercator coordinates.\n *\n * @returns {float} The fraction of the rectangle at which the latitude occurs.  If the latitude is the southern\n *          boundary of the rectangle, the return value will be zero.  If it is the northern boundary, the return\n *          value will be 1.0.  Latitudes in between are mapped according to the Web Mercator projection.\n */ \nfloat czm_latitudeToWebMercatorFraction(float latitude, float southMercatorY, float oneOverMercatorHeight)\n{\n    float sinLatitude = sin(latitude);\n    float mercatorY = 0.5 * log((1.0 + sinLatitude) / (1.0 - sinLatitude));\n    \n    return (mercatorY - southMercatorY) * oneOverMercatorHeight;\n}\n"},10093:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Computes distance from an point in 2D to a line in 2D.\n *\n * @name czm_lineDistance\n * @glslFunction\n *\n * param {vec2} point1 A point along the line.\n * param {vec2} point2 A point along the line.\n * param {vec2} point A point that may or may not be on the line.\n * returns {float} The distance from the point to the line.\n */\nfloat czm_lineDistance(vec2 point1, vec2 point2, vec2 point) {\n    return abs((point2.y - point1.y) * point.x - (point2.x - point1.x) * point.y + point2.x * point1.y - point2.y * point1.x) / distance(point2, point1);\n}\n"},72996:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Converts a linear RGB color to an sRGB color.\n *\n * @param {vec3|vec4} linearIn The color in linear color space.\n * @returns {vec3|vec4} The color in sRGB color space. The vector type matches the input.\n */\nvec3 czm_linearToSrgb(vec3 linearIn) \n{\n    return pow(linearIn, vec3(1.0/2.2));\n}\n\nvec4 czm_linearToSrgb(vec4 linearIn) \n{\n    vec3 srgbOut = pow(linearIn.rgb, vec3(1.0/2.2));\n    return vec4(srgbOut, linearIn.a);\n}\n"},56898:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Computes the luminance of a color. \n *\n * @name czm_luminance\n * @glslFunction\n *\n * @param {vec3} rgb The color.\n * \n * @returns {float} The luminance.\n *\n * @example\n * float light = czm_luminance(vec3(0.0)); // 0.0\n * float dark = czm_luminance(vec3(1.0));  // ~1.0 \n */\nfloat czm_luminance(vec3 rgb)\n{\n    // Algorithm from Chapter 10 of Graphics Shaders.\n    const vec3 W = vec3(0.2125, 0.7154, 0.0721);\n    return dot(rgb, W);\n}\n"},27392:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Computes the size of a pixel in meters at a distance from the eye.\n * <p>\n * Use this version when passing in a custom pixel ratio. For example, passing in 1.0 will return meters per native device pixel.\n * </p>\n * @name czm_metersPerPixel\n * @glslFunction\n *\n * @param {vec3} positionEC The position to get the meters per pixel in eye coordinates.\n * @param {float} pixelRatio The scaling factor from pixel space to coordinate space\n *\n * @returns {float} The meters per pixel at positionEC.\n */\nfloat czm_metersPerPixel(vec4 positionEC, float pixelRatio)\n{\n    float width = czm_viewport.z;\n    float height = czm_viewport.w;\n    float pixelWidth;\n    float pixelHeight;\n\n    float top = czm_frustumPlanes.x;\n    float bottom = czm_frustumPlanes.y;\n    float left = czm_frustumPlanes.z;\n    float right = czm_frustumPlanes.w;\n\n    if (czm_sceneMode == czm_sceneMode2D || czm_orthographicIn3D == 1.0)\n    {\n        float frustumWidth = right - left;\n        float frustumHeight = top - bottom;\n        pixelWidth = frustumWidth / width;\n        pixelHeight = frustumHeight / height;\n    }\n    else\n    {\n        float distanceToPixel = -positionEC.z;\n        float inverseNear = 1.0 / czm_currentFrustum.x;\n        float tanTheta = top * inverseNear;\n        pixelHeight = 2.0 * distanceToPixel * tanTheta / height;\n        tanTheta = right * inverseNear;\n        pixelWidth = 2.0 * distanceToPixel * tanTheta / width;\n    }\n\n    return max(pixelWidth, pixelHeight) * pixelRatio;\n}\n\n/**\n * Computes the size of a pixel in meters at a distance from the eye.\n * <p>\n * Use this version when scaling by pixel ratio.\n * </p>\n * @name czm_metersPerPixel\n * @glslFunction\n *\n * @param {vec3} positionEC The position to get the meters per pixel in eye coordinates.\n *\n * @returns {float} The meters per pixel at positionEC.\n */\nfloat czm_metersPerPixel(vec4 positionEC)\n{\n    return czm_metersPerPixel(positionEC, czm_pixelRatio);\n}\n"},23777:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Transforms a position from model to window coordinates.  The transformation\n * from model to clip coordinates is done using {@link czm_modelViewProjection}.\n * The transform from normalized device coordinates to window coordinates is\n * done using {@link czm_viewportTransformation}, which assumes a depth range\n * of <code>near = 0</code> and <code>far = 1</code>.\n * <br /><br />\n * This transform is useful when there is a need to manipulate window coordinates\n * in a vertex shader as done by {@link BillboardCollection}.\n * <br /><br />\n * This function should not be confused with {@link czm_viewportOrthographic},\n * which is an orthographic projection matrix that transforms from window \n * coordinates to clip coordinates.\n *\n * @name czm_modelToWindowCoordinates\n * @glslFunction\n *\n * @param {vec4} position The position in model coordinates to transform.\n *\n * @returns {vec4} The transformed position in window coordinates.\n *\n * @see czm_eyeToWindowCoordinates\n * @see czm_modelViewProjection\n * @see czm_viewportTransformation\n * @see czm_viewportOrthographic\n * @see BillboardCollection\n *\n * @example\n * vec4 positionWC = czm_modelToWindowCoordinates(positionMC);\n */\nvec4 czm_modelToWindowCoordinates(vec4 position)\n{\n    vec4 q = czm_modelViewProjection * position;                // clip coordinates\n    q.xyz /= q.w;                                                // normalized device coordinates\n    q.xyz = (czm_viewportTransformation * vec4(q.xyz, 1.0)).xyz; // window coordinates\n    return q;\n}\n"},68130:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * DOC_TBA\n *\n * @name czm_multiplyWithColorBalance\n * @glslFunction\n */\nvec3 czm_multiplyWithColorBalance(vec3 left, vec3 right)\n{\n    // Algorithm from Chapter 10 of Graphics Shaders.\n    const vec3 W = vec3(0.2125, 0.7154, 0.0721);\n    \n    vec3 target = left * right;\n    float leftLuminance = dot(left, W);\n    float rightLuminance = dot(right, W);\n    float targetLuminance = dot(target, W);\n    \n    return ((leftLuminance + rightLuminance) / (2.0 * targetLuminance)) * target;\n}\n"},66040:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Computes a value that scales with distance.  The scaling is clamped at the near and\n * far distances, and does not extrapolate.  This function works with the\n * {@link NearFarScalar} JavaScript class.\n *\n * @name czm_nearFarScalar\n * @glslFunction\n *\n * @param {vec4} nearFarScalar A vector with 4 components: Near distance (x), Near value (y), Far distance (z), Far value (w).\n * @param {float} cameraDistSq The square of the current distance from the camera.\n *\n * @returns {float} The value at this distance.\n */\nfloat czm_nearFarScalar(vec4 nearFarScalar, float cameraDistSq)\n{\n    float valueAtMin = nearFarScalar.y;\n    float valueAtMax = nearFarScalar.w;\n    float nearDistanceSq = nearFarScalar.x * nearFarScalar.x;\n    float farDistanceSq = nearFarScalar.z * nearFarScalar.z;\n\n    float t = (cameraDistSq - nearDistanceSq) / (farDistanceSq - nearDistanceSq);\n\n    t = pow(clamp(t, 0.0, 1.0), 0.2);\n\n    return mix(valueAtMin, valueAtMax, t);\n}\n"},37447:(e,n,t)=>{t.d(n,{Z:()=>o});const o=" /**\n  * Decodes a unit-length vector in 'oct' encoding to a normalized 3-component Cartesian vector.\n  * The 'oct' encoding is described in \"A Survey of Efficient Representations of Independent Unit Vectors\",\n  * Cigolle et al 2014: http://jcgt.org/published/0003/02/01/\n  *\n  * @name czm_octDecode\n  * @param {vec2} encoded The oct-encoded, unit-length vector\n  * @param {float} range The maximum value of the SNORM range. The encoded vector is stored in log2(rangeMax+1) bits.\n  * @returns {vec3} The decoded and normalized vector\n  */\n  vec3 czm_octDecode(vec2 encoded, float range)\n  {\n      if (encoded.x == 0.0 && encoded.y == 0.0) {\n          return vec3(0.0, 0.0, 0.0);\n      }\n\n     encoded = encoded / range * 2.0 - 1.0;\n     vec3 v = vec3(encoded.x, encoded.y, 1.0 - abs(encoded.x) - abs(encoded.y));\n     if (v.z < 0.0)\n     {\n         v.xy = (1.0 - abs(v.yx)) * czm_signNotZero(v.xy);\n     }\n\n     return normalize(v);\n  }\n\n/**\n * Decodes a unit-length vector in 'oct' encoding to a normalized 3-component Cartesian vector.\n * The 'oct' encoding is described in \"A Survey of Efficient Representations of Independent Unit Vectors\",\n * Cigolle et al 2014: http://jcgt.org/published/0003/02/01/\n *\n * @name czm_octDecode\n * @param {vec2} encoded The oct-encoded, unit-length vector\n * @returns {vec3} The decoded and normalized vector\n */\n vec3 czm_octDecode(vec2 encoded)\n {\n    return czm_octDecode(encoded, 255.0);\n }\n\n /**\n * Decodes a unit-length vector in 'oct' encoding packed into a floating-point number to a normalized 3-component Cartesian vector.\n * The 'oct' encoding is described in \"A Survey of Efficient Representations of Independent Unit Vectors\",\n * Cigolle et al 2014: http://jcgt.org/published/0003/02/01/\n *\n * @name czm_octDecode\n * @param {float} encoded The oct-encoded, unit-length vector\n * @returns {vec3} The decoded and normalized vector\n */\n vec3 czm_octDecode(float encoded)\n {\n    float temp = encoded / 256.0;\n    float x = floor(temp);\n    float y = (temp - x) * 256.0;\n    return czm_octDecode(vec2(x, y));\n }\n\n/**\n * Decodes three unit-length vectors in 'oct' encoding packed into two floating-point numbers to normalized 3-component Cartesian vectors.\n * The 'oct' encoding is described in \"A Survey of Efficient Representations of Independent Unit Vectors\",\n * Cigolle et al 2014: http://jcgt.org/published/0003/02/01/\n *\n * @name czm_octDecode\n * @param {vec2} encoded The packed oct-encoded, unit-length vectors.\n * @param {vec3} vector1 One decoded and normalized vector.\n * @param {vec3} vector2 One decoded and normalized vector.\n * @param {vec3} vector3 One decoded and normalized vector.\n */\n  void czm_octDecode(vec2 encoded, out vec3 vector1, out vec3 vector2, out vec3 vector3)\n {\n    float temp = encoded.x / 65536.0;\n    float x = floor(temp);\n    float encodedFloat1 = (temp - x) * 65536.0;\n\n    temp = encoded.y / 65536.0;\n    float y = floor(temp);\n    float encodedFloat2 = (temp - y) * 65536.0;\n\n    vector1 = czm_octDecode(encodedFloat1);\n    vector2 = czm_octDecode(encodedFloat2);\n    vector3 = czm_octDecode(vec2(x, y));\n }\n\n"},23782:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Packs a depth value into a vec3 that can be represented by unsigned bytes.\n *\n * @name czm_packDepth\n * @glslFunction\n *\n * @param {float} depth The floating-point depth.\n * @returns {vec3} The packed depth.\n */\nvec4 czm_packDepth(float depth)\n{\n    // See Aras Pranckevi\u010dius' post Encoding Floats to RGBA\n    // http://aras-p.info/blog/2009/07/30/encoding-floats-to-rgba-the-final/\n    vec4 enc = vec4(1.0, 255.0, 65025.0, 16581375.0) * depth;\n    enc = fract(enc);\n    enc -= enc.yzww * vec4(1.0 / 255.0, 1.0 / 255.0, 1.0 / 255.0, 0.0);\n    return enc;\n}\n"},57549:(e,n,t)=>{t.d(n,{Z:()=>o});const o="vec3 lambertianDiffuse(vec3 diffuseColor)\n{\n    return diffuseColor / czm_pi;\n}\n\nvec3 fresnelSchlick2(vec3 f0, vec3 f90, float VdotH)\n{\n    return f0 + (f90 - f0) * pow(clamp(1.0 - VdotH, 0.0, 1.0), 5.0);\n}\n\nfloat smithVisibilityG1(float NdotV, float roughness)\n{\n    // this is the k value for direct lighting.\n    // for image based lighting it will be roughness^2 / 2\n    float k = (roughness + 1.0) * (roughness + 1.0) / 8.0;\n    return NdotV / (NdotV * (1.0 - k) + k);\n}\n\nfloat smithVisibilityGGX(float roughness, float NdotL, float NdotV)\n{\n    return (\n        smithVisibilityG1(NdotL, roughness) *\n        smithVisibilityG1(NdotV, roughness)\n    );\n}\n\nfloat GGX(float roughness, float NdotH)\n{\n    float roughnessSquared = roughness * roughness;\n    float f = (NdotH * roughnessSquared - NdotH) * NdotH + 1.0;\n    return roughnessSquared / (czm_pi * f * f);\n}\n\n/**\n * Compute the diffuse and specular contributions using physically based\n * rendering. This function only handles direct lighting.\n * <p>\n * This function only handles the lighting calculations. Metallic/roughness\n * and specular/glossy must be handled separately. See {@czm_pbrMetallicRoughnessMaterial}, {@czm_pbrSpecularGlossinessMaterial} and {@czm_defaultPbrMaterial}\n * </p>\n *\n * @name czm_pbrlighting\n * @glslFunction\n *\n * @param {vec3} positionEC The position of the fragment in eye coordinates\n * @param {vec3} normalEC The surface normal in eye coordinates\n * @param {vec3} lightDirectionEC Unit vector pointing to the light source in eye coordinates.\n * @param {vec3} lightColorHdr radiance of the light source. This is a HDR value.\n * @param {czm_pbrParameters} The computed PBR parameters.\n * @return {vec3} The computed HDR color\n *\n * @example\n * czm_pbrParameters pbrParameters = czm_pbrMetallicRoughnessMaterial(\n *  baseColor,\n *  metallic,\n *  roughness\n * );\n * vec3 color = czm_pbrlighting(\n *  positionEC,\n *  normalEC,\n *  lightDirectionEC,\n *  lightColorHdr,\n *  pbrParameters);\n */\nvec3 czm_pbrLighting(\n    vec3 positionEC,\n    vec3 normalEC,\n    vec3 lightDirectionEC,\n    vec3 lightColorHdr,\n    czm_pbrParameters pbrParameters\n)\n{\n    vec3 v = -normalize(positionEC);\n    vec3 l = normalize(lightDirectionEC);\n    vec3 h = normalize(v + l);\n    vec3 n = normalEC;\n    float NdotL = clamp(dot(n, l), 0.001, 1.0);\n    float NdotV = abs(dot(n, v)) + 0.001;\n    float NdotH = clamp(dot(n, h), 0.0, 1.0);\n    float LdotH = clamp(dot(l, h), 0.0, 1.0);\n    float VdotH = clamp(dot(v, h), 0.0, 1.0);\n\n    vec3 f0 = pbrParameters.f0;\n    float reflectance = max(max(f0.r, f0.g), f0.b);\n    vec3 f90 = vec3(clamp(reflectance * 25.0, 0.0, 1.0));\n    vec3 F = fresnelSchlick2(f0, f90, VdotH);\n\n    float alpha = pbrParameters.roughness;\n    float G = smithVisibilityGGX(alpha, NdotL, NdotV);\n    float D = GGX(alpha, NdotH);\n    vec3 specularContribution = F * G * D / (4.0 * NdotL * NdotV);\n\n    vec3 diffuseColor = pbrParameters.diffuseColor;\n    // F here represents the specular contribution\n    vec3 diffuseContribution = (1.0 - F) * lambertianDiffuse(diffuseColor);\n\n    // Lo = (diffuse + specular) * Li * NdotL\n    return (diffuseContribution + specularContribution) * NdotL * lightColorHdr;\n}\n"},50016:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Compute parameters for physically based rendering using the\n * metallic/roughness workflow. All inputs are linear; sRGB texture values must\n * be decoded beforehand\n *\n * @name czm_pbrMetallicRoughnessMaterial\n * @glslFunction\n *\n * @param {vec3} baseColor For dielectrics, this is the base color. For metals, this is the f0 value (reflectance at normal incidence)\n * @param {float} metallic 0.0 indicates dielectric. 1.0 indicates metal. Values in between are allowed (e.g. to model rust or dirt);\n * @param {float} roughness A value between 0.0 and 1.0\n * @return {czm_pbrParameters} parameters to pass into {@link czm_pbrLighting}\n */\nczm_pbrParameters czm_pbrMetallicRoughnessMaterial(\n    vec3 baseColor,\n    float metallic,\n    float roughness\n) \n{\n    czm_pbrParameters results;\n\n    // roughness is authored as perceptual roughness\n    // square it to get material roughness\n    roughness = clamp(roughness, 0.0, 1.0);\n    results.roughness = roughness * roughness;\n\n    // dielectrics us f0 = 0.04, metals use albedo as f0\n    metallic = clamp(metallic, 0.0, 1.0);\n    const vec3 REFLECTANCE_DIELECTRIC = vec3(0.04);\n    vec3 f0 = mix(REFLECTANCE_DIELECTRIC, baseColor, metallic);\n    results.f0 = f0;\n\n    // diffuse only applies to dielectrics.\n    results.diffuseColor = baseColor * (1.0 - f0) * (1.0 - metallic);\n\n    return results;\n}\n"},14576:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Compute parameters for physically based rendering using the\n * specular/glossy workflow. All inputs are linear; sRGB texture values must\n * be decoded beforehand\n *\n * @name czm_pbrSpecularGlossinessMaterial\n * @glslFunction\n *\n * @param {vec3} diffuse The diffuse color for dielectrics (non-metals)\n * @param {vec3} specular The reflectance at normal incidence (f0)\n * @param {float} glossiness A number from 0.0 to 1.0 indicating how smooth the surface is.\n * @return {czm_pbrParameters} parameters to pass into {@link czm_pbrLighting}\n */\nczm_pbrParameters czm_pbrSpecularGlossinessMaterial(\n    vec3 diffuse,\n    vec3 specular,\n    float glossiness\n) \n{\n    czm_pbrParameters results;\n\n    // glossiness is the opposite of roughness, but easier for artists to use.\n    float roughness = 1.0 - glossiness;\n    results.roughness = roughness * roughness;\n\n    results.diffuseColor = diffuse * (1.0 - max(max(specular.r, specular.g), specular.b));\n    results.f0 = specular;\n\n    return results;\n}\n"},17578:(e,n,t)=>{t.d(n,{Z:()=>o});const o="float czm_private_getLambertDiffuseOfMaterial(vec3 lightDirectionEC, czm_material material)\n{\n    return czm_getLambertDiffuse(lightDirectionEC, material.normal);\n}\n\nfloat czm_private_getSpecularOfMaterial(vec3 lightDirectionEC, vec3 toEyeEC, czm_material material)\n{\n    return czm_getSpecular(lightDirectionEC, toEyeEC, material.normal, material.shininess);\n}\n\n/**\n * Computes a color using the Phong lighting model.\n *\n * @name czm_phong\n * @glslFunction\n *\n * @param {vec3} toEye A normalized vector from the fragment to the eye in eye coordinates.\n * @param {czm_material} material The fragment's material.\n *\n * @returns {vec4} The computed color.\n *\n * @example\n * vec3 positionToEyeEC = // ...\n * czm_material material = // ...\n * vec3 lightDirectionEC = // ...\n * gl_FragColor = czm_phong(normalize(positionToEyeEC), material, lightDirectionEC);\n *\n * @see czm_getMaterial\n */\nvec4 czm_phong(vec3 toEye, czm_material material, vec3 lightDirectionEC)\n{\n    // Diffuse from directional light sources at eye (for top-down)\n    float diffuse = czm_private_getLambertDiffuseOfMaterial(vec3(0.0, 0.0, 1.0), material);\n    if (czm_sceneMode == czm_sceneMode3D) {\n        // (and horizon views in 3D)\n        diffuse += czm_private_getLambertDiffuseOfMaterial(vec3(0.0, 1.0, 0.0), material);\n    }\n\n    float specular = czm_private_getSpecularOfMaterial(lightDirectionEC, toEye, material);\n\n    // Temporary workaround for adding ambient.\n    vec3 materialDiffuse = material.diffuse * 0.5;\n\n    vec3 ambient = materialDiffuse;\n    vec3 color = ambient + material.emission;\n    color += materialDiffuse * diffuse * czm_lightColor;\n    color += material.specular * specular * czm_lightColor;\n\n    return vec4(color, material.alpha);\n}\n\nvec4 czm_private_phong(vec3 toEye, czm_material material, vec3 lightDirectionEC)\n{\n    float diffuse = czm_private_getLambertDiffuseOfMaterial(lightDirectionEC, material);\n    float specular = czm_private_getSpecularOfMaterial(lightDirectionEC, toEye, material);\n\n    vec3 ambient = vec3(0.0);\n    vec3 color = ambient + material.emission;\n    color += material.diffuse * diffuse * czm_lightColor;\n    color += material.specular * specular * czm_lightColor;\n\n    return vec4(color, material.alpha);\n}\n"},56508:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Computes distance from a point to a plane.\n *\n * @name czm_planeDistance\n * @glslFunction\n *\n * param {vec4} plane A Plane in Hessian Normal Form. See Plane.js\n * param {vec3} point A point in the same space as the plane.\n * returns {float} The distance from the point to the plane.\n */\nfloat czm_planeDistance(vec4 plane, vec3 point) {\n    return (dot(plane.xyz, point) + plane.w);\n}\n\n/**\n * Computes distance from a point to a plane.\n *\n * @name czm_planeDistance\n * @glslFunction\n *\n * param {vec3} planeNormal Normal for a plane in Hessian Normal Form. See Plane.js\n * param {float} planeDistance Distance for a plane in Hessian Normal form. See Plane.js\n * param {vec3} point A point in the same space as the plane.\n * returns {float} The distance from the point to the plane.\n */\nfloat czm_planeDistance(vec3 planeNormal, float planeDistance, vec3 point) {\n    return (dot(planeNormal, point) + planeDistance);\n}\n"},89479:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Computes the point along a ray at the given time.  <code>time</code> can be positive, negative, or zero.\n *\n * @name czm_pointAlongRay\n * @glslFunction\n *\n * @param {czm_ray} ray The ray to compute the point along.\n * @param {float} time The time along the ray.\n * \n * @returns {vec3} The point along the ray at the given time.\n * \n * @example\n * czm_ray ray = czm_ray(vec3(0.0), vec3(1.0, 0.0, 0.0)); // origin, direction\n * vec3 v = czm_pointAlongRay(ray, 2.0); // (2.0, 0.0, 0.0)\n */\nvec3 czm_pointAlongRay(czm_ray ray, float time)\n{\n    return ray.origin + (time * ray.direction);\n}\n"},48297:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * DOC_TBA\n *\n * @name czm_rayEllipsoidIntersectionInterval\n * @glslFunction\n */\nczm_raySegment czm_rayEllipsoidIntersectionInterval(czm_ray ray, vec3 ellipsoid_center, vec3 ellipsoid_inverseRadii)\n{\n   // ray and ellipsoid center in eye coordinates.  radii in model coordinates.\n    vec3 q = ellipsoid_inverseRadii * (czm_inverseModelView * vec4(ray.origin, 1.0)).xyz;\n    vec3 w = ellipsoid_inverseRadii * (czm_inverseModelView * vec4(ray.direction, 0.0)).xyz;\n\n    q = q - ellipsoid_inverseRadii * (czm_inverseModelView * vec4(ellipsoid_center, 1.0)).xyz;\n\n    float q2 = dot(q, q);\n    float qw = dot(q, w);\n\n    if (q2 > 1.0) // Outside ellipsoid.\n    {\n        if (qw >= 0.0) // Looking outward or tangent (0 intersections).\n        {\n            return czm_emptyRaySegment;\n        }\n        else // qw < 0.0.\n        {\n            float qw2 = qw * qw;\n            float difference = q2 - 1.0; // Positively valued.\n            float w2 = dot(w, w);\n            float product = w2 * difference;\n\n            if (qw2 < product) // Imaginary roots (0 intersections).\n            {\n                return czm_emptyRaySegment;\n            }\n            else if (qw2 > product) // Distinct roots (2 intersections).\n            {\n                float discriminant = qw * qw - product;\n                float temp = -qw + sqrt(discriminant); // Avoid cancellation.\n                float root0 = temp / w2;\n                float root1 = difference / temp;\n                if (root0 < root1)\n                {\n                    czm_raySegment i = czm_raySegment(root0, root1);\n                    return i;\n                }\n                else\n                {\n                    czm_raySegment i = czm_raySegment(root1, root0);\n                    return i;\n                }\n            }\n            else // qw2 == product.  Repeated roots (2 intersections).\n            {\n                float root = sqrt(difference / w2);\n                czm_raySegment i = czm_raySegment(root, root);\n                return i;\n            }\n        }\n    }\n    else if (q2 < 1.0) // Inside ellipsoid (2 intersections).\n    {\n        float difference = q2 - 1.0; // Negatively valued.\n        float w2 = dot(w, w);\n        float product = w2 * difference; // Negatively valued.\n        float discriminant = qw * qw - product;\n        float temp = -qw + sqrt(discriminant); // Positively valued.\n        czm_raySegment i = czm_raySegment(0.0, temp / w2);\n        return i;\n    }\n    else // q2 == 1.0. On ellipsoid.\n    {\n        if (qw < 0.0) // Looking inward.\n        {\n            float w2 = dot(w, w);\n            czm_raySegment i = czm_raySegment(0.0, -qw / w2);\n            return i;\n        }\n        else // qw >= 0.0.  Looking outward or tangent.\n        {\n            return czm_emptyRaySegment;\n        }\n    }\n}\n"},2128:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Compute the intersection interval of a ray with a sphere.\n *\n * @name czm_raySphereIntersectionInterval\n * @glslFunction\n *\n * @param {czm_ray} ray The ray.\n * @param {vec3} center The center of the sphere.\n * @param {float} radius The radius of the sphere.\n * @return {czm_raySegment} The intersection interval of the ray with the sphere.\n */\nczm_raySegment czm_raySphereIntersectionInterval(czm_ray ray, vec3 center, float radius)\n{\n    vec3 o = ray.origin;\n    vec3 d = ray.direction;\n\n    vec3 oc = o - center;\n\n    float a = dot(d, d);\n    float b = 2.0 * dot(d, oc);\n    float c = dot(oc, oc) - (radius * radius);\n\n    float det = (b * b) - (4.0 * a * c);\n\n    if (det < 0.0) {\n        return czm_emptyRaySegment;\n    }\n\n    float sqrtDet = sqrt(det);\n\n    float t0 = (-b - sqrtDet) / (2.0 * a);\n    float t1 = (-b + sqrtDet) / (2.0 * a);\n\n    czm_raySegment result = czm_raySegment(t0, t1);\n    return result;\n}\n"},61626:(e,n,t)=>{t.d(n,{Z:()=>o});const o="float czm_readDepth(sampler2D depthTexture, vec2 texCoords)\n{\n    return czm_reverseLogDepth(texture2D(depthTexture, texCoords).r);\n}\n"},84308:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Reads a value previously transformed with {@link czm_writeNonPerspective}\n * by dividing it by `w`, the value used in the perspective divide.\n * This function is intended to be called in a fragment shader to access a\n * `varying` that should not be subject to perspective interpolation.\n * For example, screen-space texture coordinates. The value should have been\n * previously written in the vertex shader with a call to\n * {@link czm_writeNonPerspective}.\n *\n * @name czm_readNonPerspective\n * @glslFunction\n *\n * @param {float|vec2|vec3|vec4} value The non-perspective value to be read.\n * @param {float} oneOverW One over the perspective divide value, `w`. Usually this is simply `gl_FragCoord.w`.\n * @returns {float|vec2|vec3|vec4} The usable value.\n */\nfloat czm_readNonPerspective(float value, float oneOverW) {\n    return value * oneOverW;\n}\n\nvec2 czm_readNonPerspective(vec2 value, float oneOverW) {\n    return value * oneOverW;\n}\n\nvec3 czm_readNonPerspective(vec3 value, float oneOverW) {\n    return value * oneOverW;\n}\n\nvec4 czm_readNonPerspective(vec4 value, float oneOverW) {\n    return value * oneOverW;\n}\n"},94351:(e,n,t)=>{t.d(n,{Z:()=>o});const o="float czm_reverseLogDepth(float logZ)\n{\n#ifdef LOG_DEPTH\n    float near = czm_currentFrustum.x;\n    float far = czm_currentFrustum.y;\n    float log2Depth = logZ * czm_log2FarDepthFromNearPlusOne;\n    float depthFromNear = pow(2.0, log2Depth) - 1.0;\n    return far * (1.0 - near / (depthFromNear + near)) / (far - near);\n#endif\n    return logZ;\n}\n"},78866:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Round a floating point value. This function exists because round() doesn't\n * exist in GLSL 1.00. \n *\n * @param {float|vec2|vec3|vec4} value The value to round\n * @param {float|vec2|vec3|vec3} The rounded value. The type matches the input.\n */\nfloat czm_round(float value) {\n  return floor(value + 0.5);\n}\n\nvec2 czm_round(vec2 value) {\n  return floor(value + 0.5);\n}\n\nvec3 czm_round(vec3 value) {\n  return floor(value + 0.5);\n}\n\nvec4 czm_round(vec4 value) {\n  return floor(value + 0.5);\n}\n"},58445:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Samples the 4 neighboring pixels and return the weighted average.\n *\n * @private\n */\nvec3 czm_sampleOctahedralProjectionWithFiltering(sampler2D projectedMap, vec2 textureSize, vec3 direction, float lod)\n{\n    direction /= dot(vec3(1.0), abs(direction));\n    vec2 rev = abs(direction.zx) - vec2(1.0);\n    vec2 neg = vec2(direction.x < 0.0 ? rev.x : -rev.x,\n                    direction.z < 0.0 ? rev.y : -rev.y);\n    vec2 uv = direction.y < 0.0 ? neg : direction.xz;\n    vec2 coord = 0.5 * uv + vec2(0.5);\n    vec2 pixel = 1.0 / textureSize;\n\n    if (lod > 0.0)\n    {\n        // Each subseqeuent mip level is half the size\n        float scale = 1.0 / pow(2.0, lod);\n        float offset = ((textureSize.y + 1.0) / textureSize.x);\n\n        coord.x *= offset;\n        coord *= scale;\n\n        coord.x += offset + pixel.x;\n        coord.y += (1.0 - (1.0 / pow(2.0, lod - 1.0))) + pixel.y * (lod - 1.0) * 2.0;\n    }\n    else\n    {\n        coord.x *= (textureSize.y / textureSize.x);\n    }\n\n    // Do bilinear filtering\n    #ifndef OES_texture_float_linear\n        vec3 color1 = texture2D(projectedMap, coord + vec2(0.0, pixel.y)).rgb;\n        vec3 color2 = texture2D(projectedMap, coord + vec2(pixel.x, 0.0)).rgb;\n        vec3 color3 = texture2D(projectedMap, coord + pixel).rgb;\n        vec3 color4 = texture2D(projectedMap, coord).rgb;\n\n        vec2 texturePosition = coord * textureSize;\n\n        float fu = fract(texturePosition.x);\n        float fv = fract(texturePosition.y);\n\n        vec3 average1 = mix(color4, color2, fu);\n        vec3 average2 = mix(color1, color3, fu);\n\n        vec3 color = mix(average1, average2, fv);\n    #else\n        vec3 color = texture2D(projectedMap, coord).rgb;\n    #endif\n\n    return color;\n}\n\n\n/**\n * Samples from a cube map that has been projected using an octahedral projection from the given direction.\n *\n * @name czm_sampleOctahedralProjection\n * @glslFunction\n *\n * @param {sampler2D} projectedMap The texture with the octahedral projected cube map.\n * @param {vec2} textureSize The width and height dimensions in pixels of the projected map.\n * @param {vec3} direction The normalized direction used to sample the cube map.\n * @param {float} lod The level of detail to sample.\n * @param {float} maxLod The maximum level of detail.\n * @returns {vec3} The color of the cube map at the direction.\n */\nvec3 czm_sampleOctahedralProjection(sampler2D projectedMap, vec2 textureSize, vec3 direction, float lod, float maxLod) {\n    float currentLod = floor(lod + 0.5);\n    float nextLod = min(currentLod + 1.0, maxLod);\n\n    vec3 colorCurrentLod = czm_sampleOctahedralProjectionWithFiltering(projectedMap, textureSize, direction, currentLod);\n    vec3 colorNextLod = czm_sampleOctahedralProjectionWithFiltering(projectedMap, textureSize, direction, nextLod);\n\n    return mix(colorNextLod, colorCurrentLod, nextLod - lod);\n}\n"},51679:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Adjusts the saturation of a color.\n * \n * @name czm_saturation\n * @glslFunction\n * \n * @param {vec3} rgb The color.\n * @param {float} adjustment The amount to adjust the saturation of the color.\n *\n * @returns {float} The color with the saturation adjusted.\n *\n * @example\n * vec3 greyScale = czm_saturation(color, 0.0);\n * vec3 doubleSaturation = czm_saturation(color, 2.0);\n */\nvec3 czm_saturation(vec3 rgb, float adjustment)\n{\n    // Algorithm from Chapter 16 of OpenGL Shading Language\n    const vec3 W = vec3(0.2125, 0.7154, 0.0721);\n    vec3 intensity = vec3(dot(rgb, W));\n    return mix(intensity, rgb, adjustment);\n}\n"},7205:(e,n,t)=>{t.d(n,{Z:()=>o});const o="\nfloat czm_sampleShadowMap(highp samplerCube shadowMap, vec3 d)\n{\n    return czm_unpackDepth(textureCube(shadowMap, d));\n}\n\nfloat czm_sampleShadowMap(highp sampler2D shadowMap, vec2 uv)\n{\n#ifdef USE_SHADOW_DEPTH_TEXTURE\n    return texture2D(shadowMap, uv).r;\n#else\n    return czm_unpackDepth(texture2D(shadowMap, uv));\n#endif\n}\n\nfloat czm_shadowDepthCompare(samplerCube shadowMap, vec3 uv, float depth)\n{\n    return step(depth, czm_sampleShadowMap(shadowMap, uv));\n}\n\nfloat czm_shadowDepthCompare(sampler2D shadowMap, vec2 uv, float depth)\n{\n    return step(depth, czm_sampleShadowMap(shadowMap, uv));\n}\n"},85724:(e,n,t)=>{t.d(n,{Z:()=>o});const o="\nfloat czm_private_shadowVisibility(float visibility, float nDotL, float normalShadingSmooth, float darkness)\n{\n#ifdef USE_NORMAL_SHADING\n#ifdef USE_NORMAL_SHADING_SMOOTH\n    float strength = clamp(nDotL / normalShadingSmooth, 0.0, 1.0);\n#else\n    float strength = step(0.0, nDotL);\n#endif\n    visibility *= strength;\n#endif\n\n    visibility = max(visibility, darkness);\n    return visibility;\n}\n\n#ifdef USE_CUBE_MAP_SHADOW\nfloat czm_shadowVisibility(samplerCube shadowMap, czm_shadowParameters shadowParameters)\n{\n    float depthBias = shadowParameters.depthBias;\n    float depth = shadowParameters.depth;\n    float nDotL = shadowParameters.nDotL;\n    float normalShadingSmooth = shadowParameters.normalShadingSmooth;\n    float darkness = shadowParameters.darkness;\n    vec3 uvw = shadowParameters.texCoords;\n\n    depth -= depthBias;\n    float visibility = czm_shadowDepthCompare(shadowMap, uvw, depth);\n    return czm_private_shadowVisibility(visibility, nDotL, normalShadingSmooth, darkness);\n}\n#else\nfloat czm_shadowVisibility(sampler2D shadowMap, czm_shadowParameters shadowParameters)\n{\n    float depthBias = shadowParameters.depthBias;\n    float depth = shadowParameters.depth;\n    float nDotL = shadowParameters.nDotL;\n    float normalShadingSmooth = shadowParameters.normalShadingSmooth;\n    float darkness = shadowParameters.darkness;\n    vec2 uv = shadowParameters.texCoords;\n\n    depth -= depthBias;\n#ifdef USE_SOFT_SHADOWS\n    vec2 texelStepSize = shadowParameters.texelStepSize;\n    float radius = 1.0;\n    float dx0 = -texelStepSize.x * radius;\n    float dy0 = -texelStepSize.y * radius;\n    float dx1 = texelStepSize.x * radius;\n    float dy1 = texelStepSize.y * radius;\n    float visibility = (\n        czm_shadowDepthCompare(shadowMap, uv, depth) +\n        czm_shadowDepthCompare(shadowMap, uv + vec2(dx0, dy0), depth) +\n        czm_shadowDepthCompare(shadowMap, uv + vec2(0.0, dy0), depth) +\n        czm_shadowDepthCompare(shadowMap, uv + vec2(dx1, dy0), depth) +\n        czm_shadowDepthCompare(shadowMap, uv + vec2(dx0, 0.0), depth) +\n        czm_shadowDepthCompare(shadowMap, uv + vec2(dx1, 0.0), depth) +\n        czm_shadowDepthCompare(shadowMap, uv + vec2(dx0, dy1), depth) +\n        czm_shadowDepthCompare(shadowMap, uv + vec2(0.0, dy1), depth) +\n        czm_shadowDepthCompare(shadowMap, uv + vec2(dx1, dy1), depth)\n    ) * (1.0 / 9.0);\n#else\n    float visibility = czm_shadowDepthCompare(shadowMap, uv, depth);\n#endif\n\n    return czm_private_shadowVisibility(visibility, nDotL, normalShadingSmooth, darkness);\n}\n#endif\n"},23582:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Returns 1.0 if the given value is positive or zero, and -1.0 if it is negative.  This is similar to the GLSL\n * built-in function <code>sign</code> except that returns 1.0 instead of 0.0 when the input value is 0.0.\n * \n * @name czm_signNotZero\n * @glslFunction\n *\n * @param {} value The value for which to determine the sign.\n * @returns {} 1.0 if the value is positive or zero, -1.0 if the value is negative.\n */\nfloat czm_signNotZero(float value)\n{\n    return value >= 0.0 ? 1.0 : -1.0;\n}\n\nvec2 czm_signNotZero(vec2 value)\n{\n    return vec2(czm_signNotZero(value.x), czm_signNotZero(value.y));\n}\n\nvec3 czm_signNotZero(vec3 value)\n{\n    return vec3(czm_signNotZero(value.x), czm_signNotZero(value.y), czm_signNotZero(value.z));\n}\n\nvec4 czm_signNotZero(vec4 value)\n{\n    return vec4(czm_signNotZero(value.x), czm_signNotZero(value.y), czm_signNotZero(value.z), czm_signNotZero(value.w));\n}\n"},87370:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Computes a color from the third order spherical harmonic coefficients and a normalized direction vector.\n * <p>\n * The order of the coefficients is [L00, L1_1, L10, L11, L2_2, L2_1, L20, L21, L22].\n * </p>\n *\n * @name czm_sphericalHarmonics\n * @glslFunction\n *\n * @param {vec3} normal The normalized direction.\n * @param {vec3[9]} coefficients The third order spherical harmonic coefficients.\n * @returns {vec3} The color at the direction.\n *\n * @see https://graphics.stanford.edu/papers/envmap/envmap.pdf\n */\nvec3 czm_sphericalHarmonics(vec3 normal, vec3 coefficients[9])\n{\n    vec3 L00 = coefficients[0];\n    vec3 L1_1 = coefficients[1];\n    vec3 L10 = coefficients[2];\n    vec3 L11 = coefficients[3];\n    vec3 L2_2 = coefficients[4];\n    vec3 L2_1 = coefficients[5];\n    vec3 L20 = coefficients[6];\n    vec3 L21 = coefficients[7];\n    vec3 L22 = coefficients[8];\n\n    float x = normal.x;\n    float y = normal.y;\n    float z = normal.z;\n\n    return\n          L00\n        + L1_1 * y\n        + L10 * z\n        + L11 * x\n        + L2_2 * (y * x)\n        + L2_1 * (y * z)\n        + L20 * (3.0 * z * z - 1.0)\n        + L21 * (z * x)\n        + L22 * (x * x - y * y);\n}\n"},87446:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Converts an sRGB color to a linear RGB color.\n *\n * @param {vec3|vec4} srgbIn The color in sRGB space\n * @returns {vec3|vec4} The color in linear color space. The vector type matches the input.\n */\nvec3 czm_srgbToLinear(vec3 srgbIn)\n{\n    return pow(srgbIn, vec3(2.2));\n}\n\nvec4 czm_srgbToLinear(vec4 srgbIn) \n{\n    vec3 linearOut = pow(srgbIn.rgb, vec3(2.2));\n    return vec4(linearOut, srgbIn.a);\n}\n"},12275:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Creates a matrix that transforms vectors from tangent space to eye space.\n *\n * @name czm_tangentToEyeSpaceMatrix\n * @glslFunction\n *\n * @param {vec3} normalEC The normal vector in eye coordinates.\n * @param {vec3} tangentEC The tangent vector in eye coordinates.\n * @param {vec3} bitangentEC The bitangent vector in eye coordinates.\n *\n * @returns {mat3} The matrix that transforms from tangent space to eye space.\n *\n * @example\n * mat3 tangentToEye = czm_tangentToEyeSpaceMatrix(normalEC, tangentEC, bitangentEC);\n * vec3 normal = tangentToEye * texture2D(normalMap, st).xyz;\n */\nmat3 czm_tangentToEyeSpaceMatrix(vec3 normalEC, vec3 tangentEC, vec3 bitangentEC)\n{\n    vec3 normal = normalize(normalEC);\n    vec3 tangent = normalize(tangentEC);\n    vec3 bitangent = normalize(bitangentEC);\n    return mat3(tangent.x  , tangent.y  , tangent.z,\n                bitangent.x, bitangent.y, bitangent.z,\n                normal.x   , normal.y   , normal.z);\n}\n"},11471:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Transforms a plane.\n * \n * @name czm_transformPlane\n * @glslFunction\n *\n * @param {vec4} plane The plane in Hessian Normal Form.\n * @param {mat4} transform The inverse-transpose of a transformation matrix.\n */\nvec4 czm_transformPlane(vec4 plane, mat4 transform) {\n    vec4 transformedPlane = transform * plane;\n    // Convert the transformed plane to Hessian Normal Form\n    float normalMagnitude = length(transformedPlane.xyz);\n    return transformedPlane / normalMagnitude;\n}\n"},39391:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Translates a position (or any <code>vec3</code>) that was encoded with {@link EncodedCartesian3},\n * and then provided to the shader as separate <code>high</code> and <code>low</code> bits to\n * be relative to the eye.  As shown in the example, the position can then be transformed in eye\n * or clip coordinates using {@link czm_modelViewRelativeToEye} or {@link czm_modelViewProjectionRelativeToEye},\n * respectively.\n * <p>\n * This technique, called GPU RTE, eliminates jittering artifacts when using large coordinates as\n * described in {@link http://help.agi.com/AGIComponents/html/BlogPrecisionsPrecisions.htm|Precisions, Precisions}.\n * </p>\n *\n * @name czm_translateRelativeToEye\n * @glslFunction\n *\n * @param {vec3} high The position's high bits.\n * @param {vec3} low The position's low bits.\n * @returns {vec3} The position translated to be relative to the camera's position.\n *\n * @example\n * attribute vec3 positionHigh;\n * attribute vec3 positionLow;\n *\n * void main()\n * {\n *   vec4 p = czm_translateRelativeToEye(positionHigh, positionLow);\n *   gl_Position = czm_modelViewProjectionRelativeToEye * p;\n * }\n *\n * @see czm_modelViewRelativeToEye\n * @see czm_modelViewProjectionRelativeToEye\n * @see czm_computePosition\n * @see EncodedCartesian3\n */\nvec4 czm_translateRelativeToEye(vec3 high, vec3 low)\n{\n    vec3 highDifference = high - czm_encodedCameraPositionMCHigh;\n    vec3 lowDifference = low - czm_encodedCameraPositionMCLow;\n\n    return vec4(highDifference + lowDifference, 1.0);\n}\n"},78938:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * @private\n */\nvec4 czm_translucentPhong(vec3 toEye, czm_material material, vec3 lightDirectionEC)\n{\n    // Diffuse from directional light sources at eye (for top-down and horizon views)\n    float diffuse = czm_getLambertDiffuse(vec3(0.0, 0.0, 1.0), material.normal);\n\n    if (czm_sceneMode == czm_sceneMode3D) {\n        // (and horizon views in 3D)\n        diffuse += czm_getLambertDiffuse(vec3(0.0, 1.0, 0.0), material.normal);\n    }\n\n    diffuse = clamp(diffuse, 0.0, 1.0);\n\n    float specular = czm_getSpecular(lightDirectionEC, toEye, material.normal, material.shininess);\n\n    // Temporary workaround for adding ambient.\n    vec3 materialDiffuse = material.diffuse * 0.5;\n\n    vec3 ambient = materialDiffuse;\n    vec3 color = ambient + material.emission;\n    color += materialDiffuse * diffuse * czm_lightColor;\n    color += material.specular * specular * czm_lightColor;\n\n    return vec4(color, material.alpha);\n}\n"},40443:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Returns the transpose of the matrix.  The input <code>matrix</code> can be\n * a <code>mat2</code>, <code>mat3</code>, or <code>mat4</code>.\n *\n * @name czm_transpose\n * @glslFunction\n *\n * @param {} matrix The matrix to transpose.\n *\n * @returns {} The transposed matrix.\n *\n * @example\n * // GLSL declarations\n * mat2 czm_transpose(mat2 matrix);\n * mat3 czm_transpose(mat3 matrix);\n * mat4 czm_transpose(mat4 matrix);\n *\n * // Transpose a 3x3 rotation matrix to find its inverse.\n * mat3 eastNorthUpToEye = czm_eastNorthUpToEyeCoordinates(\n *     positionMC, normalEC);\n * mat3 eyeToEastNorthUp = czm_transpose(eastNorthUpToEye);\n */\nmat2 czm_transpose(mat2 matrix)\n{\n    return mat2(\n        matrix[0][0], matrix[1][0],\n        matrix[0][1], matrix[1][1]);\n}\n\nmat3 czm_transpose(mat3 matrix)\n{\n    return mat3(\n        matrix[0][0], matrix[1][0], matrix[2][0],\n        matrix[0][1], matrix[1][1], matrix[2][1],\n        matrix[0][2], matrix[1][2], matrix[2][2]);\n}\n\nmat4 czm_transpose(mat4 matrix)\n{\n    return mat4(\n        matrix[0][0], matrix[1][0], matrix[2][0], matrix[3][0],\n        matrix[0][1], matrix[1][1], matrix[2][1], matrix[3][1],\n        matrix[0][2], matrix[1][2], matrix[2][2], matrix[3][2],\n        matrix[0][3], matrix[1][3], matrix[2][3], matrix[3][3]);\n}\n"},38033:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Unpacks a vec4 depth value to a float in [0, 1) range.\n *\n * @name czm_unpackDepth\n * @glslFunction\n *\n * @param {vec4} packedDepth The packed depth.\n *\n * @returns {float} The floating-point depth in [0, 1) range.\n */\n float czm_unpackDepth(vec4 packedDepth)\n {\n    // See Aras Pranckevi\u010dius' post Encoding Floats to RGBA\n    // http://aras-p.info/blog/2009/07/30/encoding-floats-to-rgba-the-final/\n    return dot(packedDepth, vec4(1.0, 1.0 / 255.0, 1.0 / 65025.0, 1.0 / 16581375.0));\n }\n"},21285:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Unpack an IEEE 754 single-precision float that is packed as a little-endian unsigned normalized vec4.\n *\n * @name czm_unpackFloat\n * @glslFunction\n *\n * @param {vec4} packedFloat The packed float.\n *\n * @returns {float} The floating-point depth in arbitrary range.\n */\nfloat czm_unpackFloat(vec4 packedFloat)\n{\n    // Convert to [0.0, 255.0] and round to integer\n    packedFloat = floor(packedFloat * 255.0 + 0.5);\n    float sign = 1.0 - step(128.0, packedFloat[3]) * 2.0;\n    float exponent = 2.0 * mod(packedFloat[3], 128.0) + step(128.0, packedFloat[2]) - 127.0;    \n    if (exponent == -127.0)\n    {\n        return 0.0;\n    }\n    float mantissa = mod(packedFloat[2], 128.0) * 65536.0 + packedFloat[1] * 256.0 + packedFloat[0] + float(0x800000);\n    float result = sign * exp2(exponent - 23.0) * mantissa;\n    return result;\n}\n"},32419:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Unpack unsigned integers of 1-4 bytes. in WebGL 1, there is no uint type,\n * so the return value is an int.\n * <p>\n * There are also precision limitations in WebGL 1. highp int is still limited\n * to 24 bits. Above the value of 2^24 = 16777216, precision loss may occur.\n * </p>\n *\n * @param {float|vec2|vec3|vec4} packed The packed value. For vectors, the components are listed in little-endian order.\n *\n * @return {int} The unpacked value.\n */\n int czm_unpackUint(float packedValue) {\n   float rounded = czm_round(packedValue * 255.0);\n   return int(rounded);\n }\n\n int czm_unpackUint(vec2 packedValue) {\n   vec2 rounded = czm_round(packedValue * 255.0);\n   return int(dot(rounded, vec2(1.0, 256.0)));\n }\n\n int czm_unpackUint(vec3 packedValue) {\n   vec3 rounded = czm_round(packedValue * 255.0);\n   return int(dot(rounded, vec3(1.0, 256.0, 65536.0)));\n }\n\n int czm_unpackUint(vec4 packedValue) {\n   vec4 rounded = czm_round(packedValue * 255.0);\n   return int(dot(rounded, vec4(1.0, 256.0, 65536.0, 16777216.0)));\n }\n"},30089:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Transform metadata values following the EXT_structural_metadata spec\n * by multiplying by scale and adding the offset. Operations are always\n * performed component-wise, even for matrices.\n * \n * @param {float|vec2|vec3|vec4|mat2|mat3|mat4} offset The offset to add\n * @param {float|vec2|vec3|vec4|mat2|mat3|mat4} scale The scale factor to multiply\n * @param {float|vec2|vec3|vec4|mat2|mat3|mat4} value The original value.\n *\n * @return {float|vec2|vec3|vec4|mat2|mat3|mat4} The transformed value of the same scalar/vector/matrix type as the input.\n */\nfloat czm_valueTransform(float offset, float scale, float value) {\n  return scale * value + offset;\n}\n\nvec2 czm_valueTransform(vec2 offset, vec2 scale, vec2 value) {\n  return scale * value + offset;\n}\n\nvec3 czm_valueTransform(vec3 offset, vec3 scale, vec3 value) {\n  return scale * value + offset;\n}\n\nvec4 czm_valueTransform(vec4 offset, vec4 scale, vec4 value) {\n  return scale * value + offset;\n}\n\nmat2 czm_valueTransform(mat2 offset, mat2 scale, mat2 value) {\n  return matrixCompMult(scale, value) + offset;\n}\n\nmat3 czm_valueTransform(mat3 offset, mat3 scale, mat3 value) {\n  return matrixCompMult(scale, value) + offset;\n}\n\nmat4 czm_valueTransform(mat4 offset, mat4 scale, mat4 value) {\n  return matrixCompMult(scale, value) + offset;\n}\n"},20355:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef LOG_DEPTH\n// 1.0 at the near plane, increasing linearly from there.\nvarying float v_depthFromNearPlusOne;\n#ifdef SHADOW_MAP\nvarying vec3 v_logPositionEC;\n#endif\n#endif\n\nvec4 czm_updatePositionDepth(vec4 coords) {\n#if defined(LOG_DEPTH)\n\n#ifdef SHADOW_MAP\n    vec3 logPositionEC = (czm_inverseProjection * coords).xyz;\n    v_logPositionEC = logPositionEC;\n#endif\n\n    // With the very high far/near ratios used with the logarithmic depth\n    // buffer, floating point rounding errors can cause linear depth values\n    // to end up on the wrong side of the far plane, even for vertices that\n    // are really nowhere near it. Since we always write a correct logarithmic\n    // depth value in the fragment shader anyway, we just need to make sure\n    // such errors don't cause the primitive to be clipped entirely before\n    // we even get to the fragment shader.\n    coords.z = clamp(coords.z / coords.w, -1.0, 1.0) * coords.w;\n#endif\n\n    return coords;\n}\n\n/**\n * Writes the logarithmic depth to gl_Position using the already computed gl_Position.\n *\n * @name czm_vertexLogDepth\n * @glslFunction\n */\nvoid czm_vertexLogDepth()\n{\n#ifdef LOG_DEPTH\n    v_depthFromNearPlusOne = (gl_Position.w - czm_currentFrustum.x) + 1.0;\n    gl_Position = czm_updatePositionDepth(gl_Position);\n#endif\n}\n\n/**\n * Writes the logarithmic depth to gl_Position using the provided clip coordinates.\n * <p>\n * An example use case for this function would be moving the vertex in window coordinates\n * before converting back to clip coordinates. Use the original vertex clip coordinates.\n * </p>\n * @name czm_vertexLogDepth\n * @glslFunction\n *\n * @param {vec4} clipCoords The vertex in clip coordinates.\n *\n * @example\n * czm_vertexLogDepth(czm_projection * vec4(positionEyeCoordinates, 1.0));\n */\nvoid czm_vertexLogDepth(vec4 clipCoords)\n{\n#ifdef LOG_DEPTH\n    v_depthFromNearPlusOne = (clipCoords.w - czm_currentFrustum.x) + 1.0;\n    czm_updatePositionDepth(clipCoords);\n#endif\n}\n"},97283:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Transforms a position from window to eye coordinates.\n * The transform from window to normalized device coordinates is done using components\n * of (@link czm_viewport} and {@link czm_viewportTransformation} instead of calculating\n * the inverse of <code>czm_viewportTransformation</code>. The transformation from\n * normalized device coordinates to clip coordinates is done using <code>fragmentCoordinate.w</code>,\n * which is expected to be the scalar used in the perspective divide. The transformation\n * from clip to eye coordinates is done using {@link czm_inverseProjection}.\n *\n * @name czm_windowToEyeCoordinates\n * @glslFunction\n *\n * @param {vec4} fragmentCoordinate The position in window coordinates to transform.\n *\n * @returns {vec4} The transformed position in eye coordinates.\n *\n * @see czm_modelToWindowCoordinates\n * @see czm_eyeToWindowCoordinates\n * @see czm_inverseProjection\n * @see czm_viewport\n * @see czm_viewportTransformation\n *\n * @example\n * vec4 positionEC = czm_windowToEyeCoordinates(gl_FragCoord);\n */\nvec4 czm_windowToEyeCoordinates(vec4 fragmentCoordinate)\n{\n    // Reconstruct NDC coordinates\n    float x = 2.0 * (fragmentCoordinate.x - czm_viewport.x) / czm_viewport.z - 1.0;\n    float y = 2.0 * (fragmentCoordinate.y - czm_viewport.y) / czm_viewport.w - 1.0;\n    float z = (fragmentCoordinate.z - czm_viewportTransformation[3][2]) / czm_viewportTransformation[2][2];\n    vec4 q = vec4(x, y, z, 1.0);\n\n    // Reverse the perspective division to obtain clip coordinates.\n    q /= fragmentCoordinate.w;\n\n    // Reverse the projection transformation to obtain eye coordinates.\n    if (!(czm_inverseProjection == mat4(0.0))) // IE and Edge sometimes do something weird with != between mat4s\n    {\n        q = czm_inverseProjection * q;\n    }\n    else\n    {\n        float top = czm_frustumPlanes.x;\n        float bottom = czm_frustumPlanes.y;\n        float left = czm_frustumPlanes.z;\n        float right = czm_frustumPlanes.w;\n\n        float near = czm_currentFrustum.x;\n        float far = czm_currentFrustum.y;\n\n        q.x = (q.x * (right - left) + left + right) * 0.5;\n        q.y = (q.y * (top - bottom) + bottom + top) * 0.5;\n        q.z = (q.z * (near - far) - near - far) * 0.5;\n        q.w = 1.0;\n    }\n\n    return q;\n}\n\n/**\n * Transforms a position given as window x/y and a depth or a log depth from window to eye coordinates.\n * This function produces more accurate results for window positions with log depth than\n * conventionally unpacking the log depth using czm_reverseLogDepth and using the standard version\n * of czm_windowToEyeCoordinates.\n *\n * @name czm_windowToEyeCoordinates\n * @glslFunction\n *\n * @param {vec2} fragmentCoordinateXY The XY position in window coordinates to transform.\n * @param {float} depthOrLogDepth A depth or log depth for the fragment.\n *\n * @see czm_modelToWindowCoordinates\n * @see czm_eyeToWindowCoordinates\n * @see czm_inverseProjection\n * @see czm_viewport\n * @see czm_viewportTransformation\n *\n * @returns {vec4} The transformed position in eye coordinates.\n */\nvec4 czm_windowToEyeCoordinates(vec2 fragmentCoordinateXY, float depthOrLogDepth)\n{\n    // See reverseLogDepth.glsl. This is separate to re-use the pow.\n#ifdef LOG_DEPTH\n    float near = czm_currentFrustum.x;\n    float far = czm_currentFrustum.y;\n    float log2Depth = depthOrLogDepth * czm_log2FarDepthFromNearPlusOne;\n    float depthFromNear = pow(2.0, log2Depth) - 1.0;\n    float depthFromCamera = depthFromNear + near;\n    vec4 windowCoord = vec4(fragmentCoordinateXY, far * (1.0 - near / depthFromCamera) / (far - near), 1.0);\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(windowCoord);\n    eyeCoordinate.w = 1.0 / depthFromCamera; // Better precision\n    return eyeCoordinate;\n#else\n    vec4 windowCoord = vec4(fragmentCoordinateXY, depthOrLogDepth, 1.0);\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(windowCoord);\n#endif\n    return eyeCoordinate;\n}\n"},37088:(e,n,t)=>{t.d(n,{Z:()=>o});const o="// emulated noperspective\n#if defined(GL_EXT_frag_depth) && !defined(LOG_DEPTH)\nvarying float v_WindowZ;\n#endif\n\n/**\n * Emulates GL_DEPTH_CLAMP. Clamps a fragment to the near and far plane\n * by writing the fragment's depth. See czm_depthClamp for more details.\n * <p>\n * The shader must enable the GL_EXT_frag_depth extension.\n * </p>\n *\n * @name czm_writeDepthClamp\n * @glslFunction\n *\n * @example\n * gl_FragColor = color;\n * czm_writeDepthClamp();\n *\n * @see czm_depthClamp\n */\nvoid czm_writeDepthClamp()\n{\n#if defined(GL_EXT_frag_depth) && !defined(LOG_DEPTH)\n    gl_FragDepthEXT = clamp(v_WindowZ * gl_FragCoord.w, 0.0, 1.0);\n#endif\n}\n"},5417:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef LOG_DEPTH\nvarying float v_depthFromNearPlusOne;\n\n#ifdef POLYGON_OFFSET\nuniform vec2 u_polygonOffset;\n#endif\n\n#endif\n\n/**\n * Writes the fragment depth to the logarithmic depth buffer.\n * <p>\n * Use this when the vertex shader does not call {@link czm_vertexlogDepth}, for example, when\n * ray-casting geometry using a full screen quad.\n * </p>\n * @name czm_writeLogDepth\n * @glslFunction\n *\n * @param {float} depth The depth coordinate, where 1.0 is on the near plane and\n *                      depth increases in eye-space units from there\n *\n * @example\n * czm_writeLogDepth((czm_projection * v_positionEyeCoordinates).w + 1.0);\n */\nvoid czm_writeLogDepth(float depth)\n{\n#if defined(GL_EXT_frag_depth) && defined(LOG_DEPTH)\n    // Discard the vertex if it's not between the near and far planes.\n    // We allow a bit of epsilon on the near plane comparison because a 1.0\n    // from the vertex shader (indicating the vertex should be _on_ the near\n    // plane) will not necessarily come here as exactly 1.0.\n    if (depth <= 0.9999999 || depth > czm_farDepthFromNearPlusOne) {\n        discard;\n    }\n\n#ifdef POLYGON_OFFSET\n    // Polygon offset: m * factor + r * units\n    float factor = u_polygonOffset[0];\n    float units = u_polygonOffset[1];\n\n    // If we can't compute derivatives, just leave out the factor I guess?\n#ifdef GL_OES_standard_derivatives\n    // m = sqrt(dZdX^2 + dZdY^2);\n    float x = dFdx(depth);\n    float y = dFdy(depth);\n    float m = sqrt(x * x + y * y);\n\n    // Apply the factor before computing the log depth.\n    depth += m * factor;\n#endif\n\n#endif\n\n    gl_FragDepthEXT = log2(depth) * czm_oneOverLog2FarDepthFromNearPlusOne;\n\n#ifdef POLYGON_OFFSET\n    // Apply the units after the log depth.\n    gl_FragDepthEXT += czm_epsilon7 * units;\n#endif\n\n#endif\n}\n\n/**\n * Writes the fragment depth to the logarithmic depth buffer.\n * <p>\n * Use this when the vertex shader calls {@link czm_vertexlogDepth}.\n * </p>\n *\n * @name czm_writeLogDepth\n * @glslFunction\n */\nvoid czm_writeLogDepth() {\n#ifdef LOG_DEPTH\n    czm_writeLogDepth(v_depthFromNearPlusOne);\n#endif\n}\n"},10548:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Transforms a value for non-perspective interpolation by multiplying\n * it by w, the value used in the perspective divide. This function is\n * intended to be called in a vertex shader to compute the value of a\n * `varying` that should not be subject to perspective interpolation.\n * For example, screen-space texture coordinates. The fragment shader\n * must call {@link czm_readNonPerspective} to retrieve the final\n * non-perspective value.\n *\n * @name czm_writeNonPerspective\n * @glslFunction\n *\n * @param {float|vec2|vec3|vec4} value The value to be interpolated without accounting for perspective.\n * @param {float} w The perspective divide value. Usually this is the computed `gl_Position.w`.\n * @returns {float|vec2|vec3|vec4} The transformed value, intended to be stored in a `varying` and read in the\n *          fragment shader with {@link czm_readNonPerspective}.\n */\nfloat czm_writeNonPerspective(float value, float w) {\n    return value * w;\n}\n\nvec2 czm_writeNonPerspective(vec2 value, float w) {\n    return value * w;\n}\n\nvec3 czm_writeNonPerspective(vec3 value, float w) {\n    return value * w;\n}\n\nvec4 czm_writeNonPerspective(vec4 value, float w) {\n    return value * w;\n}\n"},42103:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * @name czm_depthRangeStruct\n * @glslStruct\n */\nstruct czm_depthRangeStruct\n{\n    float near;\n    float far;\n};\n"},64808:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Holds material information that can be used for lighting. Returned by all czm_getMaterial functions.\n *\n * @name czm_material\n * @glslStruct\n *\n * @property {vec3} diffuse Incoming light that scatters evenly in all directions.\n * @property {float} specular Intensity of incoming light reflecting in a single direction.\n * @property {float} shininess The sharpness of the specular reflection.  Higher values create a smaller, more focused specular highlight.\n * @property {vec3} normal Surface's normal in eye coordinates. It is used for effects such as normal mapping. The default is the surface's unmodified normal.\n * @property {vec3} emission Light emitted by the material equally in all directions. The default is vec3(0.0), which emits no light.\n * @property {float} alpha Alpha of this material. 0.0 is completely transparent; 1.0 is completely opaque.\n */\nstruct czm_material\n{\n    vec3 diffuse;\n    float specular;\n    float shininess;\n    vec3 normal;\n    vec3 emission;\n    float alpha;\n};\n"},56553:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Used as input to every material's czm_getMaterial function.\n *\n * @name czm_materialInput\n * @glslStruct\n *\n * @property {float} s 1D texture coordinates.\n * @property {vec2} st 2D texture coordinates.\n * @property {vec3} str 3D texture coordinates.\n * @property {vec3} normalEC Unperturbed surface normal in eye coordinates.\n * @property {mat3} tangentToEyeMatrix Matrix for converting a tangent space normal to eye space.\n * @property {vec3} positionToEyeEC Vector from the fragment to the eye in eye coordinates.  The magnitude is the distance in meters from the fragment to the eye.\n * @property {float} height The height of the terrain in meters above or below the WGS84 ellipsoid.  Only available for globe materials.\n * @property {float} slope The slope of the terrain in radians.  0 is flat; pi/2 is vertical.  Only available for globe materials.\n * @property {float} aspect The aspect of the terrain in radians.  0 is East, pi/2 is North, pi is West, 3pi/2 is South.  Only available for globe materials.\n */\nstruct czm_materialInput\n{\n    float s;\n    vec2 st;\n    vec3 str;\n    vec3 normalEC;\n    mat3 tangentToEyeMatrix;\n    vec3 positionToEyeEC;\n    float height;\n    float slope;\n    float aspect;\n};\n"},22106:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Struct for representing a material for a {@link ModelExperimental}. The model\n * rendering pipeline will pass this struct between material, custom shaders,\n * and lighting stages. This is not to be confused with {@link czm_material}\n * which is used by the older Fabric materials system, although they are similar\n *\n * @name czm_modelMaterial\n * @glslStruct\n *\n * @property {vec3} diffuse Incoming light that scatters evenly in all directions.\n * @property {float} alpha Alpha of this material. 0.0 is completely transparent; 1.0 is completely opaque.\n * @property {vec3} specular Color of reflected light at normal incidence in PBR materials. This is sometimes referred to as f0 in the literature.\n * @property {float} roughness A number from 0.0 to 1.0 representing how rough the surface is. Values near 0.0 produce glossy surfaces, while values near 1.0 produce rough surfaces.\n * @property {vec3} normalEC Surface's normal in eye coordinates. It is used for effects such as normal mapping. The default is the surface's unmodified normal.\n * @property {float} occlusion Ambient occlusion recieved at this point on the material. 1.0 means fully lit, 0.0 means fully occluded.\n * @property {vec3} emissive Light emitted by the material equally in all directions. The default is vec3(0.0), which emits no light.\n */\nstruct czm_modelMaterial {\n    vec3 diffuse;\n    float alpha;\n    vec3 specular;\n    float roughness;\n    vec3 normalEC;\n    float occlusion;\n    vec3 emissive;\n};\n"},92629:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Struct for representing the output of a custom vertex shader.\n * \n * @name czm_modelVertexOutput\n * @glslStruct\n *\n * @see {@link CustomShader}\n * @see {@link ModelExperimental}\n *\n * @property {vec3} positionMC The position of the vertex in model coordinates\n * @property {float} pointSize A custom value for gl_PointSize. This is only used for point primitives. \n */\nstruct czm_modelVertexOutput {\n  vec3 positionMC;\n  float pointSize;\n};\n"},70193:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Parameters for {@link czm_pbrLighting}\n *\n * @name czm_material\n * @glslStruct\n *\n * @property {vec3} diffuseColor the diffuse color of the material for the lambert term of the rendering equation\n * @property {float} roughness a value from 0.0 to 1.0 that indicates how rough the surface of the material is.\n * @property {vec3} f0 The reflectance of the material at normal incidence\n */\nstruct czm_pbrParameters\n{\n    vec3 diffuseColor;\n    float roughness;\n    vec3 f0;\n};\n"},39524:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * DOC_TBA\n *\n * @name czm_ray\n * @glslStruct\n */\nstruct czm_ray\n{\n    vec3 origin;\n    vec3 direction;\n};\n"},5878:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * DOC_TBA\n *\n * @name czm_raySegment\n * @glslStruct\n */\nstruct czm_raySegment\n{\n    float start;\n    float stop;\n};\n\n/**\n * DOC_TBA\n *\n * @name czm_emptyRaySegment\n * @glslConstant \n */\nconst czm_raySegment czm_emptyRaySegment = czm_raySegment(-czm_infinity, -czm_infinity);\n\n/**\n * DOC_TBA\n *\n * @name czm_fullRaySegment\n * @glslConstant \n */\nconst czm_raySegment czm_fullRaySegment = czm_raySegment(0.0, czm_infinity);\n"},78531:(e,n,t)=>{t.d(n,{Z:()=>o});const o="struct czm_shadowParameters\n{\n#ifdef USE_CUBE_MAP_SHADOW\n    vec3 texCoords;\n#else\n    vec2 texCoords;\n#endif\n\n    float depthBias;\n    float depth;\n    float nDotL;\n    vec2 texelStepSize;\n    float normalShadingSmooth;\n    float darkness;\n};\n"},10631:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D u_noiseTexture;\nuniform vec3 u_noiseTextureDimensions;\nuniform float u_noiseDetail;\nvarying vec2 v_offset;\nvarying vec3 v_maximumSize;\nvarying vec4 v_color;\nvarying float v_slice;\nvarying float v_brightness;\n\nfloat wrap(float value, float rangeLength) {\n    if(value < 0.0) {\n        float absValue = abs(value);\n        float modValue = mod(absValue, rangeLength);\n        return mod(rangeLength - modValue, rangeLength);\n    }\n    return mod(value, rangeLength);\n}\n\nvec3 wrapVec(vec3 value, float rangeLength) {\n    return vec3(wrap(value.x, rangeLength),\n                wrap(value.y, rangeLength),\n                wrap(value.z, rangeLength));\n}\n\nfloat textureSliceWidth = u_noiseTextureDimensions.x;\nfloat noiseTextureRows = u_noiseTextureDimensions.y;\nfloat inverseNoiseTextureRows = u_noiseTextureDimensions.z;\n\nfloat textureSliceWidthSquared = textureSliceWidth * textureSliceWidth;\nvec2 inverseNoiseTextureDimensions = vec2(noiseTextureRows / textureSliceWidthSquared,\n                                          inverseNoiseTextureRows / textureSliceWidth);\n\nvec2 voxelToUV(vec3 voxelIndex) {\n    vec3 wrappedIndex = wrapVec(voxelIndex, textureSliceWidth);\n    float column = mod(wrappedIndex.z, textureSliceWidth * inverseNoiseTextureRows);\n    float row = floor(wrappedIndex.z / textureSliceWidth * noiseTextureRows);\n\n    float xPixelCoord = wrappedIndex.x + column * textureSliceWidth;\n    float yPixelCoord = wrappedIndex.y + row * textureSliceWidth;\n    return vec2(xPixelCoord, yPixelCoord) * inverseNoiseTextureDimensions;\n}\n\n// Interpolate a voxel with its neighbor (along the positive X-axis)\nvec4 lerpSamplesX(vec3 voxelIndex, float x) {\n    vec2 uv0 = voxelToUV(voxelIndex);\n    vec2 uv1 = voxelToUV(voxelIndex + vec3(1.0, 0.0, 0.0));\n    vec4 sample0 = texture2D(u_noiseTexture, uv0);\n    vec4 sample1 = texture2D(u_noiseTexture, uv1);\n    return mix(sample0, sample1, x);\n}\n\nvec4 sampleNoiseTexture(vec3 position) {\n    vec3 recenteredPos = position + vec3(textureSliceWidth / 2.0);\n    vec3 lerpValue = fract(recenteredPos);\n    vec3 voxelIndex = floor(recenteredPos);\n\n    vec4 xLerp00 = lerpSamplesX(voxelIndex, lerpValue.x);\n    vec4 xLerp01 = lerpSamplesX(voxelIndex + vec3(0.0, 0.0, 1.0), lerpValue.x);\n    vec4 xLerp10 = lerpSamplesX(voxelIndex + vec3(0.0, 1.0, 0.0), lerpValue.x);\n    vec4 xLerp11 = lerpSamplesX(voxelIndex + vec3(0.0, 1.0, 1.0), lerpValue.x);\n\n    vec4 yLerp0 = mix(xLerp00, xLerp10, lerpValue.y);\n    vec4 yLerp1 = mix(xLerp01, xLerp11, lerpValue.y);\n    return mix(yLerp0, yLerp1, lerpValue.z);\n}\n\n// Intersection with a unit sphere with radius 0.5 at center (0, 0, 0).\nbool intersectSphere(vec3 origin, vec3 dir, float slice,\n                     out vec3 point, out vec3 normal) {\n    float A = dot(dir, dir);\n    float B = dot(origin, dir);\n    float C = dot(origin, origin) - 0.25;\n    float discriminant = (B * B) - (A * C);\n    if(discriminant < 0.0) {\n        return false;\n    }\n    float root = sqrt(discriminant);\n    float t = (-B - root) / A;\n    if(t < 0.0) {\n        t = (-B + root) / A;\n    }\n    point = origin + t * dir;\n\n    if(slice >= 0.0) {\n        point.z = (slice / 2.0) - 0.5;\n        if(length(point) > 0.5) {\n            return false;\n        }\n    }\n\n    normal = normalize(point);\n    point -= czm_epsilon2 * normal;\n    return true;\n}\n\n// Transforms the ray origin and direction into unit sphere space,\n// then transforms the result back into the ellipsoid's space.\nbool intersectEllipsoid(vec3 origin, vec3 dir, vec3 center, vec3 scale, float slice,\n                        out vec3 point, out vec3 normal) {\n    if(scale.x <= 0.01 || scale.y < 0.01 || scale.z < 0.01) {\n        return false;\n    }\n\n    vec3 o = (origin - center) / scale;\n    vec3 d = dir / scale;\n    vec3 p, n;\n    bool intersected = intersectSphere(o, d, slice, p, n);\n    if(intersected) {\n        point = (p * scale) + center;\n        normal = n;\n    }\n    return intersected;\n}\n\n// Assume that if phase shift is being called for octave i,\n// the frequency is of i - 1. This saves us from doing extra\n// division / multiplication operations.\nvec2 phaseShift2D(vec2 p, vec2 freq) {\n    return (czm_pi / 2.0) * sin(freq.yx * p.yx);\n}\n\nvec2 phaseShift3D(vec3 p, vec2 freq) {\n    return phaseShift2D(p.xy, freq) + czm_pi * vec2(sin(freq.x * p.z));\n}\n\n// The cloud texture function derived from Gardner's 1985 paper,\n// \"Visual Simulation of Clouds.\"\n// https://www.cs.drexel.edu/~david/Classes/Papers/p297-gardner.pdf\nconst float T0    = 0.6;  // contrast of the texture pattern\nconst float k     = 0.1;  // computed to produce a maximum value of 1\nconst float C0    = 0.8;  // coefficient\nconst float FX0   = 0.6;  // frequency X\nconst float FY0   = 0.6;  // frequency Y\nconst int octaves = 5;\n\nfloat T(vec3 point) {\n    vec2 sum = vec2(0.0);\n    float Ci = C0;\n    vec2 FXY = vec2(FX0, FY0);\n    vec2 PXY = vec2(0.0);\n    for(int i = 1; i <= octaves; i++) {\n        PXY = phaseShift3D(point, FXY);\n        Ci *= 0.707;\n        FXY *= 2.0;\n        vec2 sinTerm = sin(FXY * point.xy + PXY);\n        sum += Ci * sinTerm + vec2(T0);\n    }\n    return k * sum.x * sum.y;\n}\n\nconst float a = 0.5;  // fraction of surface reflection due to ambient or scattered light,\nconst float t = 0.4;  // fraction of texture shading\nconst float s = 0.25; // fraction of specular reflection\n\nfloat I(float Id, float Is, float It) {\n    return (1.0 - a) * ((1.0 - t) * ((1.0 - s) * Id + s * Is) + t * It) + a;\n}\n\nconst vec3 lightDir = normalize(vec3(0.2, -1.0, 0.7));\n\nvec4 drawCloud(vec3 rayOrigin, vec3 rayDir, vec3 cloudCenter, vec3 cloudScale, float cloudSlice,\n               float brightness) {\n    vec3 cloudPoint, cloudNormal;\n    if(!intersectEllipsoid(rayOrigin, rayDir, cloudCenter, cloudScale, cloudSlice,\n                            cloudPoint, cloudNormal)) {\n        return vec4(0.0);\n    }\n\n    float Id = clamp(dot(cloudNormal, -lightDir), 0.0, 1.0);  // diffuse reflection\n    float Is = max(pow(dot(-lightDir, -rayDir), 2.0), 0.0);   // specular reflection\n    float It = T(cloudPoint);                                 // texture function\n    float intensity = I(Id, Is, It);\n    vec3 color = vec3(intensity * clamp(brightness, 0.1, 1.0));\n\n    vec4 noise = sampleNoiseTexture(u_noiseDetail * cloudPoint);\n    float W = noise.x;\n    float W2 = noise.y;\n    float W3 = noise.z;\n\n    // The dot product between the cloud's normal and the ray's direction is greatest\n    // in the center of the ellipsoid's surface. It decreases towards the edge.\n    // Thus, it is used to blur the areas leading to the edges of the ellipsoid,\n    // so that no harsh lines appear.\n\n    // The first (and biggest) layer of worley noise is then subtracted from this.\n    // The final result is scaled up so that the base cloud is not too translucent.\n    float ndDot = clamp(dot(cloudNormal, -rayDir), 0.0, 1.0);\n    float TR = pow(ndDot, 3.0) - W; // translucency\n    TR *= 1.3;\n\n    // Subtracting the second and third layers of worley noise is more complicated.\n    // If these layers of noise were simply subtracted from the current translucency,\n    // the shape derived from the first layer of noise would be completely deleted.\n    // The erosion of this noise should thus be constricted to the edges of the cloud.\n    // However, because the edges of the ellipsoid were already blurred away, mapping\n    // the noise to (1.0 - ndDot) will have no impact on most of the cloud's appearance.\n    // The value of (0.5 - ndDot) provides the best compromise.\n    float minusDot = 0.5 - ndDot;\n\n    // Even with the previous calculation, subtracting the second layer of wnoise\n    // erode too much of the cloud. The addition of it, however, will detailed\n    // volume to the cloud. As long as the noise is only added and not subtracted,\n    // the results are aesthetically pleasing.\n\n    // The minusDot product is mapped in a way that it is larger at the edges of\n    // the ellipsoid, so a subtraction and min operation are used instead of\n    // an addition and max one.\n    TR -= min(minusDot * W2, 0.0);\n\n    // The third level of worley noise is subtracted from the result, with some\n    // modifications. First, a scalar is added to minusDot so that the noise\n    // starts affecting the shape farther away from the center of the ellipsoid's\n    // surface. Then, it is scaled down so its impact is not too intense.\n    TR -= 0.8 * (minusDot + 0.25) * W3;\n\n    // The texture function's shading does not correlate with the shape of the cloud\n    // produced by the layers of noise, so an extra shading scalar is calculated.\n    // The darkest areas of the cloud are assigned to be where the noise erodes\n    // the cloud the most. This is then interpolated based on the translucency\n    // and the diffuse shading term of that point in the cloud.\n    float shading = mix(1.0 - 0.8 * W * W, 1.0, Id * TR);\n\n    // To avoid values that are too dark, this scalar is increased by a small amount\n    // and clamped so it never goes to zero.\n    shading = clamp(shading + 0.2, 0.3, 1.0);\n\n    // Finally, the contrast of the cloud's color is increased.\n    vec3 finalColor = mix(vec3(0.5), shading * color, 1.15);\n    return vec4(finalColor, clamp(TR, 0.0, 1.0)) * v_color;\n}\n\nvoid main() {\n#ifdef DEBUG_BILLBOARDS\n    gl_FragColor = vec4(0.0, 0.5, 0.5, 1.0);\n#endif\n    // To avoid calculations with high values,\n    // we raycast from an arbitrarily smaller space.\n    vec2 coordinate = v_maximumSize.xy * v_offset;\n\n    vec3 ellipsoidScale = 0.82 * v_maximumSize;\n    vec3 ellipsoidCenter = vec3(0.0);\n\n    float zOffset = max(ellipsoidScale.z - 10.0, 0.0);\n    vec3 eye = vec3(0, 0, -10.0 - zOffset);\n    vec3 rayDir = normalize(vec3(coordinate, 1.0) - eye);\n    vec3 rayOrigin = eye;\n#ifdef DEBUG_ELLIPSOIDS\n    vec3 point, normal;\n    if(intersectEllipsoid(rayOrigin, rayDir, ellipsoidCenter, ellipsoidScale, v_slice,\n                          point, normal)) {\n        gl_FragColor = v_brightness * v_color;\n    }\n#else\n#ifndef DEBUG_BILLBOARDS\n    vec4 cloud = drawCloud(rayOrigin, rayDir,\n                           ellipsoidCenter, ellipsoidScale, v_slice, v_brightness);\n    if(cloud.w < 0.01) {\n        discard;\n    }\n    gl_FragColor = cloud;\n#endif\n#endif\n}\n"},74650:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef INSTANCED\nattribute vec2 direction;\n#endif\nattribute vec4 positionHighAndScaleX;\nattribute vec4 positionLowAndScaleY;\nattribute vec4 packedAttribute0;\nattribute vec4 packedAttribute1;\nattribute vec4 color;\n\nvarying vec2 v_offset;\nvarying vec3 v_maximumSize;\nvarying vec4 v_color;\nvarying float v_slice;\nvarying float v_brightness;\n\nvoid main() {\n    // Unpack attributes.\n    vec3 positionHigh = positionHighAndScaleX.xyz;\n    vec3 positionLow = positionLowAndScaleY.xyz;\n    vec2 scale = vec2(positionHighAndScaleX.w, positionLowAndScaleY.w);\n\n    float show = packedAttribute0.x;\n    float brightness = packedAttribute0.y;\n    vec2 coordinates = packedAttribute0.wz;\n    vec3 maximumSize = packedAttribute1.xyz;\n    float slice = packedAttribute1.w;\n\n#ifdef INSTANCED\n    vec2 dir = direction;\n#else\n    vec2 dir = coordinates;\n#endif\n\n    vec2 offset = dir - vec2(0.5, 0.5);\n    vec2 scaledOffset = scale * offset;\n    vec4 p = czm_translateRelativeToEye(positionHigh, positionLow);\n    vec4 positionEC = czm_modelViewRelativeToEye * p;\n    positionEC.xy += scaledOffset;\n    \n    positionEC.xyz *= show;\n    gl_Position = czm_projection * positionEC;\n\n    v_offset = offset;\n    v_maximumSize = maximumSize;\n    v_color = color;\n    v_slice = slice;\n    v_brightness = brightness;\n}\n"},21766:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform vec3 u_noiseTextureDimensions;\nuniform float u_noiseDetail;\nuniform vec3 u_noiseOffset;\nvarying vec2 v_position;\n\nfloat textureSliceWidth = u_noiseTextureDimensions.x;\nfloat inverseNoiseTextureRows = u_noiseTextureDimensions.z;\n\nfloat wrap(float value, float rangeLength) {\n    if(value < 0.0) {\n        float absValue = abs(value);\n        float modValue = mod(absValue, rangeLength);\n        return mod(rangeLength - modValue, rangeLength);\n    }\n    return mod(value, rangeLength);\n}\n\nvec3 wrapVec(vec3 value, float rangeLength) {\n    return vec3(wrap(value.x, rangeLength),\n                wrap(value.y, rangeLength),\n                wrap(value.z, rangeLength));\n}\n\nvec3 random3(vec3 p) {\n    float dot1 = dot(p, vec3(127.1, 311.7, 932.8));\n    float dot2 = dot(p, vec3(269.5, 183.3, 421.4));\n    return fract(vec3(sin(dot1 - dot2), cos(dot1 * dot2), dot1 * dot2));\n}\n\n// Frequency corresponds to cell size.\n// The higher the frequency, the smaller the cell size.\nvec3 getWorleyCellPoint(vec3 centerCell, vec3 offset, float freq) {\n    vec3 cell = centerCell + offset;\n    cell = wrapVec(cell, textureSliceWidth / u_noiseDetail);\n    cell += floor(u_noiseOffset / u_noiseDetail);\n    vec3 p = offset + random3(cell);\n    return p;\n}\n\nfloat worleyNoise(vec3 p, float freq) {\n    vec3 centerCell = floor(p * freq);\n    vec3 pointInCell = fract(p * freq);\n    float shortestDistance = 1000.0;\n\n    for(float z = -1.0; z <= 1.0; z++) {\n        for(float y = -1.0; y <= 1.0; y++) {\n            for(float x = -1.0; x <= 1.0; x++) {\n                vec3 offset = vec3(x, y, z);\n                vec3 point = getWorleyCellPoint(centerCell, offset, freq);\n\n                float distance = length(pointInCell - point);\n                if(distance < shortestDistance) {\n                    shortestDistance = distance;\n                }\n            }\n        }\n    }\n\n    return shortestDistance;\n}\n\nconst float MAX_FBM_ITERATIONS = 10.0;\n\nfloat worleyFBMNoise(vec3 p, float octaves, float scale) {\n    float noise = 0.0;\n    float freq = 1.0;\n    float persistence = 0.625;\n    for(float i = 0.0; i < MAX_FBM_ITERATIONS; i++) {\n        if(i >= octaves) {\n            break;\n        }\n\n        noise += worleyNoise(p * scale, freq * scale) * persistence;\n        persistence *= 0.5;\n        freq *= 2.0;\n    }\n    return noise;\n}\n\nvoid main() {\n    float x = mod(v_position.x, textureSliceWidth);\n    float y = mod(v_position.y, textureSliceWidth);\n    float sliceRow = floor(v_position.y / textureSliceWidth);\n    float z = floor(v_position.x / textureSliceWidth) + sliceRow * inverseNoiseTextureRows * textureSliceWidth;\n\n    vec3 position = vec3(x, y, z);\n    position /= u_noiseDetail;\n    float worley0 = clamp(worleyFBMNoise(position, 3.0, 1.0), 0.0, 1.0);\n    float worley1 = clamp(worleyFBMNoise(position, 3.0, 2.0), 0.0, 1.0);\n    float worley2 = clamp(worleyFBMNoise(position, 3.0, 3.0), 0.0, 1.0);\n    gl_FragColor = vec4(worley0, worley1, worley2, 1.0);\n}\n"},41749:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform vec3 u_noiseTextureDimensions;\nattribute vec2 position;\n\nvarying vec2 v_position;\n\nvoid main()\n{\n    gl_Position = vec4(position, 0.1, 1.0);\n\n    float textureSliceWidth = u_noiseTextureDimensions.x;\n    float noiseTextureRows = u_noiseTextureDimensions.y;\n    float inverseNoiseTextureRows = u_noiseTextureDimensions.z;\n    vec2 transformedPos = (position * 0.5) + vec2(0.5);\n    transformedPos *= textureSliceWidth;\n    transformedPos.x *= textureSliceWidth * inverseNoiseTextureRows;\n    transformedPos.y *= noiseTextureRows;\n    v_position = transformedPos;\n}\n"},28814:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D u_opaqueDepthTexture;\nuniform sampler2D u_translucentDepthTexture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    float opaqueDepth = texture2D(u_opaqueDepthTexture, v_textureCoordinates).r;\n    float translucentDepth = texture2D(u_translucentDepthTexture, v_textureCoordinates).r;\n    translucentDepth = czm_branchFreeTernary(translucentDepth > opaqueDepth, 1.0, translucentDepth);\n    gl_FragColor = czm_packDepth(translucentDepth);\n}\n"},37701:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * Compositing for Weighted Blended Order-Independent Transparency. See:\n * - http://jcgt.org/published/0002/02/09/\n * - http://casual-effects.blogspot.com/2014/03/weighted-blended-order-independent.html\n */\n\nuniform sampler2D u_opaque;\nuniform sampler2D u_accumulation;\nuniform sampler2D u_revealage;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    vec4 opaque = texture2D(u_opaque, v_textureCoordinates);\n    vec4 accum = texture2D(u_accumulation, v_textureCoordinates);\n    float r = texture2D(u_revealage, v_textureCoordinates).r;\n\n#ifdef MRT\n    vec4 transparent = vec4(accum.rgb / clamp(r, 1e-4, 5e4), accum.a);\n#else\n    vec4 transparent = vec4(accum.rgb / clamp(accum.a, 1e-4, 5e4), r);\n#endif\n\n    gl_FragColor = (1.0 - transparent.a) * transparent + transparent.a * opaque;\n\n    if (opaque != czm_backgroundColor)\n    {\n        gl_FragColor.a = 1.0;\n    }\n}\n"},3824:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec4 positionEC;\n\nvoid main()\n{\n    vec3 position;\n    vec3 direction;\n    if (czm_orthographicIn3D == 1.0)\n    {\n        vec2 uv = (gl_FragCoord.xy -  czm_viewport.xy) / czm_viewport.zw;\n        vec2 minPlane = vec2(czm_frustumPlanes.z, czm_frustumPlanes.y); // left, bottom\n        vec2 maxPlane = vec2(czm_frustumPlanes.w, czm_frustumPlanes.x); // right, top\n        position = vec3(mix(minPlane, maxPlane, uv), 0.0);\n        direction = vec3(0.0, 0.0, -1.0);\n    } \n    else \n    {\n        position = vec3(0.0);\n        direction = normalize(positionEC.xyz);\n    }\n\n    czm_ray ray = czm_ray(position, direction);\n\n    vec3 ellipsoid_center = czm_view[3].xyz;\n\n    czm_raySegment intersection = czm_rayEllipsoidIntersectionInterval(ray, ellipsoid_center, czm_ellipsoidInverseRadii);\n    if (!czm_isEmpty(intersection))\n    {\n        gl_FragColor = vec4(1.0, 1.0, 0.0, 1.0);\n    }\n    else\n    {\n        discard;\n    }\n\n    czm_writeLogDepth();\n}\n"},86043:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec4 position;\n\nvarying vec4 positionEC;\n\nvoid main()\n{\n    positionEC = czm_modelView * position;\n    gl_Position = czm_projection * positionEC;\n\n    czm_vertexLogDepth();\n}\n"},74835:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef WRITE_DEPTH\n#ifdef GL_EXT_frag_depth\n#extension GL_EXT_frag_depth : enable\n#endif\n#endif\n\nuniform vec3 u_radii;\nuniform vec3 u_oneOverEllipsoidRadiiSquared;\n\nvarying vec3 v_positionEC;\n\nvec4 computeEllipsoidColor(czm_ray ray, float intersection, float side)\n{\n    vec3 positionEC = czm_pointAlongRay(ray, intersection);\n    vec3 positionMC = (czm_inverseModelView * vec4(positionEC, 1.0)).xyz;\n    vec3 geodeticNormal = normalize(czm_geodeticSurfaceNormal(positionMC, vec3(0.0), u_oneOverEllipsoidRadiiSquared));\n    vec3 sphericalNormal = normalize(positionMC / u_radii);\n    vec3 normalMC = geodeticNormal * side;              // normalized surface normal (always facing the viewer) in model coordinates\n    vec3 normalEC = normalize(czm_normal * normalMC);   // normalized surface normal in eye coordiantes\n\n    vec2 st = czm_ellipsoidWgs84TextureCoordinates(sphericalNormal);\n    vec3 positionToEyeEC = -positionEC;\n\n    czm_materialInput materialInput;\n    materialInput.s = st.s;\n    materialInput.st = st;\n    materialInput.str = (positionMC + u_radii) / u_radii;\n    materialInput.normalEC = normalEC;\n    materialInput.tangentToEyeMatrix = czm_eastNorthUpToEyeCoordinates(positionMC, normalEC);\n    materialInput.positionToEyeEC = positionToEyeEC;\n    czm_material material = czm_getMaterial(materialInput);\n\n#ifdef ONLY_SUN_LIGHTING\n    return czm_private_phong(normalize(positionToEyeEC), material, czm_sunDirectionEC);\n#else\n    return czm_phong(normalize(positionToEyeEC), material, czm_lightDirectionEC);\n#endif\n}\n\nvoid main()\n{\n    // PERFORMANCE_TODO: When dynamic branching is available, compute ratio of maximum and minimum radii\n    // in the vertex shader. Only when it is larger than some constant, march along the ray.\n    // Otherwise perform one intersection test which will be the common case.\n\n    // Test if the ray intersects a sphere with the ellipsoid's maximum radius.\n    // For very oblate ellipsoids, using the ellipsoid's radii for an intersection test\n    // may cause false negatives. This will discard fragments before marching the ray forward.\n    float maxRadius = max(u_radii.x, max(u_radii.y, u_radii.z)) * 1.5;\n    vec3 direction = normalize(v_positionEC);\n    vec3 ellipsoidCenter = czm_modelView[3].xyz;\n\n    float t1 = -1.0;\n    float t2 = -1.0;\n\n    float b = -2.0 * dot(direction, ellipsoidCenter);\n    float c = dot(ellipsoidCenter, ellipsoidCenter) - maxRadius * maxRadius;\n\n    float discriminant = b * b - 4.0 * c;\n    if (discriminant >= 0.0) {\n        t1 = (-b - sqrt(discriminant)) * 0.5;\n        t2 = (-b + sqrt(discriminant)) * 0.5;\n    }\n\n    if (t1 < 0.0 && t2 < 0.0) {\n        discard;\n    }\n\n    float t = min(t1, t2);\n    if (t < 0.0) {\n        t = 0.0;\n    }\n\n    // March ray forward to intersection with larger sphere and find\n    czm_ray ray = czm_ray(t * direction, direction);\n\n    vec3 ellipsoid_inverseRadii = vec3(1.0 / u_radii.x, 1.0 / u_radii.y, 1.0 / u_radii.z);\n\n    czm_raySegment intersection = czm_rayEllipsoidIntersectionInterval(ray, ellipsoidCenter, ellipsoid_inverseRadii);\n\n    if (czm_isEmpty(intersection))\n    {\n        discard;\n    }\n\n    // If the viewer is outside, compute outsideFaceColor, with normals facing outward.\n    vec4 outsideFaceColor = (intersection.start != 0.0) ? computeEllipsoidColor(ray, intersection.start, 1.0) : vec4(0.0);\n\n    // If the viewer either is inside or can see inside, compute insideFaceColor, with normals facing inward.\n    vec4 insideFaceColor = (outsideFaceColor.a < 1.0) ? computeEllipsoidColor(ray, intersection.stop, -1.0) : vec4(0.0);\n\n    gl_FragColor = mix(insideFaceColor, outsideFaceColor, outsideFaceColor.a);\n    gl_FragColor.a = 1.0 - (1.0 - insideFaceColor.a) * (1.0 - outsideFaceColor.a);\n\n#ifdef WRITE_DEPTH\n#ifdef GL_EXT_frag_depth\n    t = (intersection.start != 0.0) ? intersection.start : intersection.stop;\n    vec3 positionEC = czm_pointAlongRay(ray, t);\n    vec4 positionCC = czm_projection * vec4(positionEC, 1.0);\n#ifdef LOG_DEPTH\n    czm_writeLogDepth(1.0 + positionCC.w);\n#else\n    float z = positionCC.z / positionCC.w;\n\n    float n = czm_depthRange.near;\n    float f = czm_depthRange.far;\n\n    gl_FragDepthEXT = (z * (f - n) + f + n) * 0.5;\n#endif\n#endif\n#endif\n}\n"},39547:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec3 position;\n\nuniform vec3 u_radii;\n\nvarying vec3 v_positionEC;\n\nvoid main()\n{\n    // In the vertex data, the cube goes from (-1.0, -1.0, -1.0) to (1.0, 1.0, 1.0) in model coordinates.\n    // Scale to consider the radii.  We could also do this once on the CPU when using the BoxGeometry,\n    // but doing it here allows us to change the radii without rewriting the vertex data, and\n    // allows all ellipsoids to reuse the same vertex data.\n    vec4 p = vec4(u_radii * position, 1.0);\n\n    v_positionEC = (czm_modelView * p).xyz;     // position in eye coordinates\n    gl_Position = czm_modelViewProjection * p;  // position in clip coordinates\n\n    // With multi-frustum, when the ellipsoid primitive is positioned on the intersection of two frustums\n    // and close to terrain, the terrain (writes depth) in the closest frustum can overwrite part of the\n    // ellipsoid (does not write depth) that was rendered in the farther frustum.\n    //\n    // Here, we clamp the depth in the vertex shader to avoid being overwritten; however, this creates\n    // artifacts since some fragments can be alpha blended twice.  This is solved by only rendering\n    // the ellipsoid in the closest frustum to the viewer.\n    gl_Position.z = clamp(gl_Position.z, czm_depthRange.near, czm_depthRange.far);\n\n    czm_vertexLogDepth();\n}\n"},64270:(e,n,t)=>{t.d(n,{Z:()=>o});const o="/**\n * @license\n * Copyright (c) 2014-2015, NVIDIA CORPORATION. All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n *  * Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n *  * Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n *  * Neither the name of NVIDIA CORPORATION nor the names of its\n *    contributors may be used to endorse or promote products derived\n *    from this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY\n * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR\n * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY\n * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n// NVIDIA GameWorks Graphics Samples GitHub link: https://github.com/NVIDIAGameWorks/GraphicsSamples\n// Original FXAA 3.11 shader link: https://github.com/NVIDIAGameWorks/GraphicsSamples/blob/master/samples/es3-kepler/FXAA/FXAA3_11.h\n\n// Steps used to integrate into Cesium:\n// * The following defines are set:\n//       #define FXAA_PC 1\n//       #define FXAA_WEBGL_1 1\n//       #define FXAA_GREEN_AS_LUMA 1\n//       #define FXAA_EARLY_EXIT 1\n//       #define FXAA_GLSL_120 1\n// * All other preprocessor directives besides the FXAA_QUALITY__P* directives were removed.\n// * Double underscores are invalid for preprocessor directives so replace them with a single underscore. Replace\n//   /FXAA_QUALITY__P(.*)/g with /FXAA_QUALITY__P$1/.\n// * There are no implicit conversions from ivec* to vec* so replace:\n//       #define FxaaInt2 ivec2\n//           with\n//       #define FxaaInt2 vec2\n// * The texture2DLod function is only available in vertex shaders so replace:\n//       #define FxaaTexTop(t, p) texture2DLod(t, p, 0.0)\n//       #define FxaaTexOff(t, p, o, r) texture2DLod(t, p + (o * r), 0.0)\n//           with\n//       #define FxaaTexTop(t, p) texture2D(t, p)\n//       #define FxaaTexOff(t, p, o, r) texture2D(t, p + (o * r))\n// * FXAA_QUALITY_PRESET is prepended in the javascript code. We may want to expose that setting in the future.\n// * The following parameters to FxaaPixelShader are unused and can be removed:\n//       fxaaConsolePosPos\n//       fxaaConsoleRcpFrameOpt\n//       fxaaConsoleRcpFrameOpt2\n//       fxaaConsole360RcpFrameOpt2\n//       fxaaConsoleEdgeSharpness\n//       fxaaConsoleEdgeThreshold\n//       fxaaConsoleEdgeThresholdMi\n//       fxaaConsole360ConstDir\n\n//\n// Choose the quality preset.\n// This needs to be compiled into the shader as it effects code.\n// Best option to include multiple presets is to\n// in each shader define the preset, then include this file.\n//\n// OPTIONS\n// -----------------------------------------------------------------------\n// 10 to 15 - default medium dither (10=fastest, 15=highest quality)\n// 20 to 29 - less dither, more expensive (20=fastest, 29=highest quality)\n// 39       - no dither, very expensive\n//\n// NOTES\n// -----------------------------------------------------------------------\n// 12 = slightly faster then FXAA 3.9 and higher edge quality (default)\n// 13 = about same speed as FXAA 3.9 and better than 12\n// 23 = closest to FXAA 3.9 visually and performance wise\n//  _ = the lowest digit is directly related to performance\n// _  = the highest digit is directly related to style\n//\n//#define FXAA_QUALITY_PRESET 12\n\n\n#if (FXAA_QUALITY_PRESET == 10)\n    #define FXAA_QUALITY_PS 3\n    #define FXAA_QUALITY_P0 1.5\n    #define FXAA_QUALITY_P1 3.0\n    #define FXAA_QUALITY_P2 12.0\n#endif\n#if (FXAA_QUALITY_PRESET == 11)\n    #define FXAA_QUALITY_PS 4\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 3.0\n    #define FXAA_QUALITY_P3 12.0\n#endif\n#if (FXAA_QUALITY_PRESET == 12)\n    #define FXAA_QUALITY_PS 5\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 2.0\n    #define FXAA_QUALITY_P3 4.0\n    #define FXAA_QUALITY_P4 12.0\n#endif\n#if (FXAA_QUALITY_PRESET == 13)\n    #define FXAA_QUALITY_PS 6\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 2.0\n    #define FXAA_QUALITY_P3 2.0\n    #define FXAA_QUALITY_P4 4.0\n    #define FXAA_QUALITY_P5 12.0\n#endif\n#if (FXAA_QUALITY_PRESET == 14)\n    #define FXAA_QUALITY_PS 7\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 2.0\n    #define FXAA_QUALITY_P3 2.0\n    #define FXAA_QUALITY_P4 2.0\n    #define FXAA_QUALITY_P5 4.0\n    #define FXAA_QUALITY_P6 12.0\n#endif\n#if (FXAA_QUALITY_PRESET == 15)\n    #define FXAA_QUALITY_PS 8\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 2.0\n    #define FXAA_QUALITY_P3 2.0\n    #define FXAA_QUALITY_P4 2.0\n    #define FXAA_QUALITY_P5 2.0\n    #define FXAA_QUALITY_P6 4.0\n    #define FXAA_QUALITY_P7 12.0\n#endif\n#if (FXAA_QUALITY_PRESET == 20)\n    #define FXAA_QUALITY_PS 3\n    #define FXAA_QUALITY_P0 1.5\n    #define FXAA_QUALITY_P1 2.0\n    #define FXAA_QUALITY_P2 8.0\n#endif\n#if (FXAA_QUALITY_PRESET == 21)\n    #define FXAA_QUALITY_PS 4\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 2.0\n    #define FXAA_QUALITY_P3 8.0\n#endif\n#if (FXAA_QUALITY_PRESET == 22)\n    #define FXAA_QUALITY_PS 5\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 2.0\n    #define FXAA_QUALITY_P3 2.0\n    #define FXAA_QUALITY_P4 8.0\n#endif\n#if (FXAA_QUALITY_PRESET == 23)\n    #define FXAA_QUALITY_PS 6\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 2.0\n    #define FXAA_QUALITY_P3 2.0\n    #define FXAA_QUALITY_P4 2.0\n    #define FXAA_QUALITY_P5 8.0\n#endif\n#if (FXAA_QUALITY_PRESET == 24)\n    #define FXAA_QUALITY_PS 7\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 2.0\n    #define FXAA_QUALITY_P3 2.0\n    #define FXAA_QUALITY_P4 2.0\n    #define FXAA_QUALITY_P5 3.0\n    #define FXAA_QUALITY_P6 8.0\n#endif\n#if (FXAA_QUALITY_PRESET == 25)\n    #define FXAA_QUALITY_PS 8\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 2.0\n    #define FXAA_QUALITY_P3 2.0\n    #define FXAA_QUALITY_P4 2.0\n    #define FXAA_QUALITY_P5 2.0\n    #define FXAA_QUALITY_P6 4.0\n    #define FXAA_QUALITY_P7 8.0\n#endif\n#if (FXAA_QUALITY_PRESET == 26)\n    #define FXAA_QUALITY_PS 9\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 2.0\n    #define FXAA_QUALITY_P3 2.0\n    #define FXAA_QUALITY_P4 2.0\n    #define FXAA_QUALITY_P5 2.0\n    #define FXAA_QUALITY_P6 2.0\n    #define FXAA_QUALITY_P7 4.0\n    #define FXAA_QUALITY_P8 8.0\n#endif\n#if (FXAA_QUALITY_PRESET == 27)\n    #define FXAA_QUALITY_PS 10\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 2.0\n    #define FXAA_QUALITY_P3 2.0\n    #define FXAA_QUALITY_P4 2.0\n    #define FXAA_QUALITY_P5 2.0\n    #define FXAA_QUALITY_P6 2.0\n    #define FXAA_QUALITY_P7 2.0\n    #define FXAA_QUALITY_P8 4.0\n    #define FXAA_QUALITY_P9 8.0\n#endif\n#if (FXAA_QUALITY_PRESET == 28)\n    #define FXAA_QUALITY_PS 11\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 2.0\n    #define FXAA_QUALITY_P3 2.0\n    #define FXAA_QUALITY_P4 2.0\n    #define FXAA_QUALITY_P5 2.0\n    #define FXAA_QUALITY_P6 2.0\n    #define FXAA_QUALITY_P7 2.0\n    #define FXAA_QUALITY_P8 2.0\n    #define FXAA_QUALITY_P9 4.0\n    #define FXAA_QUALITY_P10 8.0\n#endif\n#if (FXAA_QUALITY_PRESET == 29)\n    #define FXAA_QUALITY_PS 12\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.5\n    #define FXAA_QUALITY_P2 2.0\n    #define FXAA_QUALITY_P3 2.0\n    #define FXAA_QUALITY_P4 2.0\n    #define FXAA_QUALITY_P5 2.0\n    #define FXAA_QUALITY_P6 2.0\n    #define FXAA_QUALITY_P7 2.0\n    #define FXAA_QUALITY_P8 2.0\n    #define FXAA_QUALITY_P9 2.0\n    #define FXAA_QUALITY_P10 4.0\n    #define FXAA_QUALITY_P11 8.0\n#endif\n#if (FXAA_QUALITY_PRESET == 39)\n    #define FXAA_QUALITY_PS 12\n    #define FXAA_QUALITY_P0 1.0\n    #define FXAA_QUALITY_P1 1.0\n    #define FXAA_QUALITY_P2 1.0\n    #define FXAA_QUALITY_P3 1.0\n    #define FXAA_QUALITY_P4 1.0\n    #define FXAA_QUALITY_P5 1.5\n    #define FXAA_QUALITY_P6 2.0\n    #define FXAA_QUALITY_P7 2.0\n    #define FXAA_QUALITY_P8 2.0\n    #define FXAA_QUALITY_P9 2.0\n    #define FXAA_QUALITY_P10 4.0\n    #define FXAA_QUALITY_P11 8.0\n#endif\n\n#define FxaaBool bool\n#define FxaaFloat float\n#define FxaaFloat2 vec2\n#define FxaaFloat3 vec3\n#define FxaaFloat4 vec4\n#define FxaaHalf float\n#define FxaaHalf2 vec2\n#define FxaaHalf3 vec3\n#define FxaaHalf4 vec4\n#define FxaaInt2 vec2\n#define FxaaTex sampler2D\n\n#define FxaaSat(x) clamp(x, 0.0, 1.0)\n#define FxaaTexTop(t, p) texture2D(t, p)\n#define FxaaTexOff(t, p, o, r) texture2D(t, p + (o * r))\n\nFxaaFloat FxaaLuma(FxaaFloat4 rgba) { return rgba.y; }\n\nFxaaFloat4 FxaaPixelShader(\n    //\n    // Use noperspective interpolation here (turn off perspective interpolation).\n    // {xy} = center of pixel\n    FxaaFloat2 pos,\n    //\n    // Input color texture.\n    // {rgb_} = color in linear or perceptual color space\n    // if (FXAA_GREEN_AS_LUMA == 0)\n    //     {___a} = luma in perceptual color space (not linear)\n    FxaaTex tex,\n    //\n    // Only used on FXAA Quality.\n    // This must be from a constant/uniform.\n    // {x_} = 1.0/screenWidthInPixels\n    // {_y} = 1.0/screenHeightInPixels\n    FxaaFloat2 fxaaQualityRcpFrame,\n    //\n    // Only used on FXAA Quality.\n    // This used to be the FXAA_QUALITY_SUBPIX define.\n    // It is here now to allow easier tuning.\n    // Choose the amount of sub-pixel aliasing removal.\n    // This can effect sharpness.\n    //   1.00 - upper limit (softer)\n    //   0.75 - default amount of filtering\n    //   0.50 - lower limit (sharper, less sub-pixel aliasing removal)\n    //   0.25 - almost off\n    //   0.00 - completely off\n    FxaaFloat fxaaQualitySubpix,\n    //\n    // Only used on FXAA Quality.\n    // This used to be the FXAA_QUALITY_EDGE_THRESHOLD define.\n    // It is here now to allow easier tuning.\n    // The minimum amount of local contrast required to apply algorithm.\n    //   0.333 - too little (faster)\n    //   0.250 - low quality\n    //   0.166 - default\n    //   0.125 - high quality\n    //   0.063 - overkill (slower)\n    FxaaFloat fxaaQualityEdgeThreshold,\n    //\n    // Only used on FXAA Quality.\n    // This used to be the FXAA_QUALITY_EDGE_THRESHOLD_MIN define.\n    // It is here now to allow easier tuning.\n    // Trims the algorithm from processing darks.\n    //   0.0833 - upper limit (default, the start of visible unfiltered edges)\n    //   0.0625 - high quality (faster)\n    //   0.0312 - visible limit (slower)\n    // Special notes when using FXAA_GREEN_AS_LUMA,\n    //   Likely want to set this to zero.\n    //   As colors that are mostly not-green\n    //   will appear very dark in the green channel!\n    //   Tune by looking at mostly non-green content,\n    //   then start at zero and increase until aliasing is a problem.\n    FxaaFloat fxaaQualityEdgeThresholdMin\n) {\n/*--------------------------------------------------------------------------*/\n    FxaaFloat2 posM;\n    posM.x = pos.x;\n    posM.y = pos.y;\n    FxaaFloat4 rgbyM = FxaaTexTop(tex, posM);\n    #define lumaM rgbyM.y\n    FxaaFloat lumaS = FxaaLuma(FxaaTexOff(tex, posM, FxaaInt2( 0, 1), fxaaQualityRcpFrame.xy));\n    FxaaFloat lumaE = FxaaLuma(FxaaTexOff(tex, posM, FxaaInt2( 1, 0), fxaaQualityRcpFrame.xy));\n    FxaaFloat lumaN = FxaaLuma(FxaaTexOff(tex, posM, FxaaInt2( 0,-1), fxaaQualityRcpFrame.xy));\n    FxaaFloat lumaW = FxaaLuma(FxaaTexOff(tex, posM, FxaaInt2(-1, 0), fxaaQualityRcpFrame.xy));\n/*--------------------------------------------------------------------------*/\n    FxaaFloat maxSM = max(lumaS, lumaM);\n    FxaaFloat minSM = min(lumaS, lumaM);\n    FxaaFloat maxESM = max(lumaE, maxSM);\n    FxaaFloat minESM = min(lumaE, minSM);\n    FxaaFloat maxWN = max(lumaN, lumaW);\n    FxaaFloat minWN = min(lumaN, lumaW);\n    FxaaFloat rangeMax = max(maxWN, maxESM);\n    FxaaFloat rangeMin = min(minWN, minESM);\n    FxaaFloat rangeMaxScaled = rangeMax * fxaaQualityEdgeThreshold;\n    FxaaFloat range = rangeMax - rangeMin;\n    FxaaFloat rangeMaxClamped = max(fxaaQualityEdgeThresholdMin, rangeMaxScaled);\n    FxaaBool earlyExit = range < rangeMaxClamped;\n/*--------------------------------------------------------------------------*/\n    if(earlyExit)\n        return rgbyM;\n/*--------------------------------------------------------------------------*/\n    FxaaFloat lumaNW = FxaaLuma(FxaaTexOff(tex, posM, FxaaInt2(-1,-1), fxaaQualityRcpFrame.xy));\n    FxaaFloat lumaSE = FxaaLuma(FxaaTexOff(tex, posM, FxaaInt2( 1, 1), fxaaQualityRcpFrame.xy));\n    FxaaFloat lumaNE = FxaaLuma(FxaaTexOff(tex, posM, FxaaInt2( 1,-1), fxaaQualityRcpFrame.xy));\n    FxaaFloat lumaSW = FxaaLuma(FxaaTexOff(tex, posM, FxaaInt2(-1, 1), fxaaQualityRcpFrame.xy));\n/*--------------------------------------------------------------------------*/\n    FxaaFloat lumaNS = lumaN + lumaS;\n    FxaaFloat lumaWE = lumaW + lumaE;\n    FxaaFloat subpixRcpRange = 1.0/range;\n    FxaaFloat subpixNSWE = lumaNS + lumaWE;\n    FxaaFloat edgeHorz1 = (-2.0 * lumaM) + lumaNS;\n    FxaaFloat edgeVert1 = (-2.0 * lumaM) + lumaWE;\n/*--------------------------------------------------------------------------*/\n    FxaaFloat lumaNESE = lumaNE + lumaSE;\n    FxaaFloat lumaNWNE = lumaNW + lumaNE;\n    FxaaFloat edgeHorz2 = (-2.0 * lumaE) + lumaNESE;\n    FxaaFloat edgeVert2 = (-2.0 * lumaN) + lumaNWNE;\n/*--------------------------------------------------------------------------*/\n    FxaaFloat lumaNWSW = lumaNW + lumaSW;\n    FxaaFloat lumaSWSE = lumaSW + lumaSE;\n    FxaaFloat edgeHorz4 = (abs(edgeHorz1) * 2.0) + abs(edgeHorz2);\n    FxaaFloat edgeVert4 = (abs(edgeVert1) * 2.0) + abs(edgeVert2);\n    FxaaFloat edgeHorz3 = (-2.0 * lumaW) + lumaNWSW;\n    FxaaFloat edgeVert3 = (-2.0 * lumaS) + lumaSWSE;\n    FxaaFloat edgeHorz = abs(edgeHorz3) + edgeHorz4;\n    FxaaFloat edgeVert = abs(edgeVert3) + edgeVert4;\n/*--------------------------------------------------------------------------*/\n    FxaaFloat subpixNWSWNESE = lumaNWSW + lumaNESE;\n    FxaaFloat lengthSign = fxaaQualityRcpFrame.x;\n    FxaaBool horzSpan = edgeHorz >= edgeVert;\n    FxaaFloat subpixA = subpixNSWE * 2.0 + subpixNWSWNESE;\n/*--------------------------------------------------------------------------*/\n    if(!horzSpan) lumaN = lumaW;\n    if(!horzSpan) lumaS = lumaE;\n    if(horzSpan) lengthSign = fxaaQualityRcpFrame.y;\n    FxaaFloat subpixB = (subpixA * (1.0/12.0)) - lumaM;\n/*--------------------------------------------------------------------------*/\n    FxaaFloat gradientN = lumaN - lumaM;\n    FxaaFloat gradientS = lumaS - lumaM;\n    FxaaFloat lumaNN = lumaN + lumaM;\n    FxaaFloat lumaSS = lumaS + lumaM;\n    FxaaBool pairN = abs(gradientN) >= abs(gradientS);\n    FxaaFloat gradient = max(abs(gradientN), abs(gradientS));\n    if(pairN) lengthSign = -lengthSign;\n    FxaaFloat subpixC = FxaaSat(abs(subpixB) * subpixRcpRange);\n/*--------------------------------------------------------------------------*/\n    FxaaFloat2 posB;\n    posB.x = posM.x;\n    posB.y = posM.y;\n    FxaaFloat2 offNP;\n    offNP.x = (!horzSpan) ? 0.0 : fxaaQualityRcpFrame.x;\n    offNP.y = ( horzSpan) ? 0.0 : fxaaQualityRcpFrame.y;\n    if(!horzSpan) posB.x += lengthSign * 0.5;\n    if( horzSpan) posB.y += lengthSign * 0.5;\n/*--------------------------------------------------------------------------*/\n    FxaaFloat2 posN;\n    posN.x = posB.x - offNP.x * FXAA_QUALITY_P0;\n    posN.y = posB.y - offNP.y * FXAA_QUALITY_P0;\n    FxaaFloat2 posP;\n    posP.x = posB.x + offNP.x * FXAA_QUALITY_P0;\n    posP.y = posB.y + offNP.y * FXAA_QUALITY_P0;\n    FxaaFloat subpixD = ((-2.0)*subpixC) + 3.0;\n    FxaaFloat lumaEndN = FxaaLuma(FxaaTexTop(tex, posN));\n    FxaaFloat subpixE = subpixC * subpixC;\n    FxaaFloat lumaEndP = FxaaLuma(FxaaTexTop(tex, posP));\n/*--------------------------------------------------------------------------*/\n    if(!pairN) lumaNN = lumaSS;\n    FxaaFloat gradientScaled = gradient * 1.0/4.0;\n    FxaaFloat lumaMM = lumaM - lumaNN * 0.5;\n    FxaaFloat subpixF = subpixD * subpixE;\n    FxaaBool lumaMLTZero = lumaMM < 0.0;\n/*--------------------------------------------------------------------------*/\n    lumaEndN -= lumaNN * 0.5;\n    lumaEndP -= lumaNN * 0.5;\n    FxaaBool doneN = abs(lumaEndN) >= gradientScaled;\n    FxaaBool doneP = abs(lumaEndP) >= gradientScaled;\n    if(!doneN) posN.x -= offNP.x * FXAA_QUALITY_P1;\n    if(!doneN) posN.y -= offNP.y * FXAA_QUALITY_P1;\n    FxaaBool doneNP = (!doneN) || (!doneP);\n    if(!doneP) posP.x += offNP.x * FXAA_QUALITY_P1;\n    if(!doneP) posP.y += offNP.y * FXAA_QUALITY_P1;\n/*--------------------------------------------------------------------------*/\n    if(doneNP) {\n        if(!doneN) lumaEndN = FxaaLuma(FxaaTexTop(tex, posN.xy));\n        if(!doneP) lumaEndP = FxaaLuma(FxaaTexTop(tex, posP.xy));\n        if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\n        if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\n        doneN = abs(lumaEndN) >= gradientScaled;\n        doneP = abs(lumaEndP) >= gradientScaled;\n        if(!doneN) posN.x -= offNP.x * FXAA_QUALITY_P2;\n        if(!doneN) posN.y -= offNP.y * FXAA_QUALITY_P2;\n        doneNP = (!doneN) || (!doneP);\n        if(!doneP) posP.x += offNP.x * FXAA_QUALITY_P2;\n        if(!doneP) posP.y += offNP.y * FXAA_QUALITY_P2;\n/*--------------------------------------------------------------------------*/\n        #if (FXAA_QUALITY_PS > 3)\n        if(doneNP) {\n            if(!doneN) lumaEndN = FxaaLuma(FxaaTexTop(tex, posN.xy));\n            if(!doneP) lumaEndP = FxaaLuma(FxaaTexTop(tex, posP.xy));\n            if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\n            if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\n            doneN = abs(lumaEndN) >= gradientScaled;\n            doneP = abs(lumaEndP) >= gradientScaled;\n            if(!doneN) posN.x -= offNP.x * FXAA_QUALITY_P3;\n            if(!doneN) posN.y -= offNP.y * FXAA_QUALITY_P3;\n            doneNP = (!doneN) || (!doneP);\n            if(!doneP) posP.x += offNP.x * FXAA_QUALITY_P3;\n            if(!doneP) posP.y += offNP.y * FXAA_QUALITY_P3;\n/*--------------------------------------------------------------------------*/\n            #if (FXAA_QUALITY_PS > 4)\n            if(doneNP) {\n                if(!doneN) lumaEndN = FxaaLuma(FxaaTexTop(tex, posN.xy));\n                if(!doneP) lumaEndP = FxaaLuma(FxaaTexTop(tex, posP.xy));\n                if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\n                if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\n                doneN = abs(lumaEndN) >= gradientScaled;\n                doneP = abs(lumaEndP) >= gradientScaled;\n                if(!doneN) posN.x -= offNP.x * FXAA_QUALITY_P4;\n                if(!doneN) posN.y -= offNP.y * FXAA_QUALITY_P4;\n                doneNP = (!doneN) || (!doneP);\n                if(!doneP) posP.x += offNP.x * FXAA_QUALITY_P4;\n                if(!doneP) posP.y += offNP.y * FXAA_QUALITY_P4;\n/*--------------------------------------------------------------------------*/\n                #if (FXAA_QUALITY_PS > 5)\n                if(doneNP) {\n                    if(!doneN) lumaEndN = FxaaLuma(FxaaTexTop(tex, posN.xy));\n                    if(!doneP) lumaEndP = FxaaLuma(FxaaTexTop(tex, posP.xy));\n                    if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\n                    if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\n                    doneN = abs(lumaEndN) >= gradientScaled;\n                    doneP = abs(lumaEndP) >= gradientScaled;\n                    if(!doneN) posN.x -= offNP.x * FXAA_QUALITY_P5;\n                    if(!doneN) posN.y -= offNP.y * FXAA_QUALITY_P5;\n                    doneNP = (!doneN) || (!doneP);\n                    if(!doneP) posP.x += offNP.x * FXAA_QUALITY_P5;\n                    if(!doneP) posP.y += offNP.y * FXAA_QUALITY_P5;\n/*--------------------------------------------------------------------------*/\n                    #if (FXAA_QUALITY_PS > 6)\n                    if(doneNP) {\n                        if(!doneN) lumaEndN = FxaaLuma(FxaaTexTop(tex, posN.xy));\n                        if(!doneP) lumaEndP = FxaaLuma(FxaaTexTop(tex, posP.xy));\n                        if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\n                        if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\n                        doneN = abs(lumaEndN) >= gradientScaled;\n                        doneP = abs(lumaEndP) >= gradientScaled;\n                        if(!doneN) posN.x -= offNP.x * FXAA_QUALITY_P6;\n                        if(!doneN) posN.y -= offNP.y * FXAA_QUALITY_P6;\n                        doneNP = (!doneN) || (!doneP);\n                        if(!doneP) posP.x += offNP.x * FXAA_QUALITY_P6;\n                        if(!doneP) posP.y += offNP.y * FXAA_QUALITY_P6;\n/*--------------------------------------------------------------------------*/\n                        #if (FXAA_QUALITY_PS > 7)\n                        if(doneNP) {\n                            if(!doneN) lumaEndN = FxaaLuma(FxaaTexTop(tex, posN.xy));\n                            if(!doneP) lumaEndP = FxaaLuma(FxaaTexTop(tex, posP.xy));\n                            if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\n                            if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\n                            doneN = abs(lumaEndN) >= gradientScaled;\n                            doneP = abs(lumaEndP) >= gradientScaled;\n                            if(!doneN) posN.x -= offNP.x * FXAA_QUALITY_P7;\n                            if(!doneN) posN.y -= offNP.y * FXAA_QUALITY_P7;\n                            doneNP = (!doneN) || (!doneP);\n                            if(!doneP) posP.x += offNP.x * FXAA_QUALITY_P7;\n                            if(!doneP) posP.y += offNP.y * FXAA_QUALITY_P7;\n/*--------------------------------------------------------------------------*/\n    #if (FXAA_QUALITY_PS > 8)\n    if(doneNP) {\n        if(!doneN) lumaEndN = FxaaLuma(FxaaTexTop(tex, posN.xy));\n        if(!doneP) lumaEndP = FxaaLuma(FxaaTexTop(tex, posP.xy));\n        if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\n        if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\n        doneN = abs(lumaEndN) >= gradientScaled;\n        doneP = abs(lumaEndP) >= gradientScaled;\n        if(!doneN) posN.x -= offNP.x * FXAA_QUALITY_P8;\n        if(!doneN) posN.y -= offNP.y * FXAA_QUALITY_P8;\n        doneNP = (!doneN) || (!doneP);\n        if(!doneP) posP.x += offNP.x * FXAA_QUALITY_P8;\n        if(!doneP) posP.y += offNP.y * FXAA_QUALITY_P8;\n/*--------------------------------------------------------------------------*/\n        #if (FXAA_QUALITY_PS > 9)\n        if(doneNP) {\n            if(!doneN) lumaEndN = FxaaLuma(FxaaTexTop(tex, posN.xy));\n            if(!doneP) lumaEndP = FxaaLuma(FxaaTexTop(tex, posP.xy));\n            if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\n            if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\n            doneN = abs(lumaEndN) >= gradientScaled;\n            doneP = abs(lumaEndP) >= gradientScaled;\n            if(!doneN) posN.x -= offNP.x * FXAA_QUALITY_P9;\n            if(!doneN) posN.y -= offNP.y * FXAA_QUALITY_P9;\n            doneNP = (!doneN) || (!doneP);\n            if(!doneP) posP.x += offNP.x * FXAA_QUALITY_P9;\n            if(!doneP) posP.y += offNP.y * FXAA_QUALITY_P9;\n/*--------------------------------------------------------------------------*/\n            #if (FXAA_QUALITY_PS > 10)\n            if(doneNP) {\n                if(!doneN) lumaEndN = FxaaLuma(FxaaTexTop(tex, posN.xy));\n                if(!doneP) lumaEndP = FxaaLuma(FxaaTexTop(tex, posP.xy));\n                if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\n                if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\n                doneN = abs(lumaEndN) >= gradientScaled;\n                doneP = abs(lumaEndP) >= gradientScaled;\n                if(!doneN) posN.x -= offNP.x * FXAA_QUALITY_P10;\n                if(!doneN) posN.y -= offNP.y * FXAA_QUALITY_P10;\n                doneNP = (!doneN) || (!doneP);\n                if(!doneP) posP.x += offNP.x * FXAA_QUALITY_P10;\n                if(!doneP) posP.y += offNP.y * FXAA_QUALITY_P10;\n/*--------------------------------------------------------------------------*/\n                #if (FXAA_QUALITY_PS > 11)\n                if(doneNP) {\n                    if(!doneN) lumaEndN = FxaaLuma(FxaaTexTop(tex, posN.xy));\n                    if(!doneP) lumaEndP = FxaaLuma(FxaaTexTop(tex, posP.xy));\n                    if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\n                    if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\n                    doneN = abs(lumaEndN) >= gradientScaled;\n                    doneP = abs(lumaEndP) >= gradientScaled;\n                    if(!doneN) posN.x -= offNP.x * FXAA_QUALITY_P11;\n                    if(!doneN) posN.y -= offNP.y * FXAA_QUALITY_P11;\n                    doneNP = (!doneN) || (!doneP);\n                    if(!doneP) posP.x += offNP.x * FXAA_QUALITY_P11;\n                    if(!doneP) posP.y += offNP.y * FXAA_QUALITY_P11;\n/*--------------------------------------------------------------------------*/\n                    #if (FXAA_QUALITY_PS > 12)\n                    if(doneNP) {\n                        if(!doneN) lumaEndN = FxaaLuma(FxaaTexTop(tex, posN.xy));\n                        if(!doneP) lumaEndP = FxaaLuma(FxaaTexTop(tex, posP.xy));\n                        if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\n                        if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\n                        doneN = abs(lumaEndN) >= gradientScaled;\n                        doneP = abs(lumaEndP) >= gradientScaled;\n                        if(!doneN) posN.x -= offNP.x * FXAA_QUALITY_P12;\n                        if(!doneN) posN.y -= offNP.y * FXAA_QUALITY_P12;\n                        doneNP = (!doneN) || (!doneP);\n                        if(!doneP) posP.x += offNP.x * FXAA_QUALITY_P12;\n                        if(!doneP) posP.y += offNP.y * FXAA_QUALITY_P12;\n/*--------------------------------------------------------------------------*/\n                    }\n                    #endif\n/*--------------------------------------------------------------------------*/\n                }\n                #endif\n/*--------------------------------------------------------------------------*/\n            }\n            #endif\n/*--------------------------------------------------------------------------*/\n        }\n        #endif\n/*--------------------------------------------------------------------------*/\n    }\n    #endif\n/*--------------------------------------------------------------------------*/\n                        }\n                        #endif\n/*--------------------------------------------------------------------------*/\n                    }\n                    #endif\n/*--------------------------------------------------------------------------*/\n                }\n                #endif\n/*--------------------------------------------------------------------------*/\n            }\n            #endif\n/*--------------------------------------------------------------------------*/\n        }\n        #endif\n/*--------------------------------------------------------------------------*/\n    }\n/*--------------------------------------------------------------------------*/\n    FxaaFloat dstN = posM.x - posN.x;\n    FxaaFloat dstP = posP.x - posM.x;\n    if(!horzSpan) dstN = posM.y - posN.y;\n    if(!horzSpan) dstP = posP.y - posM.y;\n/*--------------------------------------------------------------------------*/\n    FxaaBool goodSpanN = (lumaEndN < 0.0) != lumaMLTZero;\n    FxaaFloat spanLength = (dstP + dstN);\n    FxaaBool goodSpanP = (lumaEndP < 0.0) != lumaMLTZero;\n    FxaaFloat spanLengthRcp = 1.0/spanLength;\n/*--------------------------------------------------------------------------*/\n    FxaaBool directionN = dstN < dstP;\n    FxaaFloat dst = min(dstN, dstP);\n    FxaaBool goodSpan = directionN ? goodSpanN : goodSpanP;\n    FxaaFloat subpixG = subpixF * subpixF;\n    FxaaFloat pixelOffset = (dst * (-spanLengthRcp)) + 0.5;\n    FxaaFloat subpixH = subpixG * fxaaQualitySubpix;\n/*--------------------------------------------------------------------------*/\n    FxaaFloat pixelOffsetGood = goodSpan ? pixelOffset : 0.0;\n    FxaaFloat pixelOffsetSubpix = max(pixelOffsetGood, subpixH);\n    if(!horzSpan) posM.x += pixelOffsetSubpix * lengthSign;\n    if( horzSpan) posM.y += pixelOffsetSubpix * lengthSign;\n    return FxaaFloat4(FxaaTexTop(tex, posM).xyz, lumaM);\n}\n"},22120:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform vec4 u_initialColor;\n\n#if TEXTURE_UNITS > 0\nuniform sampler2D u_dayTextures[TEXTURE_UNITS];\nuniform vec4 u_dayTextureTranslationAndScale[TEXTURE_UNITS];\nuniform bool u_dayTextureUseWebMercatorT[TEXTURE_UNITS];\n\n#ifdef APPLY_ALPHA\nuniform float u_dayTextureAlpha[TEXTURE_UNITS];\n#endif\n\n#ifdef APPLY_DAY_NIGHT_ALPHA\nuniform float u_dayTextureNightAlpha[TEXTURE_UNITS];\nuniform float u_dayTextureDayAlpha[TEXTURE_UNITS];\n#endif\n\n#ifdef APPLY_SPLIT\nuniform float u_dayTextureSplit[TEXTURE_UNITS];\n#endif\n\n#ifdef APPLY_BRIGHTNESS\nuniform float u_dayTextureBrightness[TEXTURE_UNITS];\n#endif\n\n#ifdef APPLY_CONTRAST\nuniform float u_dayTextureContrast[TEXTURE_UNITS];\n#endif\n\n#ifdef APPLY_HUE\nuniform float u_dayTextureHue[TEXTURE_UNITS];\n#endif\n\n#ifdef APPLY_SATURATION\nuniform float u_dayTextureSaturation[TEXTURE_UNITS];\n#endif\n\n#ifdef APPLY_GAMMA\nuniform float u_dayTextureOneOverGamma[TEXTURE_UNITS];\n#endif\n\n#ifdef APPLY_IMAGERY_CUTOUT\nuniform vec4 u_dayTextureCutoutRectangles[TEXTURE_UNITS];\n#endif\n\n#ifdef APPLY_COLOR_TO_ALPHA\nuniform vec4 u_colorsToAlpha[TEXTURE_UNITS];\n#endif\n\nuniform vec4 u_dayTextureTexCoordsRectangle[TEXTURE_UNITS];\n#endif\n\n#ifdef SHOW_REFLECTIVE_OCEAN\nuniform sampler2D u_waterMask;\nuniform vec4 u_waterMaskTranslationAndScale;\nuniform float u_zoomedOutOceanSpecularIntensity;\n#endif\n\n#ifdef SHOW_OCEAN_WAVES\nuniform sampler2D u_oceanNormalMap;\n#endif\n\n#if defined(ENABLE_DAYNIGHT_SHADING) || defined(GROUND_ATMOSPHERE)\nuniform vec2 u_lightingFadeDistance;\n#endif\n\n#ifdef TILE_LIMIT_RECTANGLE\nuniform vec4 u_cartographicLimitRectangle;\n#endif\n\n#ifdef GROUND_ATMOSPHERE\nuniform vec2 u_nightFadeDistance;\n#endif\n\n#ifdef ENABLE_CLIPPING_PLANES\nuniform highp sampler2D u_clippingPlanes;\nuniform mat4 u_clippingPlanesMatrix;\nuniform vec4 u_clippingPlanesEdgeStyle;\n#endif\n\n#if defined(GROUND_ATMOSPHERE) || defined(FOG) && defined(DYNAMIC_ATMOSPHERE_LIGHTING) && (defined(ENABLE_VERTEX_LIGHTING) || defined(ENABLE_DAYNIGHT_SHADING))\nuniform float u_minimumBrightness;\n#endif\n\n#ifdef COLOR_CORRECT\nuniform vec3 u_hsbShift; // Hue, saturation, brightness\n#endif\n\n#ifdef HIGHLIGHT_FILL_TILE\nuniform vec4 u_fillHighlightColor;\n#endif\n\n#ifdef TRANSLUCENT\nuniform vec4 u_frontFaceAlphaByDistance;\nuniform vec4 u_backFaceAlphaByDistance;\nuniform vec4 u_translucencyRectangle;\n#endif\n\n#ifdef UNDERGROUND_COLOR\nuniform vec4 u_undergroundColor;\nuniform vec4 u_undergroundColorAlphaByDistance;\n#endif\n\n#ifdef ENABLE_VERTEX_LIGHTING\nuniform float u_lambertDiffuseMultiplier;\n#endif\n\nvarying vec3 v_positionMC;\nvarying vec3 v_positionEC;\nvarying vec3 v_textureCoordinates;\nvarying vec3 v_normalMC;\nvarying vec3 v_normalEC;\n\n#ifdef APPLY_MATERIAL\nvarying float v_height;\nvarying float v_slope;\nvarying float v_aspect;\n#endif\n\n#if defined(FOG) || defined(GROUND_ATMOSPHERE) || defined(UNDERGROUND_COLOR) || defined(TRANSLUCENT)\nvarying float v_distance;\n#endif\n\n#if defined(GROUND_ATMOSPHERE) || defined(FOG)\nvarying vec3 v_atmosphereRayleighColor;\nvarying vec3 v_atmosphereMieColor;\nvarying float v_atmosphereOpacity;\n#endif\n\n#if defined(UNDERGROUND_COLOR) || defined(TRANSLUCENT)\nfloat interpolateByDistance(vec4 nearFarScalar, float distance)\n{\n    float startDistance = nearFarScalar.x;\n    float startValue = nearFarScalar.y;\n    float endDistance = nearFarScalar.z;\n    float endValue = nearFarScalar.w;\n    float t = clamp((distance - startDistance) / (endDistance - startDistance), 0.0, 1.0);\n    return mix(startValue, endValue, t);\n}\n#endif\n\n#if defined(UNDERGROUND_COLOR) || defined(TRANSLUCENT) || defined(APPLY_MATERIAL)\nvec4 alphaBlend(vec4 sourceColor, vec4 destinationColor)\n{\n    return sourceColor * vec4(sourceColor.aaa, 1.0) + destinationColor * (1.0 - sourceColor.a);\n}\n#endif\n\n#ifdef TRANSLUCENT\nbool inTranslucencyRectangle()\n{\n    return\n        v_textureCoordinates.x > u_translucencyRectangle.x &&\n        v_textureCoordinates.x < u_translucencyRectangle.z &&\n        v_textureCoordinates.y > u_translucencyRectangle.y &&\n        v_textureCoordinates.y < u_translucencyRectangle.w;\n}\n#endif\n\nvec4 sampleAndBlend(\n    vec4 previousColor,\n    sampler2D textureToSample,\n    vec2 tileTextureCoordinates,\n    vec4 textureCoordinateRectangle,\n    vec4 textureCoordinateTranslationAndScale,\n    float textureAlpha,\n    float textureNightAlpha,\n    float textureDayAlpha,\n    float textureBrightness,\n    float textureContrast,\n    float textureHue,\n    float textureSaturation,\n    float textureOneOverGamma,\n    float split,\n    vec4 colorToAlpha,\n    float nightBlend)\n{\n    // This crazy step stuff sets the alpha to 0.0 if this following condition is true:\n    //    tileTextureCoordinates.s < textureCoordinateRectangle.s ||\n    //    tileTextureCoordinates.s > textureCoordinateRectangle.p ||\n    //    tileTextureCoordinates.t < textureCoordinateRectangle.t ||\n    //    tileTextureCoordinates.t > textureCoordinateRectangle.q\n    // In other words, the alpha is zero if the fragment is outside the rectangle\n    // covered by this texture.  Would an actual 'if' yield better performance?\n    vec2 alphaMultiplier = step(textureCoordinateRectangle.st, tileTextureCoordinates);\n    textureAlpha = textureAlpha * alphaMultiplier.x * alphaMultiplier.y;\n\n    alphaMultiplier = step(vec2(0.0), textureCoordinateRectangle.pq - tileTextureCoordinates);\n    textureAlpha = textureAlpha * alphaMultiplier.x * alphaMultiplier.y;\n\n#if defined(APPLY_DAY_NIGHT_ALPHA) && defined(ENABLE_DAYNIGHT_SHADING)\n    textureAlpha *= mix(textureDayAlpha, textureNightAlpha, nightBlend);\n#endif\n\n    vec2 translation = textureCoordinateTranslationAndScale.xy;\n    vec2 scale = textureCoordinateTranslationAndScale.zw;\n    vec2 textureCoordinates = tileTextureCoordinates * scale + translation;\n    vec4 value = texture2D(textureToSample, textureCoordinates);\n    vec3 color = value.rgb;\n    float alpha = value.a;\n\n#ifdef APPLY_COLOR_TO_ALPHA\n    vec3 colorDiff = abs(color.rgb - colorToAlpha.rgb);\n    colorDiff.r = max(max(colorDiff.r, colorDiff.g), colorDiff.b);\n    alpha = czm_branchFreeTernary(colorDiff.r < colorToAlpha.a, 0.0, alpha);\n#endif\n\n#if !defined(APPLY_GAMMA)\n    vec4 tempColor = czm_gammaCorrect(vec4(color, alpha));\n    color = tempColor.rgb;\n    alpha = tempColor.a;\n#else\n    color = pow(color, vec3(textureOneOverGamma));\n#endif\n\n#ifdef APPLY_SPLIT\n    float splitPosition = czm_splitPosition;\n    // Split to the left\n    if (split < 0.0 && gl_FragCoord.x > splitPosition) {\n       alpha = 0.0;\n    }\n    // Split to the right\n    else if (split > 0.0 && gl_FragCoord.x < splitPosition) {\n       alpha = 0.0;\n    }\n#endif\n\n#ifdef APPLY_BRIGHTNESS\n    color = mix(vec3(0.0), color, textureBrightness);\n#endif\n\n#ifdef APPLY_CONTRAST\n    color = mix(vec3(0.5), color, textureContrast);\n#endif\n\n#ifdef APPLY_HUE\n    color = czm_hue(color, textureHue);\n#endif\n\n#ifdef APPLY_SATURATION\n    color = czm_saturation(color, textureSaturation);\n#endif\n\n    float sourceAlpha = alpha * textureAlpha;\n    float outAlpha = mix(previousColor.a, 1.0, sourceAlpha);\n    outAlpha += sign(outAlpha) - 1.0;\n\n    vec3 outColor = mix(previousColor.rgb * previousColor.a, color, sourceAlpha) / outAlpha;\n\n    // When rendering imagery for a tile in multiple passes,\n    // some GPU/WebGL implementation combinations will not blend fragments in\n    // additional passes correctly if their computation includes an unmasked\n    // divide-by-zero operation,\n    // even if it's not in the output or if the output has alpha zero.\n    //\n    // For example, without sanitization for outAlpha,\n    // this renders without artifacts:\n    //   if (outAlpha == 0.0) { outColor = vec3(0.0); }\n    //\n    // but using czm_branchFreeTernary will cause portions of the tile that are\n    // alpha-zero in the additional pass to render as black instead of blending\n    // with the previous pass:\n    //   outColor = czm_branchFreeTernary(outAlpha == 0.0, vec3(0.0), outColor);\n    //\n    // So instead, sanitize against divide-by-zero,\n    // store this state on the sign of outAlpha, and correct on return.\n\n    return vec4(outColor, max(outAlpha, 0.0));\n}\n\nvec3 colorCorrect(vec3 rgb) {\n#ifdef COLOR_CORRECT\n    // Convert rgb color to hsb\n    vec3 hsb = czm_RGBToHSB(rgb);\n    // Perform hsb shift\n    hsb.x += u_hsbShift.x; // hue\n    hsb.y = clamp(hsb.y + u_hsbShift.y, 0.0, 1.0); // saturation\n    hsb.z = hsb.z > czm_epsilon7 ? hsb.z + u_hsbShift.z : 0.0; // brightness\n    // Convert shifted hsb back to rgb\n    rgb = czm_HSBToRGB(hsb);\n#endif\n    return rgb;\n}\n\nvec4 computeDayColor(vec4 initialColor, vec3 textureCoordinates, float nightBlend);\nvec4 computeWaterColor(vec3 positionEyeCoordinates, vec2 textureCoordinates, mat3 enuToEye, vec4 imageryColor, float specularMapValue, float fade);\n\nconst float fExposure = 2.0;\n\nvec3 computeEllipsoidPosition()\n{\n    float mpp = czm_metersPerPixel(vec4(0.0, 0.0, -czm_currentFrustum.x, 1.0), 1.0);\n    vec2 xy = gl_FragCoord.xy / czm_viewport.zw * 2.0 - vec2(1.0);\n    xy *= czm_viewport.zw * mpp * 0.5;\n\n    vec3 direction = normalize(vec3(xy, -czm_currentFrustum.x));\n    czm_ray ray = czm_ray(vec3(0.0), direction);\n\n    vec3 ellipsoid_center = czm_view[3].xyz;\n\n    czm_raySegment intersection = czm_rayEllipsoidIntersectionInterval(ray, ellipsoid_center, czm_ellipsoidInverseRadii);\n\n    vec3 ellipsoidPosition = czm_pointAlongRay(ray, intersection.start);\n    return (czm_inverseView * vec4(ellipsoidPosition, 1.0)).xyz;\n}\n\nvoid main()\n{\n#ifdef TILE_LIMIT_RECTANGLE\n    if (v_textureCoordinates.x < u_cartographicLimitRectangle.x || u_cartographicLimitRectangle.z < v_textureCoordinates.x ||\n        v_textureCoordinates.y < u_cartographicLimitRectangle.y || u_cartographicLimitRectangle.w < v_textureCoordinates.y)\n        {\n            discard;\n        }\n#endif\n\n#ifdef ENABLE_CLIPPING_PLANES\n    float clipDistance = clip(gl_FragCoord, u_clippingPlanes, u_clippingPlanesMatrix);\n#endif\n\n#if defined(SHOW_REFLECTIVE_OCEAN) || defined(ENABLE_DAYNIGHT_SHADING) || defined(HDR)\n    vec3 normalMC = czm_geodeticSurfaceNormal(v_positionMC, vec3(0.0), vec3(1.0));   // normalized surface normal in model coordinates\n    vec3 normalEC = czm_normal3D * normalMC;                                         // normalized surface normal in eye coordiantes\n#endif\n\n#if defined(APPLY_DAY_NIGHT_ALPHA) && defined(ENABLE_DAYNIGHT_SHADING)\n    float nightBlend = 1.0 - clamp(czm_getLambertDiffuse(czm_lightDirectionEC, normalEC) * 5.0, 0.0, 1.0);\n#else\n    float nightBlend = 0.0;\n#endif\n\n    // The clamp below works around an apparent bug in Chrome Canary v23.0.1241.0\n    // where the fragment shader sees textures coordinates < 0.0 and > 1.0 for the\n    // fragments on the edges of tiles even though the vertex shader is outputting\n    // coordinates strictly in the 0-1 range.\n    vec4 color = computeDayColor(u_initialColor, clamp(v_textureCoordinates, 0.0, 1.0), nightBlend);\n\n#ifdef SHOW_TILE_BOUNDARIES\n    if (v_textureCoordinates.x < (1.0/256.0) || v_textureCoordinates.x > (255.0/256.0) ||\n        v_textureCoordinates.y < (1.0/256.0) || v_textureCoordinates.y > (255.0/256.0))\n    {\n        color = vec4(1.0, 0.0, 0.0, 1.0);\n    }\n#endif\n\n#if defined(ENABLE_DAYNIGHT_SHADING) || defined(GROUND_ATMOSPHERE)\n    float cameraDist;\n    if (czm_sceneMode == czm_sceneMode2D)\n    {\n        cameraDist = max(czm_frustumPlanes.x - czm_frustumPlanes.y, czm_frustumPlanes.w - czm_frustumPlanes.z) * 0.5;\n    }\n    else if (czm_sceneMode == czm_sceneModeColumbusView)\n    {\n        cameraDist = -czm_view[3].z;\n    }\n    else\n    {\n        cameraDist = length(czm_view[3]);\n    }\n    float fadeOutDist = u_lightingFadeDistance.x;\n    float fadeInDist = u_lightingFadeDistance.y;\n    if (czm_sceneMode != czm_sceneMode3D) {\n        vec3 radii = czm_ellipsoidRadii;\n        float maxRadii = max(radii.x, max(radii.y, radii.z));\n        fadeOutDist -= maxRadii;\n        fadeInDist -= maxRadii;\n    }\n    float fade = clamp((cameraDist - fadeOutDist) / (fadeInDist - fadeOutDist), 0.0, 1.0);\n#else\n    float fade = 0.0;\n#endif\n\n#ifdef SHOW_REFLECTIVE_OCEAN\n    vec2 waterMaskTranslation = u_waterMaskTranslationAndScale.xy;\n    vec2 waterMaskScale = u_waterMaskTranslationAndScale.zw;\n    vec2 waterMaskTextureCoordinates = v_textureCoordinates.xy * waterMaskScale + waterMaskTranslation;\n    waterMaskTextureCoordinates.y = 1.0 - waterMaskTextureCoordinates.y;\n\n    float mask = texture2D(u_waterMask, waterMaskTextureCoordinates).r;\n\n    if (mask > 0.0)\n    {\n        mat3 enuToEye = czm_eastNorthUpToEyeCoordinates(v_positionMC, normalEC);\n\n        vec2 ellipsoidTextureCoordinates = czm_ellipsoidWgs84TextureCoordinates(normalMC);\n        vec2 ellipsoidFlippedTextureCoordinates = czm_ellipsoidWgs84TextureCoordinates(normalMC.zyx);\n\n        vec2 textureCoordinates = mix(ellipsoidTextureCoordinates, ellipsoidFlippedTextureCoordinates, czm_morphTime * smoothstep(0.9, 0.95, normalMC.z));\n\n        color = computeWaterColor(v_positionEC, textureCoordinates, enuToEye, color, mask, fade);\n    }\n#endif\n\n#ifdef APPLY_MATERIAL\n    czm_materialInput materialInput;\n    materialInput.st = v_textureCoordinates.st;\n    materialInput.normalEC = normalize(v_normalEC);\n    materialInput.positionToEyeEC = -v_positionEC;\n    materialInput.tangentToEyeMatrix = czm_eastNorthUpToEyeCoordinates(v_positionMC, normalize(v_normalEC));     \n    materialInput.slope = v_slope;\n    materialInput.height = v_height;\n    materialInput.aspect = v_aspect;\n    czm_material material = czm_getMaterial(materialInput);\n    vec4 materialColor = vec4(material.diffuse, material.alpha);\n    color = alphaBlend(materialColor, color);\n#endif\n\n#ifdef ENABLE_VERTEX_LIGHTING\n    float diffuseIntensity = clamp(czm_getLambertDiffuse(czm_lightDirectionEC, normalize(v_normalEC)) * u_lambertDiffuseMultiplier + 0.3, 0.0, 1.0);\n    vec4 finalColor = vec4(color.rgb * czm_lightColor * diffuseIntensity, color.a);\n#elif defined(ENABLE_DAYNIGHT_SHADING)\n    float diffuseIntensity = clamp(czm_getLambertDiffuse(czm_lightDirectionEC, normalEC) * 5.0 + 0.3, 0.0, 1.0);\n    diffuseIntensity = mix(1.0, diffuseIntensity, fade);\n    vec4 finalColor = vec4(color.rgb * czm_lightColor * diffuseIntensity, color.a);\n#else\n    vec4 finalColor = color;\n#endif\n\n#ifdef ENABLE_CLIPPING_PLANES\n    vec4 clippingPlanesEdgeColor = vec4(1.0);\n    clippingPlanesEdgeColor.rgb = u_clippingPlanesEdgeStyle.rgb;\n    float clippingPlanesEdgeWidth = u_clippingPlanesEdgeStyle.a;\n\n    if (clipDistance < clippingPlanesEdgeWidth)\n    {\n        finalColor = clippingPlanesEdgeColor;\n    }\n#endif\n\n#ifdef HIGHLIGHT_FILL_TILE\n    finalColor = vec4(mix(finalColor.rgb, u_fillHighlightColor.rgb, u_fillHighlightColor.a), finalColor.a);\n#endif\n\n#if defined(DYNAMIC_ATMOSPHERE_LIGHTING_FROM_SUN)\n    vec3 atmosphereLightDirection = czm_sunDirectionWC;\n#else\n    vec3 atmosphereLightDirection = czm_lightDirectionWC;\n#endif\n\n#if defined(GROUND_ATMOSPHERE) || defined(FOG)\n    if (!czm_backFacing())\n    {\n        bool dynamicLighting = false;\n        #if defined(DYNAMIC_ATMOSPHERE_LIGHTING) && (defined(ENABLE_DAYNIGHT_SHADING) || defined(ENABLE_VERTEX_LIGHTING))\n            dynamicLighting = true;     \n        #endif\n\n        vec3 rayleighColor;\n        vec3 mieColor;\n        float opacity;\n\n        vec3 positionWC;\n        vec3 lightDirection;\n\n        // When the camera is far away (camera distance > nightFadeOutDistance), the scattering is computed in the fragment shader.\n        // Otherwise, the scattering is computed in the vertex shader.\n        #ifdef PER_FRAGMENT_GROUND_ATMOSPHERE\n            positionWC = computeEllipsoidPosition();\n            lightDirection = czm_branchFreeTernary(dynamicLighting, atmosphereLightDirection, normalize(positionWC));\n            computeAtmosphereScattering(\n                positionWC,\n                lightDirection,\n                rayleighColor,\n                mieColor,\n                opacity\n            );\n        #else\n            positionWC = v_positionMC;\n            lightDirection = czm_branchFreeTernary(dynamicLighting, atmosphereLightDirection, normalize(positionWC));\n            rayleighColor = v_atmosphereRayleighColor;\n            mieColor = v_atmosphereMieColor;\n            opacity = v_atmosphereOpacity;\n        #endif\n\n        rayleighColor = colorCorrect(rayleighColor);\n        mieColor = colorCorrect(mieColor);\n\n        vec4 groundAtmosphereColor = computeAtmosphereColor(positionWC, lightDirection, rayleighColor, mieColor, opacity);\n\n        // Fog is applied to tiles selected for fog, close to the Earth.\n        #ifdef FOG\n            vec3 fogColor = groundAtmosphereColor.rgb;\n            \n            // If there is lighting, apply that to the fog.\n            #if defined(DYNAMIC_ATMOSPHERE_LIGHTING) && (defined(ENABLE_VERTEX_LIGHTING) || defined(ENABLE_DAYNIGHT_SHADING))\n                float darken = clamp(dot(normalize(czm_viewerPositionWC), atmosphereLightDirection), u_minimumBrightness, 1.0);\n                fogColor *= darken;                \n            #endif\n\n            #ifndef HDR\n                fogColor.rgb = czm_acesTonemapping(fogColor.rgb);\n                fogColor.rgb = czm_inverseGamma(fogColor.rgb);\n            #endif\n            \n            const float modifier = 0.15;\n            finalColor = vec4(czm_fog(v_distance, finalColor.rgb, fogColor.rgb, modifier), finalColor.a);\n\n        #else\n            // The transmittance is based on optical depth i.e. the length of segment of the ray inside the atmosphere.\n            // This value is larger near the \"circumference\", as it is further away from the camera. We use it to\n            // brighten up that area of the ground atmosphere.\n            const float transmittanceModifier = 0.5;\n            float transmittance = transmittanceModifier + clamp(1.0 - groundAtmosphereColor.a, 0.0, 1.0);\n\n            vec3 finalAtmosphereColor = finalColor.rgb + groundAtmosphereColor.rgb * transmittance;\n\n            #if defined(DYNAMIC_ATMOSPHERE_LIGHTING) && (defined(ENABLE_VERTEX_LIGHTING) || defined(ENABLE_DAYNIGHT_SHADING))\n                float fadeInDist = u_nightFadeDistance.x;\n                float fadeOutDist = u_nightFadeDistance.y;\n            \n                float sunlitAtmosphereIntensity = clamp((cameraDist - fadeOutDist) / (fadeInDist - fadeOutDist), 0.05, 1.0);\n                float darken = clamp(dot(normalize(positionWC), atmosphereLightDirection), 0.0, 1.0);\n                vec3 darkenendGroundAtmosphereColor = mix(groundAtmosphereColor.rgb, finalAtmosphereColor.rgb, darken);\n\n                finalAtmosphereColor = mix(darkenendGroundAtmosphereColor, finalAtmosphereColor, sunlitAtmosphereIntensity);\n            #endif\n            \n            #ifndef HDR\n                finalAtmosphereColor.rgb = vec3(1.0) - exp(-fExposure * finalAtmosphereColor.rgb);\n            #else\n                finalAtmosphereColor.rgb = czm_saturation(finalAtmosphereColor.rgb, 1.6);\n            #endif\n            \n            finalColor.rgb = mix(finalColor.rgb, finalAtmosphereColor.rgb, fade);\n        #endif\n    }\n#endif\n\n#ifdef UNDERGROUND_COLOR\n    if (czm_backFacing())\n    {\n        float distanceFromEllipsoid = max(czm_eyeHeight, 0.0);\n        float distance = max(v_distance - distanceFromEllipsoid, 0.0);\n        float blendAmount = interpolateByDistance(u_undergroundColorAlphaByDistance, distance);\n        vec4 undergroundColor = vec4(u_undergroundColor.rgb, u_undergroundColor.a * blendAmount);\n        finalColor = alphaBlend(undergroundColor, finalColor);\n    }\n#endif\n\n#ifdef TRANSLUCENT\n    if (inTranslucencyRectangle())\n    {\n      vec4 alphaByDistance = gl_FrontFacing ? u_frontFaceAlphaByDistance : u_backFaceAlphaByDistance;\n      finalColor.a *= interpolateByDistance(alphaByDistance, v_distance);\n    }\n#endif\n    \n    gl_FragColor =  finalColor;\n}\n\n\n#ifdef SHOW_REFLECTIVE_OCEAN\n\nfloat waveFade(float edge0, float edge1, float x)\n{\n    float y = clamp((x - edge0) / (edge1 - edge0), 0.0, 1.0);\n    return pow(1.0 - y, 5.0);\n}\n\nfloat linearFade(float edge0, float edge1, float x)\n{\n    return clamp((x - edge0) / (edge1 - edge0), 0.0, 1.0);\n}\n\n// Based on water rendering by Jonas Wagner:\n// http://29a.ch/2012/7/19/webgl-terrain-rendering-water-fog\n\n// low altitude wave settings\nconst float oceanFrequencyLowAltitude = 825000.0;\nconst float oceanAnimationSpeedLowAltitude = 0.004;\nconst float oceanOneOverAmplitudeLowAltitude = 1.0 / 2.0;\nconst float oceanSpecularIntensity = 0.5;\n\n// high altitude wave settings\nconst float oceanFrequencyHighAltitude = 125000.0;\nconst float oceanAnimationSpeedHighAltitude = 0.008;\nconst float oceanOneOverAmplitudeHighAltitude = 1.0 / 2.0;\n\nvec4 computeWaterColor(vec3 positionEyeCoordinates, vec2 textureCoordinates, mat3 enuToEye, vec4 imageryColor, float maskValue, float fade)\n{\n    vec3 positionToEyeEC = -positionEyeCoordinates;\n    float positionToEyeECLength = length(positionToEyeEC);\n\n    // The double normalize below works around a bug in Firefox on Android devices.\n    vec3 normalizedPositionToEyeEC = normalize(normalize(positionToEyeEC));\n\n    // Fade out the waves as the camera moves far from the surface.\n    float waveIntensity = waveFade(70000.0, 1000000.0, positionToEyeECLength);\n\n#ifdef SHOW_OCEAN_WAVES\n    // high altitude waves\n    float time = czm_frameNumber * oceanAnimationSpeedHighAltitude;\n    vec4 noise = czm_getWaterNoise(u_oceanNormalMap, textureCoordinates * oceanFrequencyHighAltitude, time, 0.0);\n    vec3 normalTangentSpaceHighAltitude = vec3(noise.xy, noise.z * oceanOneOverAmplitudeHighAltitude);\n\n    // low altitude waves\n    time = czm_frameNumber * oceanAnimationSpeedLowAltitude;\n    noise = czm_getWaterNoise(u_oceanNormalMap, textureCoordinates * oceanFrequencyLowAltitude, time, 0.0);\n    vec3 normalTangentSpaceLowAltitude = vec3(noise.xy, noise.z * oceanOneOverAmplitudeLowAltitude);\n\n    // blend the 2 wave layers based on distance to surface\n    float highAltitudeFade = linearFade(0.0, 60000.0, positionToEyeECLength);\n    float lowAltitudeFade = 1.0 - linearFade(20000.0, 60000.0, positionToEyeECLength);\n    vec3 normalTangentSpace =\n        (highAltitudeFade * normalTangentSpaceHighAltitude) +\n        (lowAltitudeFade * normalTangentSpaceLowAltitude);\n    normalTangentSpace = normalize(normalTangentSpace);\n\n    // fade out the normal perturbation as we move farther from the water surface\n    normalTangentSpace.xy *= waveIntensity;\n    normalTangentSpace = normalize(normalTangentSpace);\n#else\n    vec3 normalTangentSpace = vec3(0.0, 0.0, 1.0);\n#endif\n\n    vec3 normalEC = enuToEye * normalTangentSpace;\n\n    const vec3 waveHighlightColor = vec3(0.3, 0.45, 0.6);\n\n    // Use diffuse light to highlight the waves\n    float diffuseIntensity = czm_getLambertDiffuse(czm_lightDirectionEC, normalEC) * maskValue;\n    vec3 diffuseHighlight = waveHighlightColor * diffuseIntensity * (1.0 - fade);\n\n#ifdef SHOW_OCEAN_WAVES\n    // Where diffuse light is low or non-existent, use wave highlights based solely on\n    // the wave bumpiness and no particular light direction.\n    float tsPerturbationRatio = normalTangentSpace.z;\n    vec3 nonDiffuseHighlight = mix(waveHighlightColor * 5.0 * (1.0 - tsPerturbationRatio), vec3(0.0), diffuseIntensity);\n#else\n    vec3 nonDiffuseHighlight = vec3(0.0);\n#endif\n\n    // Add specular highlights in 3D, and in all modes when zoomed in.\n    float specularIntensity = czm_getSpecular(czm_lightDirectionEC, normalizedPositionToEyeEC, normalEC, 10.0);\n    float surfaceReflectance = mix(0.0, mix(u_zoomedOutOceanSpecularIntensity, oceanSpecularIntensity, waveIntensity), maskValue);\n    float specular = specularIntensity * surfaceReflectance;\n\n#ifdef HDR\n    specular *= 1.4;\n\n    float e = 0.2;\n    float d = 3.3;\n    float c = 1.7;\n\n    vec3 color = imageryColor.rgb + (c * (vec3(e) + imageryColor.rgb * d) * (diffuseHighlight + nonDiffuseHighlight + specular));\n#else\n    vec3 color = imageryColor.rgb + diffuseHighlight + nonDiffuseHighlight + specular;\n#endif\n\n    return vec4(color, imageryColor.a);\n}\n\n#endif // #ifdef SHOW_REFLECTIVE_OCEAN\n"},435:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef QUANTIZATION_BITS12\nattribute vec4 compressed0;\nattribute float compressed1;\n#else\nattribute vec4 position3DAndHeight;\nattribute vec4 textureCoordAndEncodedNormals;\n#endif\n\n#ifdef GEODETIC_SURFACE_NORMALS\nattribute vec3 geodeticSurfaceNormal;\n#endif\n\n#ifdef EXAGGERATION\nuniform vec2 u_terrainExaggerationAndRelativeHeight;\n#endif\n\nuniform vec3 u_center3D;\nuniform mat4 u_modifiedModelView;\nuniform mat4 u_modifiedModelViewProjection;\nuniform vec4 u_tileRectangle;\n\n// Uniforms for 2D Mercator projection\nuniform vec2 u_southAndNorthLatitude;\nuniform vec2 u_southMercatorYAndOneOverHeight;\n\nvarying vec3 v_positionMC;\nvarying vec3 v_positionEC;\n\nvarying vec3 v_textureCoordinates;\nvarying vec3 v_normalMC;\nvarying vec3 v_normalEC;\n\n#ifdef APPLY_MATERIAL\nvarying float v_slope;\nvarying float v_aspect;\nvarying float v_height;\n#endif\n\n#if defined(FOG) || defined(GROUND_ATMOSPHERE) || defined(UNDERGROUND_COLOR) || defined(TRANSLUCENT)\nvarying float v_distance;\n#endif\n\n#if defined(FOG) || defined(GROUND_ATMOSPHERE)\nvarying vec3 v_atmosphereRayleighColor;\nvarying vec3 v_atmosphereMieColor;\nvarying float v_atmosphereOpacity;\n#endif\n\n// These functions are generated at runtime.\nvec4 getPosition(vec3 position, float height, vec2 textureCoordinates);\nfloat get2DYPositionFraction(vec2 textureCoordinates);\n\nvec4 getPosition3DMode(vec3 position, float height, vec2 textureCoordinates)\n{\n    return u_modifiedModelViewProjection * vec4(position, 1.0);\n}\n\nfloat get2DMercatorYPositionFraction(vec2 textureCoordinates)\n{\n    // The width of a tile at level 11, in radians and assuming a single root tile, is\n    //   2.0 * czm_pi / pow(2.0, 11.0)\n    // We want to just linearly interpolate the 2D position from the texture coordinates\n    // when we're at this level or higher.  The constant below is the expression\n    // above evaluated and then rounded up at the 4th significant digit.\n    const float maxTileWidth = 0.003068;\n    float positionFraction = textureCoordinates.y;\n    float southLatitude = u_southAndNorthLatitude.x;\n    float northLatitude = u_southAndNorthLatitude.y;\n    if (northLatitude - southLatitude > maxTileWidth)\n    {\n        float southMercatorY = u_southMercatorYAndOneOverHeight.x;\n        float oneOverMercatorHeight = u_southMercatorYAndOneOverHeight.y;\n\n        float currentLatitude = mix(southLatitude, northLatitude, textureCoordinates.y);\n        currentLatitude = clamp(currentLatitude, -czm_webMercatorMaxLatitude, czm_webMercatorMaxLatitude);\n        positionFraction = czm_latitudeToWebMercatorFraction(currentLatitude, southMercatorY, oneOverMercatorHeight);\n    }\n    return positionFraction;\n}\n\nfloat get2DGeographicYPositionFraction(vec2 textureCoordinates)\n{\n    return textureCoordinates.y;\n}\n\nvec4 getPositionPlanarEarth(vec3 position, float height, vec2 textureCoordinates)\n{\n    float yPositionFraction = get2DYPositionFraction(textureCoordinates);\n    vec4 rtcPosition2D = vec4(height, mix(u_tileRectangle.st, u_tileRectangle.pq, vec2(textureCoordinates.x, yPositionFraction)), 1.0);\n    return u_modifiedModelViewProjection * rtcPosition2D;\n}\n\nvec4 getPosition2DMode(vec3 position, float height, vec2 textureCoordinates)\n{\n    return getPositionPlanarEarth(position, 0.0, textureCoordinates);\n}\n\nvec4 getPositionColumbusViewMode(vec3 position, float height, vec2 textureCoordinates)\n{\n    return getPositionPlanarEarth(position, height, textureCoordinates);\n}\n\nvec4 getPositionMorphingMode(vec3 position, float height, vec2 textureCoordinates)\n{\n    // We do not do RTC while morphing, so there is potential for jitter.\n    // This is unlikely to be noticeable, though.\n    vec3 position3DWC = position + u_center3D;\n    float yPositionFraction = get2DYPositionFraction(textureCoordinates);\n    vec4 position2DWC = vec4(height, mix(u_tileRectangle.st, u_tileRectangle.pq, vec2(textureCoordinates.x, yPositionFraction)), 1.0);\n    vec4 morphPosition = czm_columbusViewMorph(position2DWC, vec4(position3DWC, 1.0), czm_morphTime);\n    return czm_modelViewProjection * morphPosition;\n}\n\n#ifdef QUANTIZATION_BITS12\nuniform vec2 u_minMaxHeight;\nuniform mat4 u_scaleAndBias;\n#endif\n\nvoid main()\n{\n#ifdef QUANTIZATION_BITS12\n    vec2 xy = czm_decompressTextureCoordinates(compressed0.x);\n    vec2 zh = czm_decompressTextureCoordinates(compressed0.y);\n    vec3 position = vec3(xy, zh.x);\n    float height = zh.y;\n    vec2 textureCoordinates = czm_decompressTextureCoordinates(compressed0.z);\n\n    height = height * (u_minMaxHeight.y - u_minMaxHeight.x) + u_minMaxHeight.x;\n    position = (u_scaleAndBias * vec4(position, 1.0)).xyz;\n\n#if (defined(ENABLE_VERTEX_LIGHTING) || defined(GENERATE_POSITION_AND_NORMAL)) && defined(INCLUDE_WEB_MERCATOR_Y)\n    float webMercatorT = czm_decompressTextureCoordinates(compressed0.w).x;\n    float encodedNormal = compressed1;\n#elif defined(INCLUDE_WEB_MERCATOR_Y)\n    float webMercatorT = czm_decompressTextureCoordinates(compressed0.w).x;\n    float encodedNormal = 0.0;\n#elif defined(ENABLE_VERTEX_LIGHTING) || defined(GENERATE_POSITION_AND_NORMAL)\n    float webMercatorT = textureCoordinates.y;\n    float encodedNormal = compressed0.w;\n#else\n    float webMercatorT = textureCoordinates.y;\n    float encodedNormal = 0.0;\n#endif\n\n#else\n    // A single float per element\n    vec3 position = position3DAndHeight.xyz;\n    float height = position3DAndHeight.w;\n    vec2 textureCoordinates = textureCoordAndEncodedNormals.xy;\n\n#if (defined(ENABLE_VERTEX_LIGHTING) || defined(GENERATE_POSITION_AND_NORMAL) || defined(APPLY_MATERIAL)) && defined(INCLUDE_WEB_MERCATOR_Y)\n    float webMercatorT = textureCoordAndEncodedNormals.z;\n    float encodedNormal = textureCoordAndEncodedNormals.w;\n#elif defined(ENABLE_VERTEX_LIGHTING) || defined(GENERATE_POSITION_AND_NORMAL) || defined(APPLY_MATERIAL)\n    float webMercatorT = textureCoordinates.y;\n    float encodedNormal = textureCoordAndEncodedNormals.z;\n#elif defined(INCLUDE_WEB_MERCATOR_Y)\n    float webMercatorT = textureCoordAndEncodedNormals.z;\n    float encodedNormal = 0.0;\n#else\n    float webMercatorT = textureCoordinates.y;\n    float encodedNormal = 0.0;\n#endif\n\n#endif\n\n    vec3 position3DWC = position + u_center3D;\n\n#ifdef GEODETIC_SURFACE_NORMALS\n    vec3 ellipsoidNormal = geodeticSurfaceNormal;\n#else\n    vec3 ellipsoidNormal = normalize(position3DWC);\n#endif\n\n#if defined(EXAGGERATION) && defined(GEODETIC_SURFACE_NORMALS)\n    float exaggeration = u_terrainExaggerationAndRelativeHeight.x;\n    float relativeHeight = u_terrainExaggerationAndRelativeHeight.y;\n    float newHeight = (height - relativeHeight) * exaggeration + relativeHeight;\n\n    // stop from going through center of earth\n    float minRadius = min(min(czm_ellipsoidRadii.x, czm_ellipsoidRadii.y), czm_ellipsoidRadii.z);\n    newHeight = max(newHeight, -minRadius);\n\n    vec3 offset = ellipsoidNormal * (newHeight - height);\n    position += offset;\n    position3DWC += offset;\n    height = newHeight;\n#endif\n\n    gl_Position = getPosition(position, height, textureCoordinates);\n\n    v_positionEC = (u_modifiedModelView * vec4(position, 1.0)).xyz;\n    v_positionMC = position3DWC;  // position in model coordinates\n\n    v_textureCoordinates = vec3(textureCoordinates, webMercatorT);\n\n#if defined(ENABLE_VERTEX_LIGHTING) || defined(GENERATE_POSITION_AND_NORMAL) || defined(APPLY_MATERIAL)\n    vec3 normalMC = czm_octDecode(encodedNormal);\n\n#if defined(EXAGGERATION) && defined(GEODETIC_SURFACE_NORMALS)\n    vec3 projection = dot(normalMC, ellipsoidNormal) * ellipsoidNormal;\n    vec3 rejection = normalMC - projection;\n    normalMC = normalize(projection + rejection * exaggeration);\n#endif\n\n    v_normalMC = normalMC;\n    v_normalEC = czm_normal3D * v_normalMC;\n#endif\n\n#if defined(FOG) || (defined(GROUND_ATMOSPHERE) && !defined(PER_FRAGMENT_GROUND_ATMOSPHERE))\n\n    bool dynamicLighting = false;\n\n    #if defined(DYNAMIC_ATMOSPHERE_LIGHTING) && (defined(ENABLE_DAYNIGHT_SHADING) || defined(ENABLE_VERTEX_LIGHTING))\n        dynamicLighting = true;\n    #endif\n\n#if defined(DYNAMIC_ATMOSPHERE_LIGHTING_FROM_SUN)\n    vec3 atmosphereLightDirection = czm_sunDirectionWC;\n#else\n    vec3 atmosphereLightDirection = czm_lightDirectionWC;\n#endif\n\n    vec3 lightDirection = czm_branchFreeTernary(dynamicLighting, atmosphereLightDirection, normalize(position3DWC));\n\n    computeAtmosphereScattering(\n        position3DWC,\n        lightDirection,\n        v_atmosphereRayleighColor,\n        v_atmosphereMieColor,\n        v_atmosphereOpacity\n    );\n#endif\n\n#if defined(FOG) || defined(GROUND_ATMOSPHERE) || defined(UNDERGROUND_COLOR) || defined(TRANSLUCENT)\n    v_distance = length((czm_modelView3D * vec4(position3DWC, 1.0)).xyz);\n#endif\n\n#ifdef APPLY_MATERIAL\n    float northPoleZ = czm_ellipsoidRadii.z;\n    vec3 northPolePositionMC = vec3(0.0, 0.0, northPoleZ);\n    vec3 vectorEastMC = normalize(cross(northPolePositionMC - v_positionMC, ellipsoidNormal));\n    float dotProd = abs(dot(ellipsoidNormal, v_normalMC));\n    v_slope = acos(dotProd);\n    vec3 normalRejected = ellipsoidNormal * dotProd;\n    vec3 normalProjected = v_normalMC - normalRejected;\n    vec3 aspectVector = normalize(normalProjected);\n    v_aspect = acos(dot(aspectVector, vectorEastMC));\n    float determ = dot(cross(vectorEastMC, aspectVector), ellipsoidNormal);\n    v_aspect = czm_branchFreeTernary(determ < 0.0, 2.0 * czm_pi - v_aspect, v_aspect);\n    v_height = height;\n#endif\n}\n"},4473:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void computeAtmosphereScattering(vec3 positionWC, vec3 lightDirection, out vec3 rayleighColor, out vec3 mieColor, out float opacity) {\n\n    vec3 cameraToPositionWC = positionWC - czm_viewerPositionWC;\n    vec3 cameraToPositionWCDirection = normalize(cameraToPositionWC);\n    czm_ray primaryRay = czm_ray(czm_viewerPositionWC, cameraToPositionWCDirection);\n    \n    float atmosphereInnerRadius = length(positionWC);\n\n    computeScattering(\n        primaryRay,\n        length(cameraToPositionWC),\n        lightDirection,\n        atmosphereInnerRadius,\n        rayleighColor,\n        mieColor,\n        opacity\n    );\n}\n"},25730:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D image;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n    vec4 rampColor = texture2D(image, vec2(materialInput.aspect / (2.0 * czm_pi), 0.5));\n    rampColor = czm_gammaCorrect(rampColor);\n    material.diffuse = rampColor.rgb;\n    material.alpha = rampColor.a;\n    return material;\n}\n"},16468:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D image;\nuniform float strength;\nuniform vec2 repeat;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    vec2 st = materialInput.st;\n\n    vec2 centerPixel = fract(repeat * st);\n    float centerBump = texture2D(image, centerPixel).channel;\n\n    float imageWidth = float(imageDimensions.x);\n    vec2 rightPixel = fract(repeat * (st + vec2(1.0 / imageWidth, 0.0)));\n    float rightBump = texture2D(image, rightPixel).channel;\n\n    float imageHeight = float(imageDimensions.y);\n    vec2 leftPixel = fract(repeat * (st + vec2(0.0, 1.0 / imageHeight)));\n    float topBump = texture2D(image, leftPixel).channel;\n\n    vec3 normalTangentSpace = normalize(vec3(centerBump - rightBump, centerBump - topBump, clamp(1.0 - strength, 0.1, 1.0)));\n    vec3 normalEC = materialInput.tangentToEyeMatrix * normalTangentSpace;\n\n    material.normal = normalEC;\n    material.diffuse = vec3(0.01);\n\n    return material;\n}\n"},62266:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform vec4 lightColor;\nuniform vec4 darkColor;\nuniform vec2 repeat;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    vec2 st = materialInput.st;\n\n    // From Stefan Gustavson's Procedural Textures in GLSL in OpenGL Insights\n    float b = mod(floor(repeat.s * st.s) + floor(repeat.t * st.t), 2.0);  // 0.0 or 1.0\n\n    // Find the distance from the closest separator (region between two colors)\n    float scaledWidth = fract(repeat.s * st.s);\n    scaledWidth = abs(scaledWidth - floor(scaledWidth + 0.5));\n    float scaledHeight = fract(repeat.t * st.t);\n    scaledHeight = abs(scaledHeight - floor(scaledHeight + 0.5));\n    float value = min(scaledWidth, scaledHeight);\n\n    vec4 currentColor = mix(lightColor, darkColor, b);\n    vec4 color = czm_antialias(lightColor, darkColor, currentColor, value, 0.03);\n\n    color = czm_gammaCorrect(color);\n    material.diffuse = color.rgb;\n    material.alpha = color.a;\n\n    return material;\n}\n"},62658:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform vec4 lightColor;\nuniform vec4 darkColor;\nuniform vec2 repeat;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    // From Stefan Gustavson's Procedural Textures in GLSL in OpenGL Insights\n    float b = smoothstep(0.3, 0.32, length(fract(repeat * materialInput.st) - 0.5));  // 0.0 or 1.0\n\n    vec4 color = mix(lightColor, darkColor, b);\n    color = czm_gammaCorrect(color);\n    material.diffuse = color.rgb;\n    material.alpha = color.a;\n\n    return material;\n}\n"},99399:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D heights;\nuniform sampler2D colors;\n\n// This material expects heights to be sorted from lowest to highest.\n\nfloat getHeight(int idx, float invTexSize)\n{\n    vec2 uv = vec2((float(idx) + 0.5) * invTexSize, 0.5);\n#ifdef OES_texture_float\n    return texture2D(heights, uv).x;\n#else\n    return czm_unpackFloat(texture2D(heights, uv));\n#endif\n}\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    float height = materialInput.height;\n    float invTexSize = 1.0 / float(heightsDimensions.x);\n\n    float minHeight = getHeight(0, invTexSize);\n    float maxHeight = getHeight(heightsDimensions.x - 1, invTexSize);\n\n    // early-out when outside the height range\n    if (height < minHeight || height > maxHeight) {\n        material.diffuse = vec3(0.0);\n        material.alpha = 0.0;\n        return material;\n    }\n\n    // Binary search to find heights above and below.\n    int idxBelow = 0;\n    int idxAbove = heightsDimensions.x;\n    float heightBelow = minHeight;\n    float heightAbove = maxHeight;\n\n    // while loop not allowed, so use for loop with max iterations.\n    // maxIterations of 16 supports a texture size up to 65536 (2^16).\n    const int maxIterations = 16;\n    for (int i = 0; i < maxIterations; i++) {\n        if (idxBelow >= idxAbove - 1) {\n            break;\n        }\n\n        int idxMid = (idxBelow + idxAbove) / 2;\n        float heightTex = getHeight(idxMid, invTexSize);\n\n        if (height > heightTex) {\n            idxBelow = idxMid;\n            heightBelow = heightTex;\n        } else {\n            idxAbove = idxMid;\n            heightAbove = heightTex;\n        }\n    }\n\n    float lerper = heightBelow == heightAbove ? 1.0 : (height - heightBelow) / (heightAbove - heightBelow);\n    vec2 colorUv = vec2(invTexSize * (float(idxBelow) + 0.5 + lerper), 0.5);\n    vec4 color = texture2D(colors, colorUv);\n\n    // undo preumultiplied alpha\n    if (color.a > 0.0) \n    {\n        color.rgb /= color.a;\n    }\n    \n    color.rgb = czm_gammaCorrect(color.rgb);\n\n    material.diffuse = color.rgb;\n    material.alpha = color.a;\n    return material;\n}\n"},58214:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef GL_OES_standard_derivatives\n    #extension GL_OES_standard_derivatives : enable\n#endif\n\nuniform vec4 color;\nuniform float spacing;\nuniform float width;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    float distanceToContour = mod(materialInput.height, spacing);\n\n#ifdef GL_OES_standard_derivatives\n    float dxc = abs(dFdx(materialInput.height));\n    float dyc = abs(dFdy(materialInput.height));\n    float dF = max(dxc, dyc) * czm_pixelRatio * width;\n    float alpha = (distanceToContour < dF) ? 1.0 : 0.0;\n#else\n    float alpha = (distanceToContour < (czm_pixelRatio * width)) ? 1.0 : 0.0;\n#endif\n\n    vec4 outColor = czm_gammaCorrect(vec4(color.rgb, alpha * color.a));\n    material.diffuse = outColor.rgb;\n    material.alpha = outColor.a;\n\n    return material;\n}\n"},56173:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D image;\nuniform float minimumHeight;\nuniform float maximumHeight;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n    float scaledHeight = clamp((materialInput.height - minimumHeight) / (maximumHeight - minimumHeight), 0.0, 1.0);\n    vec4 rampColor = texture2D(image, vec2(scaledHeight, 0.5));\n    rampColor = czm_gammaCorrect(rampColor);\n    material.diffuse = rampColor.rgb;\n    material.alpha = rampColor.a;\n    return material;\n}\n"},72378:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform vec4 fadeInColor;\nuniform vec4 fadeOutColor;\nuniform float maximumDistance;\nuniform bool repeat;\nuniform vec2 fadeDirection;\nuniform vec2 time;\n\nfloat getTime(float t, float coord)\n{\n    float scalar = 1.0 / maximumDistance;\n    float q  = distance(t, coord) * scalar;\n    if (repeat)\n    {\n        float r = distance(t, coord + 1.0) * scalar;\n        float s = distance(t, coord - 1.0) * scalar;\n        q = min(min(r, s), q);\n    }\n    return clamp(q, 0.0, 1.0);\n}\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    vec2 st = materialInput.st;\n    float s = getTime(time.x, st.s) * fadeDirection.s;\n    float t = getTime(time.y, st.t) * fadeDirection.t;\n\n    float u = length(vec2(s, t));\n    vec4 color = mix(fadeInColor, fadeOutColor, u);\n\n    color = czm_gammaCorrect(color);\n    material.emission = color.rgb;\n    material.alpha = color.a;\n\n    return material;\n}\n"},49751:(e,n,t)=>{t.d(n,{Z:()=>o});const o='#ifdef GL_OES_standard_derivatives\n    #extension GL_OES_standard_derivatives : enable\n#endif\n\nuniform vec4 color;\nuniform float cellAlpha;\nuniform vec2 lineCount;\nuniform vec2 lineThickness;\nuniform vec2 lineOffset;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    vec2 st = materialInput.st;\n\n    float scaledWidth = fract(lineCount.s * st.s - lineOffset.s);\n    scaledWidth = abs(scaledWidth - floor(scaledWidth + 0.5));\n    float scaledHeight = fract(lineCount.t * st.t - lineOffset.t);\n    scaledHeight = abs(scaledHeight - floor(scaledHeight + 0.5));\n\n    float value;\n#ifdef GL_OES_standard_derivatives\n    // Fuzz Factor - Controls blurriness of lines\n    const float fuzz = 1.2;\n    vec2 thickness = (lineThickness * czm_pixelRatio) - 1.0;\n\n    // From "3D Engine Design for Virtual Globes" by Cozzi and Ring, Listing 4.13.\n    vec2 dx = abs(dFdx(st));\n    vec2 dy = abs(dFdy(st));\n    vec2 dF = vec2(max(dx.s, dy.s), max(dx.t, dy.t)) * lineCount;\n    value = min(\n        smoothstep(dF.s * thickness.s, dF.s * (fuzz + thickness.s), scaledWidth),\n        smoothstep(dF.t * thickness.t, dF.t * (fuzz + thickness.t), scaledHeight));\n#else\n    // Fuzz Factor - Controls blurriness of lines\n    const float fuzz = 0.05;\n\n    vec2 range = 0.5 - (lineThickness * 0.05);\n    value = min(\n        1.0 - smoothstep(range.s, range.s + fuzz, scaledWidth),\n        1.0 - smoothstep(range.t, range.t + fuzz, scaledHeight));\n#endif\n\n    // Edges taken from RimLightingMaterial.glsl\n    // See http://www.fundza.com/rman_shaders/surface/fake_rim/fake_rim1.html\n    float dRim = 1.0 - abs(dot(materialInput.normalEC, normalize(materialInput.positionToEyeEC)));\n    float sRim = smoothstep(0.8, 1.0, dRim);\n    value *= (1.0 - sRim);\n\n    vec4 halfColor;\n    halfColor.rgb = color.rgb * 0.5;\n    halfColor.a = color.a * (1.0 - ((1.0 - cellAlpha) * value));\n    halfColor = czm_gammaCorrect(halfColor);\n    material.diffuse = halfColor.rgb;\n    material.emission = halfColor.rgb;\n    material.alpha = halfColor.a;\n\n    return material;\n}\n'},37741:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D image;\nuniform float strength;\nuniform vec2 repeat;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n    \n    vec4 textureValue = texture2D(image, fract(repeat * materialInput.st));\n    vec3 normalTangentSpace = textureValue.channels;\n    normalTangentSpace.xy = normalTangentSpace.xy * 2.0 - 1.0;\n    normalTangentSpace.z = clamp(1.0 - strength, 0.1, 1.0);\n    normalTangentSpace = normalize(normalTangentSpace);\n    vec3 normalEC = materialInput.tangentToEyeMatrix * normalTangentSpace;\n    \n    material.normal = normalEC;\n    \n    return material;\n}\n"},23010:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef GL_OES_standard_derivatives\n#extension GL_OES_standard_derivatives : enable\n#endif\n\nuniform vec4 color;\n\nfloat getPointOnLine(vec2 p0, vec2 p1, float x)\n{\n    float slope = (p0.y - p1.y) / (p0.x - p1.x);\n    return slope * (x - p0.x) + p0.y;\n}\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    vec2 st = materialInput.st;\n\n#ifdef GL_OES_standard_derivatives\n    float base = 1.0 - abs(fwidth(st.s)) * 10.0 * czm_pixelRatio;\n#else\n    float base = 0.975; // 2.5% of the line will be the arrow head\n#endif\n\n    vec2 center = vec2(1.0, 0.5);\n    float ptOnUpperLine = getPointOnLine(vec2(base, 1.0), center, st.s);\n    float ptOnLowerLine = getPointOnLine(vec2(base, 0.0), center, st.s);\n\n    float halfWidth = 0.15;\n    float s = step(0.5 - halfWidth, st.t);\n    s *= 1.0 - step(0.5 + halfWidth, st.t);\n    s *= 1.0 - step(base, st.s);\n\n    float t = step(base, materialInput.st.s);\n    t *= 1.0 - step(ptOnUpperLine, st.t);\n    t *= step(ptOnLowerLine, st.t);\n\n    // Find the distance from the closest separator (region between two colors)\n    float dist;\n    if (st.s < base)\n    {\n        float d1 = abs(st.t - (0.5 - halfWidth));\n        float d2 = abs(st.t - (0.5 + halfWidth));\n        dist = min(d1, d2);\n    }\n    else\n    {\n        float d1 = czm_infinity;\n        if (st.t < 0.5 - halfWidth && st.t > 0.5 + halfWidth)\n        {\n            d1 = abs(st.s - base);\n        }\n        float d2 = abs(st.t - ptOnUpperLine);\n        float d3 = abs(st.t - ptOnLowerLine);\n        dist = min(min(d1, d2), d3);\n    }\n\n    vec4 outsideColor = vec4(0.0);\n    vec4 currentColor = mix(outsideColor, color, clamp(s + t, 0.0, 1.0));\n    vec4 outColor = czm_antialias(outsideColor, color, currentColor, dist);\n\n    outColor = czm_gammaCorrect(outColor);\n    material.diffuse = outColor.rgb;\n    material.alpha = outColor.a;\n    return material;\n}\n"},47511:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform vec4 color;\nuniform vec4 gapColor;\nuniform float dashLength;\nuniform float dashPattern;\nvarying float v_polylineAngle;\n\nconst float maskLength = 16.0;\n\nmat2 rotate(float rad) {\n    float c = cos(rad);\n    float s = sin(rad);\n    return mat2(\n        c, s,\n        -s, c\n    );\n}\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    vec2 pos = rotate(v_polylineAngle) * gl_FragCoord.xy;\n\n    // Get the relative position within the dash from 0 to 1\n    float dashPosition = fract(pos.x / (dashLength * czm_pixelRatio));\n    // Figure out the mask index.\n    float maskIndex = floor(dashPosition * maskLength);\n    // Test the bit mask.\n    float maskTest = floor(dashPattern / pow(2.0, maskIndex));\n    vec4 fragColor = (mod(maskTest, 2.0) < 1.0) ? gapColor : color;\n    if (fragColor.a < 0.005) {   // matches 0/255 and 1/255\n        discard;\n    }\n\n    fragColor = czm_gammaCorrect(fragColor);\n    material.emission = fragColor.rgb;\n    material.alpha = fragColor.a;\n    return material;\n}\n"},3886:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform vec4 color;\nuniform float glowPower;\nuniform float taperPower;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    vec2 st = materialInput.st;\n    float glow = glowPower / abs(st.t - 0.5) - (glowPower / 0.5);\n\n    if (taperPower <= 0.99999) {\n        glow *= min(1.0, taperPower / (0.5 - st.s * 0.5) - (taperPower / 0.5));\n    }\n\n    vec4 fragColor;\n    fragColor.rgb = max(vec3(glow - 1.0 + color.rgb), color.rgb);\n    fragColor.a = clamp(0.0, 1.0, glow) * color.a;\n    fragColor = czm_gammaCorrect(fragColor);\n\n    material.emission = fragColor.rgb;\n    material.alpha = fragColor.a;\n\n    return material;\n}\n"},6493:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform vec4 color;\nuniform vec4 outlineColor;\nuniform float outlineWidth;\n\nvarying float v_width;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    vec2 st = materialInput.st;\n    float halfInteriorWidth =  0.5 * (v_width - outlineWidth) / v_width;\n    float b = step(0.5 - halfInteriorWidth, st.t);\n    b *= 1.0 - step(0.5 + halfInteriorWidth, st.t);\n\n    // Find the distance from the closest separator (region between two colors)\n    float d1 = abs(st.t - (0.5 - halfInteriorWidth));\n    float d2 = abs(st.t - (0.5 + halfInteriorWidth));\n    float dist = min(d1, d2);\n\n    vec4 currentColor = mix(outlineColor, color, b);\n    vec4 outColor = czm_antialias(outlineColor, color, currentColor, dist);\n    outColor = czm_gammaCorrect(outColor);\n\n    material.diffuse = outColor.rgb;\n    material.alpha = outColor.a;\n\n    return material;\n}\n"},52650:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform vec4 color;\nuniform vec4 rimColor;\nuniform float width;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    // See http://www.fundza.com/rman_shaders/surface/fake_rim/fake_rim1.html\n    float d = 1.0 - dot(materialInput.normalEC, normalize(materialInput.positionToEyeEC));\n    float s = smoothstep(1.0 - width, 1.0, d);\n\n    vec4 outColor = czm_gammaCorrect(color);\n    vec4 outRimColor = czm_gammaCorrect(rimColor);\n\n    material.diffuse = outColor.rgb;\n    material.emission = outRimColor.rgb * s;\n    material.alpha = mix(outColor.a, outRimColor.a, s);\n\n    return material;\n}\n"},47811:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D image;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n    vec4 rampColor = texture2D(image, vec2(materialInput.slope / (czm_pi / 2.0), 0.5));\n    rampColor = czm_gammaCorrect(rampColor);\n    material.diffuse = rampColor.rgb;\n    material.alpha = rampColor.a;\n    return material;\n}\n"},14160:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform vec4 evenColor;\nuniform vec4 oddColor;\nuniform float offset;\nuniform float repeat;\nuniform bool horizontal;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    // Based on the Stripes Fragment Shader in the Orange Book (11.1.2)\n    float coord = mix(materialInput.st.s, materialInput.st.t, float(horizontal));\n    float value = fract((coord - offset) * (repeat * 0.5));\n    float dist = min(value, min(abs(value - 0.5), 1.0 - value));\n\n    vec4 currentColor = mix(evenColor, oddColor, step(0.5, value));\n    vec4 color = czm_antialias(evenColor, oddColor, currentColor, dist);\n    color = czm_gammaCorrect(color);\n\n    material.diffuse = color.rgb;\n    material.alpha = color.a;\n\n    return material;\n}\n"},97499:(e,n,t)=>{t.d(n,{Z:()=>o});const o="// Thanks for the contribution Jonas\n// http://29a.ch/2012/7/19/webgl-terrain-rendering-water-fog\n\nuniform sampler2D specularMap;\nuniform sampler2D normalMap;\nuniform vec4 baseWaterColor;\nuniform vec4 blendColor;\nuniform float frequency;\nuniform float animationSpeed;\nuniform float amplitude;\nuniform float specularIntensity;\nuniform float fadeFactor;\n\nczm_material czm_getMaterial(czm_materialInput materialInput)\n{\n    czm_material material = czm_getDefaultMaterial(materialInput);\n\n    float time = czm_frameNumber * animationSpeed;\n\n    // fade is a function of the distance from the fragment and the frequency of the waves\n    float fade = max(1.0, (length(materialInput.positionToEyeEC) / 10000000000.0) * frequency * fadeFactor);\n\n    float specularMapValue = texture2D(specularMap, materialInput.st).r;\n\n    // note: not using directional motion at this time, just set the angle to 0.0;\n    vec4 noise = czm_getWaterNoise(normalMap, materialInput.st * frequency, time, 0.0);\n    vec3 normalTangentSpace = noise.xyz * vec3(1.0, 1.0, (1.0 / amplitude));\n\n    // fade out the normal perturbation as we move further from the water surface\n    normalTangentSpace.xy /= fade;\n\n    // attempt to fade out the normal perturbation as we approach non water areas (low specular map value)\n    normalTangentSpace = mix(vec3(0.0, 0.0, 50.0), normalTangentSpace, specularMapValue);\n\n    normalTangentSpace = normalize(normalTangentSpace);\n\n    // get ratios for alignment of the new normal vector with a vector perpendicular to the tangent plane\n    float tsPerturbationRatio = clamp(dot(normalTangentSpace, vec3(0.0, 0.0, 1.0)), 0.0, 1.0);\n\n    // fade out water effect as specular map value decreases\n    material.alpha = mix(blendColor.a, baseWaterColor.a, specularMapValue) * specularMapValue;\n\n    // base color is a blend of the water and non-water color based on the value from the specular map\n    // may need a uniform blend factor to better control this\n    material.diffuse = mix(blendColor.rgb, baseWaterColor.rgb, specularMapValue);\n\n    // diffuse highlights are based on how perturbed the normal is\n    material.diffuse += (0.1 * tsPerturbationRatio);\n\n    material.diffuse = material.diffuse;\n\n    material.normal = normalize(materialInput.tangentToEyeMatrix * normalTangentSpace);\n\n    material.specular = specularIntensity;\n    material.shininess = 10.0;\n\n    return material;\n}\n"},88359:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void filterByPassType(vec4 featureColor)\n{\n    bool styleTranslucent = (featureColor.a != 1.0);\n    // Only render translucent features in the translucent pass (if the style or the original command has translucency).\n    if (czm_pass == czm_passTranslucent && !styleTranslucent && !model_commandTranslucent)\n    {\n        discard;\n    }\n    // If the current pass is not the translucent pass and the style is not translucent, don't render the feature.\n    else if (czm_pass != czm_passTranslucent && styleTranslucent)\n    {\n        discard;\n    }\n}\n\nvoid cpuStylingStage(inout czm_modelMaterial material, SelectedFeature feature)\n{\n    vec4 featureColor = feature.color;\n\n    if (featureColor.a == 0.0)\n    {\n        discard;\n    }\n\n    // If a feature ID vertex attribute is used, the pass type filter is applied in the vertex shader.\n    // So, we only apply in in the fragment shader if the feature ID texture is used.\n    #ifdef HAS_SELECTED_FEATURE_ID_TEXTURE\n    filterByPassType(featureColor);\n    #endif\n\n    featureColor = czm_gammaCorrect(featureColor);\n\n    float highlight = ceil(model_colorBlend);\n    material.diffuse *= mix(featureColor.rgb, vec3(1.0), highlight);\n    material.alpha *= featureColor.a;\n}\n"},36123:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void filterByPassType(inout vec3 positionMC, vec4 featureColor)\n{\n    bool styleTranslucent = (featureColor.a != 1.0);\n    // Only render translucent features in the translucent pass (if the style or the original command has translucency).\n    if (czm_pass == czm_passTranslucent && !styleTranslucent && !model_commandTranslucent)\n    {\n        positionMC *= 0.0;\n    }\n    // If the current pass is not the transluceny pass and the style is not translucent, don't rendeer the feature.\n    else if (czm_pass != czm_passTranslucent && styleTranslucent)\n    {\n        positionMC *= 0.0;\n    }\n}\n\nvoid cpuStylingStage(inout vec3 positionMC, inout SelectedFeature feature)\n{\n    float show = ceil(feature.color.a);\n    positionMC *= show;\n\n    #ifdef HAS_SELECTED_FEATURE_ID_ATTRIBUTE\n    filterByPassType(positionMC, feature.color);\n    #endif\n}\n"},9434:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void customShaderStage(\n    inout czm_modelMaterial material,\n    ProcessedAttributes attributes,\n    FeatureIds featureIds,\n    Metadata metadata\n) {\n    // FragmentInput and initializeInputStruct() are dynamically generated in JS, \n    // see CustomShaderPipelineStage.js\n    FragmentInput fsInput;\n    initializeInputStruct(fsInput, attributes);\n    fsInput.featureIds = featureIds;\n    fsInput.metadata = metadata;\n    fragmentMain(fsInput, material);\n}\n"},87289:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void customShaderStage(\n    inout czm_modelVertexOutput vsOutput, \n    inout ProcessedAttributes attributes, \n    FeatureIds featureIds,\n    Metadata metadata\n) {\n    // VertexInput and initializeInputStruct() are dynamically generated in JS, \n    // see CustomShaderPipelineStage.js\n    VertexInput vsInput;\n    initializeInputStruct(vsInput, attributes);\n    vsInput.featureIds = featureIds;\n    vsInput.metadata = metadata;\n    vertexMain(vsInput, vsOutput);\n    attributes.positionMC = vsOutput.positionMC;\n}\n"},35598:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void featureIdStage(out FeatureIds featureIds, ProcessedAttributes attributes) {\n  initializeFeatureIds(featureIds, attributes);\n  initializeFeatureIdAliases(featureIds);\n}\n"},60073:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void featureIdStage(out FeatureIds featureIds, ProcessedAttributes attributes) \n{\n  initializeFeatureIds(featureIds, attributes);\n  initializeFeatureIdAliases(featureIds);\n  setFeatureIdVaryings();\n}\n"},24195:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void geometryStage(out ProcessedAttributes attributes)\n{\n  attributes.positionMC = v_positionMC;\n  attributes.positionEC = v_positionEC;\n\n  #ifdef COMPUTE_POSITION_WC\n  attributes.positionWC = v_positionWC;\n  #endif\n\n  #ifdef HAS_NORMALS\n  // renormalize after interpolation\n  attributes.normalEC = normalize(v_normalEC);\n  #endif\n\n  #ifdef HAS_TANGENTS\n  attributes.tangentEC = normalize(v_tangentEC);\n  #endif\n\n  #ifdef HAS_BITANGENTS\n  attributes.bitangentEC = normalize(v_bitangentEC);\n  #endif\n\n  // Everything else is dynamically generated in GeometryPipelineStage\n  setDynamicVaryings(attributes);\n}\n"},28085:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void geometryStage(inout ProcessedAttributes attributes, mat4 modelView, mat3 normal) \n{\n    // Compute positions in different coordinate systems\n    vec3 positionMC = attributes.positionMC;\n    v_positionMC = positionMC;\n    v_positionEC = (modelView * vec4(positionMC, 1.0)).xyz;\n\n    #ifdef USE_2D_POSITIONS\n    vec3 position2D = attributes.position2D;\n    vec3 positionEC = (u_modelView2D * vec4(position2D, 1.0)).xyz;\n    gl_Position = czm_projection * vec4(positionEC, 1.0);\n    #else\n    gl_Position = czm_projection * vec4(v_positionEC, 1.0);\n    #endif\n\n    // Sometimes the fragment shader needs this (e.g. custom shaders)\n    #ifdef COMPUTE_POSITION_WC\n    // Note that this is a 32-bit position which may result in jitter on small\n    // scales.\n    v_positionWC = (czm_model * vec4(positionMC, 1.0)).xyz;\n    #endif\n\n    #ifdef HAS_NORMALS\n    v_normalEC = normal * attributes.normalMC;\n    #endif\n\n    #ifdef HAS_TANGENTS\n    v_tangentEC = normalize(normal * attributes.tangentMC);    \n    #endif\n\n    #ifdef HAS_BITANGENTS\n    v_bitangentEC = normalize(normal * attributes.bitangentMC);\n    #endif\n\n    // All other varyings need to be dynamically generated in\n    // GeometryPipelineStage\n    setDynamicVaryings(attributes);\n}\n"},19411:(e,n,t)=>{t.d(n,{Z:()=>o});const o="vec3 proceduralIBL(\n    vec3 positionEC,\n    vec3 normalEC,\n    vec3 lightDirectionEC,\n    vec3 lightColorHdr,\n    czm_pbrParameters pbrParameters\n) {\n    vec3 v = -positionEC;\n    vec3 positionWC = vec3(czm_inverseView * vec4(positionEC, 1.0));\n    vec3 vWC = -normalize(positionWC);\n    vec3 l = normalize(lightDirectionEC);\n    vec3 n = normalEC;\n    vec3 r = normalize(czm_inverseViewRotation * normalize(reflect(v, n)));\n\n    float NdotL = clamp(dot(n, l), 0.001, 1.0);\n    float NdotV = abs(dot(n, v)) + 0.001;\n\n    // Figure out if the reflection vector hits the ellipsoid\n    float vertexRadius = length(positionWC);\n    float horizonDotNadir = 1.0 - min(1.0, czm_ellipsoidRadii.x / vertexRadius);\n    float reflectionDotNadir = dot(r, normalize(positionWC));\n    // Flipping the X vector is a cheap way to get the inverse of czm_temeToPseudoFixed, since that's a rotation about Z.\n    r.x = -r.x;\n    r = -normalize(czm_temeToPseudoFixed * r);\n    r.x = -r.x;\n\n    vec3 diffuseColor = pbrParameters.diffuseColor;\n    float roughness = pbrParameters.roughness;\n    vec3 specularColor = pbrParameters.f0;\n\n    float inverseRoughness = 1.04 - roughness;\n    inverseRoughness *= inverseRoughness;\n    vec3 sceneSkyBox = textureCube(czm_environmentMap, r).rgb * inverseRoughness;\n\n    float atmosphereHeight = 0.05;\n    float blendRegionSize = 0.1 * ((1.0 - inverseRoughness) * 8.0 + 1.1 - horizonDotNadir);\n    float blendRegionOffset = roughness * -1.0;\n    float farAboveHorizon = clamp(horizonDotNadir - blendRegionSize * 0.5 + blendRegionOffset, 1.0e-10 - blendRegionSize, 0.99999);\n    float aroundHorizon = clamp(horizonDotNadir + blendRegionSize * 0.5, 1.0e-10 - blendRegionSize, 0.99999);\n    float farBelowHorizon = clamp(horizonDotNadir + blendRegionSize * 1.5, 1.0e-10 - blendRegionSize, 0.99999);\n    float smoothstepHeight = smoothstep(0.0, atmosphereHeight, horizonDotNadir);\n    vec3 belowHorizonColor = mix(vec3(0.1, 0.15, 0.25), vec3(0.4, 0.7, 0.9), smoothstepHeight);\n    vec3 nadirColor = belowHorizonColor * 0.5;\n    vec3 aboveHorizonColor = mix(vec3(0.9, 1.0, 1.2), belowHorizonColor, roughness * 0.5);\n    vec3 blueSkyColor = mix(vec3(0.18, 0.26, 0.48), aboveHorizonColor, reflectionDotNadir * inverseRoughness * 0.5 + 0.75);\n    vec3 zenithColor = mix(blueSkyColor, sceneSkyBox, smoothstepHeight);\n    vec3 blueSkyDiffuseColor = vec3(0.7, 0.85, 0.9); \n    float diffuseIrradianceFromEarth = (1.0 - horizonDotNadir) * (reflectionDotNadir * 0.25 + 0.75) * smoothstepHeight;  \n    float diffuseIrradianceFromSky = (1.0 - smoothstepHeight) * (1.0 - (reflectionDotNadir * 0.25 + 0.25));\n    vec3 diffuseIrradiance = blueSkyDiffuseColor * clamp(diffuseIrradianceFromEarth + diffuseIrradianceFromSky, 0.0, 1.0);\n    float notDistantRough = (1.0 - horizonDotNadir * roughness * 0.8);\n    vec3 specularIrradiance = mix(zenithColor, aboveHorizonColor, smoothstep(farAboveHorizon, aroundHorizon, reflectionDotNadir) * notDistantRough);\n    specularIrradiance = mix(specularIrradiance, belowHorizonColor, smoothstep(aroundHorizon, farBelowHorizon, reflectionDotNadir) * inverseRoughness);\n    specularIrradiance = mix(specularIrradiance, nadirColor, smoothstep(farBelowHorizon, 1.0, reflectionDotNadir) * inverseRoughness);\n\n    // Luminance model from page 40 of http://silviojemma.com/public/papers/lighting/spherical-harmonic-lighting.pdf\n    #ifdef USE_SUN_LUMINANCE \n    // Angle between sun and zenith\n    float LdotZenith = clamp(dot(normalize(czm_inverseViewRotation * l), vWC), 0.001, 1.0);\n    float S = acos(LdotZenith);\n    // Angle between zenith and current pixel\n    float NdotZenith = clamp(dot(normalize(czm_inverseViewRotation * n), vWC), 0.001, 1.0);\n    // Angle between sun and current pixel\n    float gamma = acos(NdotL);\n    float numerator = ((0.91 + 10.0 * exp(-3.0 * gamma) + 0.45 * pow(NdotL, 2.0)) * (1.0 - exp(-0.32 / NdotZenith)));\n    float denominator = (0.91 + 10.0 * exp(-3.0 * S) + 0.45 * pow(LdotZenith,2.0)) * (1.0 - exp(-0.32));\n    float luminance = model_luminanceAtZenith * (numerator / denominator);\n    #endif \n\n    vec2 brdfLut = texture2D(czm_brdfLut, vec2(NdotV, roughness)).rg;\n    vec3 iblColor = (diffuseIrradiance * diffuseColor * model_iblFactor.x) + (specularIrradiance * czm_srgbToLinear(specularColor * brdfLut.x + brdfLut.y) * model_iblFactor.y);\n    float maximumComponent = max(max(lightColorHdr.x, lightColorHdr.y), lightColorHdr.z);\n    vec3 lightColor = lightColorHdr / max(maximumComponent, 1.0);\n    iblColor *= lightColor;\n\n    #ifdef USE_SUN_LUMINANCE \n    iblColor *= luminance;\n    #endif\n\n    return iblColor;\n}\n\nvec3 textureIBL(\n    vec3 positionEC,\n    vec3 normalEC,\n    vec3 lightDirectionEC,\n    czm_pbrParameters pbrParameters\n) {\n    vec3 diffuseColor = pbrParameters.diffuseColor;\n    float roughness = pbrParameters.roughness;\n    vec3 specularColor = pbrParameters.f0;\n\n    vec3 v = -positionEC;\n    vec3 n = normalEC;\n    vec3 l = normalize(lightDirectionEC);\n    vec3 h = normalize(v + l);\n\n    float NdotV = abs(dot(n, v)) + 0.001;\n    float VdotH = clamp(dot(v, h), 0.0, 1.0);\n\n    const mat3 yUpToZUp = mat3(\n        -1.0, 0.0, 0.0,\n        0.0, 0.0, -1.0, \n        0.0, 1.0, 0.0\n    ); \n    vec3 cubeDir = normalize(yUpToZUp * model_iblReferenceFrameMatrix * normalize(reflect(-v, n))); \n\n    #ifdef DIFFUSE_IBL \n        #ifdef CUSTOM_SPHERICAL_HARMONICS\n        vec3 diffuseIrradiance = czm_sphericalHarmonics(cubeDir, model_sphericalHarmonicCoefficients); \n        #else\n        vec3 diffuseIrradiance = czm_sphericalHarmonics(cubeDir, czm_sphericalHarmonicCoefficients); \n        #endif \n    #else \n    vec3 diffuseIrradiance = vec3(0.0); \n    #endif \n\n    #ifdef SPECULAR_IBL\n    vec3 r0 = specularColor.rgb;\n    float reflectance = max(max(r0.r, r0.g), r0.b);\n    vec3 r90 = vec3(clamp(reflectance * 25.0, 0.0, 1.0));\n    vec3 F = fresnelSchlick2(r0, r90, VdotH);\n    \n    vec2 brdfLut = texture2D(czm_brdfLut, vec2(NdotV, roughness)).rg;\n      #ifdef CUSTOM_SPECULAR_IBL \n      vec3 specularIBL = czm_sampleOctahedralProjection(model_specularEnvironmentMaps, model_specularEnvironmentMapsSize, cubeDir, roughness * model_specularEnvironmentMapsMaximumLOD, model_specularEnvironmentMapsMaximumLOD);\n      #else \n      vec3 specularIBL = czm_sampleOctahedralProjection(czm_specularEnvironmentMaps, czm_specularEnvironmentMapSize, cubeDir,  roughness * czm_specularEnvironmentMapsMaximumLOD, czm_specularEnvironmentMapsMaximumLOD);\n      #endif \n    specularIBL *= F * brdfLut.x + brdfLut.y;\n    #else \n    vec3 specularIBL = vec3(0.0); \n    #endif\n\n    return diffuseColor * diffuseIrradiance + specularColor * specularIBL;\n}\n\nvec3 imageBasedLightingStage(\n    vec3 positionEC,\n    vec3 normalEC,\n    vec3 lightDirectionEC,\n    vec3 lightColorHdr,\n    czm_pbrParameters pbrParameters\n) {\n  #if defined(DIFFUSE_IBL) || defined(SPECULAR_IBL)\n  // Environment maps were provided, use them for IBL\n  return textureIBL(\n      positionEC,\n      normalEC,\n      lightDirectionEC,\n      pbrParameters\n  );\n  #else\n  // Use the procedural IBL if there are no environment maps\n  return proceduralIBL(\n      positionEC,\n      normalEC,\n      lightDirectionEC,\n      lightColorHdr,\n      pbrParameters\n  );\n  #endif\n}"},21393:(e,n,t)=>{t.d(n,{Z:()=>o});const o="mat4 getInstancingTransform()\n{\n    mat4 instancingTransform;\n\n    #ifdef HAS_INSTANCE_MATRICES\n    instancingTransform = mat4(\n        a_instancingTransformRow0.x, a_instancingTransformRow1.x, a_instancingTransformRow2.x, 0.0, // Column 1\n        a_instancingTransformRow0.y, a_instancingTransformRow1.y, a_instancingTransformRow2.y, 0.0, // Column 2\n        a_instancingTransformRow0.z, a_instancingTransformRow1.z, a_instancingTransformRow2.z, 0.0, // Column 3\n        a_instancingTransformRow0.w, a_instancingTransformRow1.w, a_instancingTransformRow2.w, 1.0  // Column 4\n    );\n    #else\n    vec3 translation = vec3(0.0, 0.0, 0.0);\n    vec3 scale = vec3(1.0, 1.0, 1.0);\n    \n        #ifdef HAS_INSTANCE_TRANSLATION\n        translation = a_instanceTranslation;\n        #endif\n        #ifdef HAS_INSTANCE_SCALE\n        scale = a_instanceScale;\n        #endif\n\n    instancingTransform = mat4(\n        scale.x, 0.0, 0.0, 0.0,\n        0.0, scale.y, 0.0, 0.0,\n        0.0, 0.0, scale.z, 0.0,\n        translation.x, translation.y, translation.z, 1.0\n    ); \n    #endif\n\n    return instancingTransform;\n}\n"},25799:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void instancingStage(inout vec3 positionMC) \n{\n    mat4 instancingTransform = getInstancingTransform();\n\n    positionMC = (instancingTransform * vec4(positionMC, 1.0)).xyz;\n}\n"},32458:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void legacyInstancingStage(inout vec3 positionMC, out mat4 instanceModelView, out mat3 instanceModelViewInverseTranspose)\n{\n    mat4 instancingTransform = getInstancingTransform();\n\n    mat4 instanceModel = instancingTransform * u_instance_nodeTransform;\n    instanceModelView = u_instance_modifiedModelView;\n    instanceModelViewInverseTranspose = mat3(u_instance_modifiedModelView * instanceModel);\n\n    positionMC = (instanceModel * vec4(positionMC, 1.0)).xyz;\n}\n"},80634:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef LIGHTING_PBR\nvec3 computePbrLighting(czm_modelMaterial inputMaterial, ProcessedAttributes attributes)\n{\n    czm_pbrParameters pbrParameters;\n    pbrParameters.diffuseColor = inputMaterial.diffuse;\n    pbrParameters.f0 = inputMaterial.specular;\n    pbrParameters.roughness = inputMaterial.roughness;\n    \n    #ifdef USE_CUSTOM_LIGHT_COLOR\n    vec3 lightColorHdr = model_lightColorHdr;\n    #else\n    vec3 lightColorHdr = czm_lightColorHdr;\n    #endif\n\n    vec3 color = inputMaterial.diffuse;\n    #ifdef HAS_NORMALS\n    color = czm_pbrLighting(\n        attributes.positionEC,\n        inputMaterial.normalEC,\n        czm_lightDirectionEC,\n        lightColorHdr,\n        pbrParameters\n    );\n\n        #ifdef USE_IBL_LIGHTING\n        color += imageBasedLightingStage(\n            attributes.positionEC,\n            inputMaterial.normalEC,\n            czm_lightDirectionEC,\n            lightColorHdr,\n            pbrParameters\n        );\n        #endif\n    #endif\n\n    color *= inputMaterial.occlusion;\n    color += inputMaterial.emissive;\n\n    // In HDR mode, the frame buffer is in linear color space. The\n    // post-processing stages (see PostProcessStageCollection) will handle\n    // tonemapping. However, if HDR is not enabled, we must tonemap else large\n    // values may be clamped to 1.0\n    #ifndef HDR \n    color = czm_acesTonemapping(color);\n    #endif \n\n    return color;\n}\n#endif\n\nvoid lightingStage(inout czm_modelMaterial material, ProcessedAttributes attributes)\n{\n    // Even though the lighting will only set the diffuse color,\n    // pass all other properties so further stages have access to them.\n    vec3 color = vec3(0.0);\n\n    #ifdef LIGHTING_PBR\n    color = computePbrLighting(material, attributes);\n    #else // unlit\n    color = material.diffuse;\n    #endif\n\n    // If HDR is not enabled, the frame buffer stores sRGB colors rather than\n    // linear colors so the linear value must be converted.\n    #ifndef HDR\n    color = czm_linearToSrgb(color);\n    #endif\n\n    material.diffuse = color;\n}\n"},84681:(e,n,t)=>{t.d(n,{Z:()=>o});const o="// If the style color is white, it implies the feature has not been styled.\nbool isDefaultStyleColor(vec3 color)\n{\n    return all(greaterThan(color, vec3(1.0 - czm_epsilon3)));\n}\n\nvec3 blend(vec3 sourceColor, vec3 styleColor, float styleColorBlend)\n{\n    vec3 blendColor = mix(sourceColor, styleColor, styleColorBlend);\n    vec3 color = isDefaultStyleColor(styleColor.rgb) ? sourceColor : blendColor;\n    return color;\n}\n\nvec2 computeTextureTransform(vec2 texCoord, mat3 textureTransform)\n{\n    return vec2(textureTransform * vec3(texCoord, 1.0));\n}\n\n#ifdef HAS_NORMALS\nvec3 computeNormal(ProcessedAttributes attributes)\n{\n    // Geometry normal. This is already normalized \n    vec3 ng = attributes.normalEC;\n\n    vec3 normal = ng;\n    #if defined(HAS_NORMAL_TEXTURE) && !defined(USE_WIREFRAME)\n    vec2 normalTexCoords = TEXCOORD_NORMAL;\n        #ifdef HAS_NORMAL_TEXTURE_TRANSFORM\n        normalTexCoords = computeTextureTransform(normalTexCoords, u_normalTextureTransform);\n        #endif\n\n        // If HAS_BITANGENTS is set, then HAS_TANGENTS is also set\n        #ifdef HAS_BITANGENTS\n        vec3 t = attributes.tangentEC;\n        vec3 b = attributes.bitangentEC;\n        mat3 tbn = mat3(t, b, ng);\n        vec3 n = texture2D(u_normalTexture, normalTexCoords).rgb;\n        normal = normalize(tbn * (2.0 * n - 1.0));\n        #elif defined(GL_OES_standard_derivatives)\n        // Compute tangents\n        vec3 positionEC = attributes.positionEC;\n        vec3 pos_dx = dFdx(positionEC);\n        vec3 pos_dy = dFdy(positionEC);\n        vec3 tex_dx = dFdx(vec3(normalTexCoords,0.0));\n        vec3 tex_dy = dFdy(vec3(normalTexCoords,0.0));\n        vec3 t = (tex_dy.t * pos_dx - tex_dx.t * pos_dy) / (tex_dx.s * tex_dy.t - tex_dy.s * tex_dx.t);\n        t = normalize(t - ng * dot(ng, t));\n        vec3 b = normalize(cross(ng, t));\n        mat3 tbn = mat3(t, b, ng);\n        vec3 n = texture2D(u_normalTexture, normalTexCoords).rgb;\n        normal = normalize(tbn * (2.0 * n - 1.0));\n        #endif\n    #endif\n\n    return normal;\n}\n#endif\n\nvoid materialStage(inout czm_modelMaterial material, ProcessedAttributes attributes, SelectedFeature feature)\n{\n\n    #ifdef HAS_NORMALS\n    material.normalEC = computeNormal(attributes);\n    #endif\n\n    vec4 baseColorWithAlpha = vec4(1.0);\n    // Regardless of whether we use PBR, set a base color\n    #ifdef HAS_BASE_COLOR_TEXTURE\n    vec2 baseColorTexCoords = TEXCOORD_BASE_COLOR;\n\n        #ifdef HAS_BASE_COLOR_TEXTURE_TRANSFORM\n        baseColorTexCoords = computeTextureTransform(baseColorTexCoords, u_baseColorTextureTransform);\n        #endif\n\n    baseColorWithAlpha = czm_srgbToLinear(texture2D(u_baseColorTexture, baseColorTexCoords));\n\n        #ifdef HAS_BASE_COLOR_FACTOR\n        baseColorWithAlpha *= u_baseColorFactor;\n        #endif\n    #elif defined(HAS_BASE_COLOR_FACTOR)\n    baseColorWithAlpha = u_baseColorFactor;\n    #endif\n\n    #ifdef HAS_COLOR_0\n    vec4 color = attributes.color_0;\n        // .pnts files store colors in the sRGB color space\n        #ifdef HAS_SRGB_COLOR\n        color = czm_srgbToLinear(color);\n        #endif\n    baseColorWithAlpha *= color;\n    #endif\n\n    material.diffuse = baseColorWithAlpha.rgb;\n    material.alpha = baseColorWithAlpha.a;\n\n    #ifdef USE_CPU_STYLING\n    material.diffuse = blend(material.diffuse, feature.color.rgb, model_colorBlend);\n    #endif\n\n    #ifdef HAS_OCCLUSION_TEXTURE\n    vec2 occlusionTexCoords = TEXCOORD_OCCLUSION;\n        #ifdef HAS_OCCLUSION_TEXTURE_TRANSFORM\n        occlusionTexCoords = computeTextureTransform(occlusionTexCoords, u_occlusionTextureTransform);\n        #endif\n    material.occlusion = texture2D(u_occlusionTexture, occlusionTexCoords).r;\n    #endif\n\n    #ifdef HAS_EMISSIVE_TEXTURE\n    vec2 emissiveTexCoords = TEXCOORD_EMISSIVE;\n        #ifdef HAS_EMISSIVE_TEXTURE_TRANSFORM\n        emissiveTexCoords = computeTextureTransform(emissiveTexCoords, u_emissiveTextureTransform);\n        #endif\n\n    vec3 emissive = czm_srgbToLinear(texture2D(u_emissiveTexture, emissiveTexCoords).rgb);\n        #ifdef HAS_EMISSIVE_FACTOR\n        emissive *= u_emissiveFactor;\n        #endif\n    material.emissive = emissive;\n    #elif defined(HAS_EMISSIVE_FACTOR)\n    material.emissive = u_emissiveFactor;\n    #endif\n\n    #if defined(LIGHTING_PBR) && defined(USE_SPECULAR_GLOSSINESS)\n        #ifdef HAS_SPECULAR_GLOSSINESS_TEXTURE\n        vec2 specularGlossinessTexCoords = TEXCOORD_SPECULAR_GLOSSINESS;\n          #ifdef HAS_SPECULAR_GLOSSINESS_TEXTURE_TRANSFORM\n          specularGlossinessTexCoords = computeTextureTransform(specularGlossinessTexCoords, u_specularGlossinessTextureTransform);\n          #endif\n\n        vec4 specularGlossiness = czm_srgbToLinear(texture2D(u_specularGlossinessTexture, specularGlossinessTexCoords));\n        vec3 specular = specularGlossiness.rgb;\n        float glossiness = specularGlossiness.a;\n            #ifdef HAS_SPECULAR_FACTOR\n            specular *= u_specularFactor;\n            #endif\n\n            #ifdef HAS_GLOSSINESS_FACTOR\n            glossiness *= u_glossinessFactor;\n            #endif\n        #else\n            #ifdef HAS_SPECULAR_FACTOR\n            vec3 specular = clamp(u_specularFactor, vec3(0.0), vec3(1.0));\n            #else\n            vec3 specular = vec3(1.0);\n            #endif\n\n            #ifdef HAS_GLOSSINESS_FACTOR\n            float glossiness = clamp(u_glossinessFactor, 0.0, 1.0);\n            #else\n            float glossiness = 1.0;\n            #endif\n        #endif\n\n        #ifdef HAS_DIFFUSE_TEXTURE\n        vec2 diffuseTexCoords = TEXCOORD_DIFFUSE;\n            #ifdef HAS_DIFFUSE_TEXTURE_TRANSFORM\n            diffuseTexCoords = computeTextureTransform(diffuseTexCoords, u_diffuseTextureTransform);\n            #endif\n\n        vec4 diffuse = czm_srgbToLinear(texture2D(u_diffuseTexture, diffuseTexCoords));\n            #ifdef HAS_DIFFUSE_FACTOR\n            diffuse *= u_diffuseFactor;\n            #endif\n        #elif defined(HAS_DIFFUSE_FACTOR)\n        vec4 diffuse = clamp(u_diffuseFactor, vec4(0.0), vec4(1.0));\n        #else\n        vec4 diffuse = vec4(1.0);\n        #endif\n    czm_pbrParameters parameters = czm_pbrSpecularGlossinessMaterial(\n      diffuse.rgb,\n      specular,\n      glossiness\n    );\n    material.diffuse = parameters.diffuseColor;\n    // the specular glossiness extension's alpha overrides anything set\n    // by the base material.\n    material.alpha = diffuse.a;\n    material.specular = parameters.f0;\n    material.roughness = parameters.roughness;\n    #elif defined(LIGHTING_PBR)\n        #ifdef HAS_METALLIC_ROUGHNESS_TEXTURE\n        vec2 metallicRoughnessTexCoords = TEXCOORD_METALLIC_ROUGHNESS;\n            #ifdef HAS_METALLIC_ROUGHNESS_TEXTURE_TRANSFORM\n            metallicRoughnessTexCoords = computeTextureTransform(metallicRoughnessTexCoords, u_metallicRoughnessTextureTransform);\n            #endif\n\n        vec3 metallicRoughness = texture2D(u_metallicRoughnessTexture, metallicRoughnessTexCoords).rgb;\n        float metalness = clamp(metallicRoughness.b, 0.0, 1.0);\n        float roughness = clamp(metallicRoughness.g, 0.04, 1.0);\n            #ifdef HAS_METALLIC_FACTOR\n            metalness *= u_metallicFactor;\n            #endif\n\n            #ifdef HAS_ROUGHNESS_FACTOR\n            roughness *= u_roughnessFactor;\n            #endif\n        #else\n            #ifdef HAS_METALLIC_FACTOR\n            float metalness = clamp(u_metallicFactor, 0.0, 1.0);\n            #else\n            float metalness = 1.0;\n            #endif\n\n            #ifdef HAS_ROUGHNESS_FACTOR\n            float roughness = clamp(u_roughnessFactor, 0.04, 1.0);\n            #else\n            float roughness = 1.0;\n            #endif\n        #endif\n    czm_pbrParameters parameters = czm_pbrMetallicRoughnessMaterial(\n      material.diffuse,\n      metalness,\n      roughness\n    );\n    material.diffuse = parameters.diffuseColor;\n    material.specular = parameters.f0;\n    material.roughness = parameters.roughness;\n    #endif\n}\n"},67917:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void metadataStage(out Metadata metadata, ProcessedAttributes attributes)\n{\n  initializeMetadata(metadata, attributes);\n}\n"},12209:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void metadataStage(out Metadata metadata, ProcessedAttributes attributes)\n{\n  initializeMetadata(metadata, attributes);\n  setMetadataVaryings();\n}\n"},16023:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef USE_CLIPPING_PLANES_FLOAT_TEXTURE\nvec4 getClippingPlane(\n    highp sampler2D packedClippingPlanes,\n    int clippingPlaneNumber,\n    mat4 transform\n) {\n    int pixY = clippingPlaneNumber / CLIPPING_PLANES_TEXTURE_WIDTH;\n    int pixX = clippingPlaneNumber - (pixY * CLIPPING_PLANES_TEXTURE_WIDTH);\n    float pixelWidth = 1.0 / float(CLIPPING_PLANES_TEXTURE_WIDTH);\n    float pixelHeight = 1.0 / float(CLIPPING_PLANES_TEXTURE_HEIGHT);\n    float u = (float(pixX) + 0.5) * pixelWidth; // sample from center of pixel\n    float v = (float(pixY) + 0.5) * pixelHeight;\n    vec4 plane = texture2D(packedClippingPlanes, vec2(u, v));\n    return czm_transformPlane(plane, transform);\n}\n#else\n// Handle uint8 clipping texture instead\nvec4 getClippingPlane(\n    highp sampler2D packedClippingPlanes,\n    int clippingPlaneNumber,\n    mat4 transform\n) {\n    int clippingPlaneStartIndex = clippingPlaneNumber * 2; // clipping planes are two pixels each\n    int pixY = clippingPlaneStartIndex / CLIPPING_PLANES_TEXTURE_WIDTH;\n    int pixX = clippingPlaneStartIndex - (pixY * CLIPPING_PLANES_TEXTURE_WIDTH);\n    float pixelWidth = 1.0 / float(CLIPPING_PLANES_TEXTURE_WIDTH);\n    float pixelHeight = 1.0 / float(CLIPPING_PLANES_TEXTURE_HEIGHT);\n    float u = (float(pixX) + 0.5) * pixelWidth; // sample from center of pixel\n    float v = (float(pixY) + 0.5) * pixelHeight;\n    vec4 oct32 = texture2D(packedClippingPlanes, vec2(u, v)) * 255.0;\n    vec2 oct = vec2(oct32.x * 256.0 + oct32.y, oct32.z * 256.0 + oct32.w);\n    vec4 plane;\n    plane.xyz = czm_octDecode(oct, 65535.0);\n    plane.w = czm_unpackFloat(texture2D(packedClippingPlanes, vec2(u + pixelWidth, v)));\n    return czm_transformPlane(plane, transform);\n}\n#endif\n\nfloat clip(vec4 fragCoord, sampler2D clippingPlanes, mat4 clippingPlanesMatrix) {\n    vec4 position = czm_windowToEyeCoordinates(fragCoord);\n    vec3 clipNormal = vec3(0.0);\n    vec3 clipPosition = vec3(0.0);\n    float pixelWidth = czm_metersPerPixel(position);\n    \n    #ifdef UNION_CLIPPING_REGIONS\n    float clipAmount; // For union planes, we want to get the min distance. So we set the initial value to the first plane distance in the loop below.\n    #else\n    float clipAmount = 0.0;\n    bool clipped = true;\n    #endif\n\n    for (int i = 0; i < CLIPPING_PLANES_LENGTH; ++i) {\n        vec4 clippingPlane = getClippingPlane(clippingPlanes, i, clippingPlanesMatrix);\n        clipNormal = clippingPlane.xyz;\n        clipPosition = -clippingPlane.w * clipNormal;\n        float amount = dot(clipNormal, (position.xyz - clipPosition)) / pixelWidth;\n        \n        #ifdef UNION_CLIPPING_REGIONS\n        clipAmount = czm_branchFreeTernary(i == 0, amount, min(amount, clipAmount));\n        if (amount <= 0.0) {\n            discard;\n        }\n        #else\n        clipAmount = max(amount, clipAmount);\n        clipped = clipped && (amount <= 0.0);\n        #endif\n    }\n\n    #ifndef UNION_CLIPPING_REGIONS\n    if (clipped) {\n        discard;\n    }\n    #endif\n    \n    return clipAmount;\n}\n\nvoid modelClippingPlanesStage(inout vec4 color)\n{\n    float clipDistance = clip(gl_FragCoord, model_clippingPlanes, model_clippingPlanesMatrix);\n    vec4 clippingPlanesEdgeColor = vec4(1.0);\n    clippingPlanesEdgeColor.rgb = model_clippingPlanesEdgeStyle.rgb;\n    float clippingPlanesEdgeWidth = model_clippingPlanesEdgeStyle.a;\n    \n    if (clipDistance > 0.0 && clipDistance < clippingPlanesEdgeWidth) {\n        color = clippingPlanesEdgeColor;\n    }\n}\n"},63873:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void modelColorStage(inout czm_modelMaterial material)\n{\n    material.diffuse = mix(material.diffuse, model_color.rgb, model_colorBlend);\n    float highlight = ceil(model_colorBlend);\n    material.diffuse *= mix(model_color.rgb, vec3(1.0), highlight);\n    material.alpha *= model_color.a;\n}"},27028:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#if defined(HAS_NORMALS) && !defined(HAS_TANGENTS) && !defined(LIGHTING_UNLIT)\n    #ifdef GL_OES_standard_derivatives\n    #extension GL_OES_standard_derivatives : enable\n    #endif\n#endif\n\nczm_modelMaterial defaultModelMaterial()\n{\n    czm_modelMaterial material;\n    material.diffuse = vec3(1.0);\n    material.specular = vec3(0.04); // dielectric (non-metal)\n    material.roughness = 0.0;\n    material.occlusion = 1.0;\n    material.normalEC = vec3(0.0, 0.0, 1.0);\n    material.emissive = vec3(0.0);\n    material.alpha = 1.0;\n    return material;\n}\n\nvec4 handleAlpha(vec3 color, float alpha)\n{\n    #ifdef ALPHA_MODE_MASK\n    if (alpha < u_alphaCutoff) {\n        discard;\n    }\n    return vec4(color, 1.0);\n    #elif defined(ALPHA_MODE_BLEND)\n    return vec4(color, alpha);\n    #else // OPAQUE\n    return vec4(color, 1.0);\n    #endif\n}\n\nSelectedFeature selectedFeature;\n\nvoid main()\n{\n    #ifdef HAS_MODEL_SPLITTER\n    modelSplitterStage();\n    #endif\n\n    czm_modelMaterial material = defaultModelMaterial();\n\n    ProcessedAttributes attributes;\n    geometryStage(attributes);\n\n    FeatureIds featureIds;\n    featureIdStage(featureIds, attributes);\n\n    Metadata metadata;\n    metadataStage(metadata, attributes);\n\n    #ifdef HAS_SELECTED_FEATURE_ID\n    selectedFeatureIdStage(selectedFeature, featureIds);\n    #endif\n\n    #ifndef CUSTOM_SHADER_REPLACE_MATERIAL\n    materialStage(material, attributes, selectedFeature);\n    #endif\n\n    #ifdef HAS_CUSTOM_FRAGMENT_SHADER\n    customShaderStage(material, attributes, featureIds, metadata);\n    #endif\n\n    lightingStage(material, attributes);\n\n    #ifdef HAS_SELECTED_FEATURE_ID\n    cpuStylingStage(material, selectedFeature);\n    #endif\n\n    #ifdef HAS_MODEL_COLOR\n    modelColorStage(material);\n    #endif\n\n    vec4 color = handleAlpha(material.diffuse, material.alpha);\n\n    #ifdef HAS_CLIPPING_PLANES\n    modelClippingPlanesStage(color);\n    #endif\n\n    gl_FragColor = color;\n}\n"},99685:(e,n,t)=>{t.d(n,{Z:()=>o});const o="precision highp float;\n\nczm_modelVertexOutput defaultVertexOutput(vec3 positionMC) {\n    czm_modelVertexOutput vsOutput;\n    vsOutput.positionMC = positionMC;\n    vsOutput.pointSize = 1.0;\n    return vsOutput;\n}\n\nvoid main() \n{\n    // Initialize the attributes struct with all\n    // attributes except quantized ones.\n    ProcessedAttributes attributes;\n    initializeAttributes(attributes);\n\n    // Dequantize the quantized ones and add them to the\n    // attributes struct.\n    #ifdef USE_DEQUANTIZATION\n    dequantizationStage(attributes);\n    #endif\n\n    #ifdef HAS_MORPH_TARGETS\n    morphTargetsStage(attributes);\n    #endif\n\n    #ifdef HAS_SKINNING\n    skinningStage(attributes);\n    #endif\n\n    // Compute the bitangent according to the formula in the glTF spec.\n    // Normal and tangents can be affected by morphing and skinning, so\n    // the bitangent should not be computed until their values are finalized.\n    #ifdef HAS_BITANGENTS\n    attributes.bitangentMC = normalize(cross(attributes.normalMC, attributes.tangentMC) * attributes.tangentSignMC);\n    #endif\n\n    FeatureIds featureIds;\n    featureIdStage(featureIds, attributes);\n\n    #ifdef HAS_SELECTED_FEATURE_ID\n    SelectedFeature feature;\n    selectedFeatureIdStage(feature, featureIds);\n    cpuStylingStage(attributes.positionMC, feature);\n    #endif\n\n    #ifdef USE_2D_POSITIONS\n    // The scene mode 2D pipeline stage adds a different model view matrix to\n    // accurately project the model's positions in 2D. However, the output\n    // positions and normals should be transformed by the 3D matrices to keep\n    // the data the same for the fragment shader.\n    mat4 modelView = czm_modelView3D;\n    mat3 normal = czm_normal3D;\n    #else\n    // These are used for individual model projection because they will\n    // automatically change based on the scene mode.\n    mat4 modelView = czm_modelView;\n    mat3 normal = czm_normal;\n    #endif\n    \n\n    // Update the position for this instance in place\n    #ifdef HAS_INSTANCING\n\n        // The legacy instance stage is used when rendering i3dm models that \n        // encode instances transforms in world space, as opposed to glTF models\n        // that use EXT_mesh_gpu_instancing, where instance transforms are encoded\n        // in object space.\n        #ifdef USE_LEGACY_INSTANCING\n        mat4 instanceModelView;\n        mat3 instanceModelViewInverseTranspose;\n        \n        legacyInstancingStage(attributes.positionMC, instanceModelView, instanceModelViewInverseTranspose);\n\n        modelView = instanceModelView;\n        normal = instanceModelViewInverseTranspose;\n        #else\n        instancingStage(attributes.positionMC);\n        #endif\n\n        #ifdef USE_PICKING\n        v_pickColor = a_pickColor;\n        #endif\n\n    #endif\n\n    Metadata metadata;\n    metadataStage(metadata, attributes);\n\n    #ifdef HAS_CUSTOM_VERTEX_SHADER\n    czm_modelVertexOutput vsOutput = defaultVertexOutput(attributes.positionMC);\n    customShaderStage(vsOutput, attributes, featureIds, metadata);\n    #endif\n\n    // Compute the final position in each coordinate system needed.\n    // This also sets gl_Position.\n    geometryStage(attributes, modelView, normal);    \n\n    #ifdef PRIMITIVE_TYPE_POINTS\n        #ifdef HAS_CUSTOM_VERTEX_SHADER\n        gl_PointSize = vsOutput.pointSize;\n        #elif defined(USE_POINT_CLOUD_ATTENUATION)\n        gl_PointSize = pointCloudAttenuationStage(v_positionEC);\n        #else\n        gl_PointSize = 1.0;\n        #endif\n    #endif\n}\n"},90708:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void modelSplitterStage()\n{\n    // Don't split when rendering the shadow map, because it is rendered from\n    // the perspective of a totally different camera.\n#ifndef SHADOW_MAP\n    if (model_splitDirection < 0.0 && gl_FragCoord.x > czm_splitPosition) discard;\n    if (model_splitDirection > 0.0 && gl_FragCoord.x < czm_splitPosition) discard;\n#endif\n}\n"},94786:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void morphTargetsStage(inout ProcessedAttributes attributes) \n{\n    vec3 positionMC = attributes.positionMC;\n    attributes.positionMC = getMorphedPosition(positionMC);\n\n    #ifdef HAS_NORMALS\n    vec3 normalMC = attributes.normalMC;\n    attributes.normalMC = getMorphedNormal(normalMC);\n    #endif\n\n    #ifdef HAS_TANGENTS\n    vec3 tangentMC = attributes.tangentMC;\n    attributes.tangentMC = getMorphedTangent(tangentMC);\n    #endif\n}"},98985:(e,n,t)=>{t.d(n,{Z:()=>o});const o="float pointCloudAttenuationStage(vec3 positionEC) {\n  // Variables are packed into a single vector to minimize gl.uniformXXX() calls\n  float pointSize = model_pointCloudAttenuation.x;\n  float geometricError = model_pointCloudAttenuation.y;\n  float depthMultiplier = model_pointCloudAttenuation.z;\n  float depth = -positionEC.z;\n  return min((geometricError / depth) * depthMultiplier, pointSize);\n}\n"},28891:(e,n,t)=>{t.d(n,{Z:()=>o});const o="vec2 computeSt(float featureId)\n{\n    float stepX = model_textureStep.x;\n    float centerX = model_textureStep.y;\n\n    #ifdef MULTILINE_BATCH_TEXTURE\n    float stepY = model_textureStep.z;\n    float centerY = model_textureStep.w;\n\n    float xId = mod(featureId, model_textureDimensions.x); \n    float yId = floor(featureId / model_textureDimensions.x);\n    \n    return vec2(centerX + (xId * stepX), centerY + (yId * stepY));\n    #else\n    return vec2(centerX + (featureId * stepX), 0.5);\n    #endif\n}\n\nvoid selectedFeatureIdStage(out SelectedFeature feature, FeatureIds featureIds)\n{   \n    int featureId = featureIds.SELECTED_FEATURE_ID;\n\n\n    if (featureId < model_featuresLength)\n    {\n        vec2 featureSt = computeSt(float(featureId));\n\n        feature.id = featureId;\n        feature.st = featureSt;\n        feature.color = texture2D(model_batchTexture, featureSt);\n    }\n    // Floating point comparisons can be unreliable in GLSL, so we\n    // increment the feature ID to make sure it's always greater\n    // then the model_featuresLength - a condition we check for in the\n    // pick ID, to avoid sampling the pick texture if the feature ID is\n    // greater than the number of features.\n    else\n    {\n        feature.id = model_featuresLength + 1;\n        feature.st = vec2(0.0);\n        feature.color = vec4(1.0);\n    }\n\n    #ifdef HAS_NULL_FEATURE_ID\n    if (featureId == model_nullFeatureId) {\n        feature.id = featureId;\n        feature.st = vec2(0.0);\n        feature.color = vec4(1.0);\n    }\n    #endif\n}\n"},72711:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void skinningStage(inout ProcessedAttributes attributes) \n{\n    mat4 skinningMatrix = getSkinningMatrix();\n    mat3 skinningMatrixMat3 = mat3(skinningMatrix);\n\n    vec4 positionMC = vec4(attributes.positionMC, 1.0);\n    attributes.positionMC = vec3(skinningMatrix * positionMC);\n\n    #ifdef HAS_NORMALS\n    vec3 normalMC = attributes.normalMC;\n    attributes.normalMC = skinningMatrixMat3 * normalMC;\n    #endif\n\n    #ifdef HAS_TANGENTS\n    vec3 tangentMC = attributes.tangentMC;\n    attributes.tangentMC = skinningMatrixMat3 * tangentMC;\n    #endif\n}"},22927:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec2 v_textureCoordinates;\n\nuniform float originalSize;\nuniform sampler2D texture0;\nuniform sampler2D texture1;\nuniform sampler2D texture2;\nuniform sampler2D texture3;\nuniform sampler2D texture4;\nuniform sampler2D texture5;\n\nconst float yMipLevel1 = 1.0 - (1.0 / pow(2.0, 1.0));\nconst float yMipLevel2 = 1.0 - (1.0 / pow(2.0, 2.0));\nconst float yMipLevel3 = 1.0 - (1.0 / pow(2.0, 3.0));\nconst float yMipLevel4 = 1.0 - (1.0 / pow(2.0, 4.0));\n\nvoid main()\n{\n    vec2 uv = v_textureCoordinates;\n    vec2 textureSize = vec2(originalSize * 1.5 + 2.0, originalSize);\n    vec2 pixel = 1.0 / textureSize;\n\n    float mipLevel = 0.0;\n\n    if (uv.x - pixel.x > (textureSize.y / textureSize.x))\n    {\n        mipLevel = 1.0;\n        if (uv.y - pixel.y > yMipLevel1)\n        {\n            mipLevel = 2.0;\n            if (uv.y - pixel.y * 3.0 > yMipLevel2)\n            {\n                mipLevel = 3.0;\n                if (uv.y - pixel.y * 5.0 > yMipLevel3)\n                {\n                    mipLevel = 4.0;\n                    if (uv.y - pixel.y * 7.0 > yMipLevel4)\n                    {\n                        mipLevel = 5.0;\n                    }\n                }\n            }\n        }\n    }\n\n    if (mipLevel > 0.0)\n    {\n        float scale = pow(2.0, mipLevel);\n\n        uv.y -= (pixel.y * (mipLevel - 1.0) * 2.0);\n        uv.x *= ((textureSize.x - 2.0) / textureSize.y);\n\n        uv.x -= 1.0 + pixel.x;\n        uv.y -= (1.0 - (1.0 / pow(2.0, mipLevel - 1.0)));\n        uv *= scale;\n    }\n    else\n    {\n        uv.x *= (textureSize.x / textureSize.y);\n    }\n\n    if(mipLevel == 0.0)\n    {\n        gl_FragColor = texture2D(texture0, uv);\n    }\n    else if(mipLevel == 1.0)\n    {\n        gl_FragColor = texture2D(texture1, uv);\n    }\n    else if(mipLevel == 2.0)\n    {\n        gl_FragColor = texture2D(texture2, uv);\n    }\n    else if(mipLevel == 3.0)\n    {\n        gl_FragColor = texture2D(texture3, uv);\n    }\n    else if(mipLevel == 4.0)\n    {\n        gl_FragColor = texture2D(texture4, uv);\n    }\n    else if(mipLevel == 5.0)\n    {\n        gl_FragColor = texture2D(texture5, uv);\n    }\n    else\n    {\n        gl_FragColor = vec4(0.0);\n    }\n}\n"},1973:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec3 v_cubeMapCoordinates;\nuniform samplerCube cubeMap;\n\nvoid main()\n{\n    vec4 rgba = textureCube(cubeMap, v_cubeMapCoordinates);\n    #ifdef RGBA_NORMALIZED\n        gl_FragColor = vec4(rgba.rgb, 1.0);\n    #else\n        float m = rgba.a * 16.0;\n        vec3 r = rgba.rgb * m;\n        gl_FragColor = vec4(r * r, 1.0);\n    #endif\n}\n"},42518:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec4 position;\nattribute vec3 cubeMapCoordinates;\n\nvarying vec3 v_cubeMapCoordinates;\n\nvoid main()\n{\n    gl_Position = position;\n    v_cubeMapCoordinates = cubeMapCoordinates;\n}\n"},53123:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec4 v_color;\nvarying vec4 v_outlineColor;\nvarying float v_innerPercent;\nvarying float v_pixelDistance;\nvarying vec4 v_pickColor;\n\nvoid main()\n{\n    // The distance in UV space from this fragment to the center of the point, at most 0.5.\n    float distanceToCenter = length(gl_PointCoord - vec2(0.5));\n    // The max distance stops one pixel shy of the edge to leave space for anti-aliasing.\n    float maxDistance = max(0.0, 0.5 - v_pixelDistance);\n    float wholeAlpha = 1.0 - smoothstep(maxDistance, 0.5, distanceToCenter);\n    float innerAlpha = 1.0 - smoothstep(maxDistance * v_innerPercent, 0.5 * v_innerPercent, distanceToCenter);\n\n    vec4 color = mix(v_outlineColor, v_color, innerAlpha);\n    color.a *= wholeAlpha;\n\n// Fully transparent parts of the billboard are not pickable.\n#if !defined(OPAQUE) && !defined(TRANSLUCENT)\n    if (color.a < 0.005)   // matches 0/255 and 1/255\n    {\n        discard;\n    }\n#else\n// The billboard is rendered twice. The opaque pass discards translucent fragments\n// and the translucent pass discards opaque fragments.\n#ifdef OPAQUE\n    if (color.a < 0.995)   // matches < 254/255\n    {\n        discard;\n    }\n#else\n    if (color.a >= 0.995)  // matches 254/255 and 255/255\n    {\n        discard;\n    }\n#endif\n#endif\n\n    gl_FragColor = czm_gammaCorrect(color);\n    czm_writeLogDepth();\n}\n"},67380:(e,n,t)=>{t.d(n,{Z:()=>o});const o='uniform float u_maxTotalPointSize;\n\nattribute vec4 positionHighAndSize;\nattribute vec4 positionLowAndOutline;\nattribute vec4 compressedAttribute0;                       // color, outlineColor, pick color\nattribute vec4 compressedAttribute1;                       // show, translucency by distance, some free space\nattribute vec4 scaleByDistance;                            // near, nearScale, far, farScale\nattribute vec3 distanceDisplayConditionAndDisableDepth;    // near, far, disableDepthTestDistance\n\nvarying vec4 v_color;\nvarying vec4 v_outlineColor;\nvarying float v_innerPercent;\nvarying float v_pixelDistance;\nvarying vec4 v_pickColor;\n\nconst float SHIFT_LEFT8 = 256.0;\nconst float SHIFT_RIGHT8 = 1.0 / 256.0;\n\nvoid main()\n{\n    // Modifying this shader may also require modifications to PointPrimitive._computeScreenSpacePosition\n\n    // unpack attributes\n    vec3 positionHigh = positionHighAndSize.xyz;\n    vec3 positionLow = positionLowAndOutline.xyz;\n    float outlineWidthBothSides = 2.0 * positionLowAndOutline.w;\n    float totalSize = positionHighAndSize.w + outlineWidthBothSides;\n    float outlinePercent = outlineWidthBothSides / totalSize;\n    // Scale in response to browser-zoom.\n    totalSize *= czm_pixelRatio;\n    // Add padding for anti-aliasing on both sides.\n    totalSize += 3.0;\n\n    float temp = compressedAttribute1.x * SHIFT_RIGHT8;\n    float show = floor(temp);\n\n#ifdef EYE_DISTANCE_TRANSLUCENCY\n    vec4 translucencyByDistance;\n    translucencyByDistance.x = compressedAttribute1.z;\n    translucencyByDistance.z = compressedAttribute1.w;\n\n    translucencyByDistance.y = ((temp - floor(temp)) * SHIFT_LEFT8) / 255.0;\n\n    temp = compressedAttribute1.y * SHIFT_RIGHT8;\n    translucencyByDistance.w = ((temp - floor(temp)) * SHIFT_LEFT8) / 255.0;\n#endif\n\n    ///////////////////////////////////////////////////////////////////////////\n\n    vec4 color;\n    vec4 outlineColor;\n    vec4 pickColor;\n\n    // compressedAttribute0.z => pickColor.rgb\n\n    temp = compressedAttribute0.z * SHIFT_RIGHT8;\n    pickColor.b = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    pickColor.g = (temp - floor(temp)) * SHIFT_LEFT8;\n    pickColor.r = floor(temp);\n\n    // compressedAttribute0.x => color.rgb\n\n    temp = compressedAttribute0.x * SHIFT_RIGHT8;\n    color.b = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    color.g = (temp - floor(temp)) * SHIFT_LEFT8;\n    color.r = floor(temp);\n\n    // compressedAttribute0.y => outlineColor.rgb\n\n    temp = compressedAttribute0.y * SHIFT_RIGHT8;\n    outlineColor.b = (temp - floor(temp)) * SHIFT_LEFT8;\n    temp = floor(temp) * SHIFT_RIGHT8;\n    outlineColor.g = (temp - floor(temp)) * SHIFT_LEFT8;\n    outlineColor.r = floor(temp);\n\n    // compressedAttribute0.w => color.a, outlineColor.a, pickColor.a\n\n    temp = compressedAttribute0.w * SHIFT_RIGHT8;\n    pickColor.a = (temp - floor(temp)) * SHIFT_LEFT8;\n    pickColor = pickColor / 255.0;\n\n    temp = floor(temp) * SHIFT_RIGHT8;\n    outlineColor.a = (temp - floor(temp)) * SHIFT_LEFT8;\n    outlineColor /= 255.0;\n    color.a = floor(temp);\n    color /= 255.0;\n\n    ///////////////////////////////////////////////////////////////////////////\n\n    vec4 p = czm_translateRelativeToEye(positionHigh, positionLow);\n    vec4 positionEC = czm_modelViewRelativeToEye * p;\n\n    ///////////////////////////////////////////////////////////////////////////\n\n#if defined(EYE_DISTANCE_SCALING) || defined(EYE_DISTANCE_TRANSLUCENCY) || defined(DISTANCE_DISPLAY_CONDITION) || defined(DISABLE_DEPTH_DISTANCE)\n    float lengthSq;\n    if (czm_sceneMode == czm_sceneMode2D)\n    {\n        // 2D camera distance is a special case\n        // treat all billboards as flattened to the z=0.0 plane\n        lengthSq = czm_eyeHeight2D.y;\n    }\n    else\n    {\n        lengthSq = dot(positionEC.xyz, positionEC.xyz);\n    }\n#endif\n\n#ifdef EYE_DISTANCE_SCALING\n    totalSize *= czm_nearFarScalar(scaleByDistance, lengthSq);\n#endif\n    // Clamp to max point size.\n    totalSize = min(totalSize, u_maxTotalPointSize);\n    // If size is too small, push vertex behind near plane for clipping.\n    // Note that context.minimumAliasedPointSize "will be at most 1.0".\n    if (totalSize < 1.0)\n    {\n        positionEC.xyz = vec3(0.0);\n        totalSize = 1.0;\n    }\n\n    float translucency = 1.0;\n#ifdef EYE_DISTANCE_TRANSLUCENCY\n    translucency = czm_nearFarScalar(translucencyByDistance, lengthSq);\n    // push vertex behind near plane for clipping\n    if (translucency < 0.004)\n    {\n        positionEC.xyz = vec3(0.0);\n    }\n#endif\n\n#ifdef DISTANCE_DISPLAY_CONDITION\n    float nearSq = distanceDisplayConditionAndDisableDepth.x;\n    float farSq = distanceDisplayConditionAndDisableDepth.y;\n    if (lengthSq < nearSq || lengthSq > farSq) {\n        // push vertex behind camera to force it to be clipped\n        positionEC.xyz = vec3(0.0, 0.0, 1.0);\n    }\n#endif\n\n    gl_Position = czm_projection * positionEC;\n    czm_vertexLogDepth();\n\n#ifdef DISABLE_DEPTH_DISTANCE\n    float disableDepthTestDistance = distanceDisplayConditionAndDisableDepth.z;\n    if (disableDepthTestDistance == 0.0 && czm_minimumDisableDepthTestDistance != 0.0)\n    {\n        disableDepthTestDistance = czm_minimumDisableDepthTestDistance;\n    }\n\n    if (disableDepthTestDistance != 0.0)\n    {\n        // Don\'t try to "multiply both sides" by w.  Greater/less-than comparisons won\'t work for negative values of w.\n        float zclip = gl_Position.z / gl_Position.w;\n        bool clipped = (zclip < -1.0 || zclip > 1.0);\n        if (!clipped && (disableDepthTestDistance < 0.0 || (lengthSq > 0.0 && lengthSq < disableDepthTestDistance)))\n        {\n            // Position z on the near plane.\n            gl_Position.z = -gl_Position.w;\n#ifdef LOG_DEPTH\n            czm_vertexLogDepth(vec4(czm_currentFrustum.x));\n#endif\n        }\n    }\n#endif\n\n    v_color = color;\n    v_color.a *= translucency * show;\n    v_outlineColor = outlineColor;\n    v_outlineColor.a *= translucency * show;\n\n    v_innerPercent = 1.0 - outlinePercent;\n    v_pixelDistance = 2.0 / totalSize;\n    gl_PointSize = totalSize * show;\n    gl_Position *= show;\n\n    v_pickColor = pickColor;\n}\n'},85975:(e,n,t)=>{t.d(n,{Z:()=>o});const o="void clipLineSegmentToNearPlane(\n    vec3 p0,\n    vec3 p1,\n    out vec4 positionWC,\n    out bool clipped,\n    out bool culledByNearPlane,\n    out vec4 clippedPositionEC)\n{\n    culledByNearPlane = false;\n    clipped = false;\n\n    vec3 p0ToP1 = p1 - p0;\n    float magnitude = length(p0ToP1);\n    vec3 direction = normalize(p0ToP1);\n\n    // Distance that p0 is behind the near plane. Negative means p0 is\n    // in front of the near plane.\n    float endPoint0Distance =  czm_currentFrustum.x + p0.z;\n\n    // Camera looks down -Z.\n    // When moving a point along +Z: LESS VISIBLE\n    //   * Points in front of the camera move closer to the camera.\n    //   * Points behind the camrea move farther away from the camera.\n    // When moving a point along -Z: MORE VISIBLE\n    //   * Points in front of the camera move farther away from the camera.\n    //   * Points behind the camera move closer to the camera.\n\n    // Positive denominator: -Z, becoming more visible\n    // Negative denominator: +Z, becoming less visible\n    // Nearly zero: parallel to near plane\n    float denominator = -direction.z;\n\n    if (endPoint0Distance > 0.0 && abs(denominator) < czm_epsilon7)\n    {\n        // p0 is behind the near plane and the line to p1 is nearly parallel to\n        // the near plane, so cull the segment completely.\n        culledByNearPlane = true;\n    }\n    else if (endPoint0Distance > 0.0)\n    {\n        // p0 is behind the near plane, and the line to p1 is moving distinctly\n        // toward or away from it.\n\n        // t = (-plane distance - dot(plane normal, ray origin)) / dot(plane normal, ray direction)\n        float t = endPoint0Distance / denominator;\n        if (t < 0.0 || t > magnitude)\n        {\n            // Near plane intersection is not between the two points.\n            // We already confirmed p0 is behind the naer plane, so now\n            // we know the entire segment is behind it.\n            culledByNearPlane = true;\n        }\n        else\n        {\n            // Segment crosses the near plane, update p0 to lie exactly on it.\n            p0 = p0 + t * direction;\n\n            // Numerical noise might put us a bit on the wrong side of the near plane.\n            // Don't let that happen.\n            p0.z = min(p0.z, -czm_currentFrustum.x);\n\n            clipped = true;\n        }\n    }\n\n    clippedPositionEC = vec4(p0, 1.0);\n    positionWC = czm_eyeToWindowCoordinates(clippedPositionEC);\n}\n\nvec4 getPolylineWindowCoordinatesEC(vec4 positionEC, vec4 prevEC, vec4 nextEC, float expandDirection, float width, bool usePrevious, out float angle)\n{\n    // expandDirection +1 is to the _left_ when looking from positionEC toward nextEC.\n\n#ifdef POLYLINE_DASH\n    // Compute the window coordinates of the points.\n    vec4 positionWindow = czm_eyeToWindowCoordinates(positionEC);\n    vec4 previousWindow = czm_eyeToWindowCoordinates(prevEC);\n    vec4 nextWindow = czm_eyeToWindowCoordinates(nextEC);\n\n    // Determine the relative screen space direction of the line.\n    vec2 lineDir;\n    if (usePrevious) {\n        lineDir = normalize(positionWindow.xy - previousWindow.xy);\n    }\n    else {\n        lineDir = normalize(nextWindow.xy - positionWindow.xy);\n    }\n    angle = atan(lineDir.x, lineDir.y) - 1.570796327; // precomputed atan(1,0)\n\n    // Quantize the angle so it doesn't change rapidly between segments.\n    angle = floor(angle / czm_piOverFour + 0.5) * czm_piOverFour;\n#endif\n\n    vec4 clippedPrevWC, clippedPrevEC;\n    bool prevSegmentClipped, prevSegmentCulled;\n    clipLineSegmentToNearPlane(prevEC.xyz, positionEC.xyz, clippedPrevWC, prevSegmentClipped, prevSegmentCulled, clippedPrevEC);\n\n    vec4 clippedNextWC, clippedNextEC;\n    bool nextSegmentClipped, nextSegmentCulled;\n    clipLineSegmentToNearPlane(nextEC.xyz, positionEC.xyz, clippedNextWC, nextSegmentClipped, nextSegmentCulled, clippedNextEC);\n\n    bool segmentClipped, segmentCulled;\n    vec4 clippedPositionWC, clippedPositionEC;\n    clipLineSegmentToNearPlane(positionEC.xyz, usePrevious ? prevEC.xyz : nextEC.xyz, clippedPositionWC, segmentClipped, segmentCulled, clippedPositionEC);\n\n    if (segmentCulled)\n    {\n        return vec4(0.0, 0.0, 0.0, 1.0);\n    }\n\n    vec2 directionToPrevWC = normalize(clippedPrevWC.xy - clippedPositionWC.xy);\n    vec2 directionToNextWC = normalize(clippedNextWC.xy - clippedPositionWC.xy);\n\n    // If a segment was culled, we can't use the corresponding direction\n    // computed above. We should never see both of these be true without\n    // `segmentCulled` above also being true.\n    if (prevSegmentCulled)\n    {\n        directionToPrevWC = -directionToNextWC;\n    }\n    else if (nextSegmentCulled)\n    {\n        directionToNextWC = -directionToPrevWC;\n    }\n\n    vec2 thisSegmentForwardWC, otherSegmentForwardWC;\n    if (usePrevious)\n    {\n        thisSegmentForwardWC = -directionToPrevWC;\n        otherSegmentForwardWC = directionToNextWC;\n    }\n    else\n    {\n        thisSegmentForwardWC = directionToNextWC;\n        otherSegmentForwardWC =  -directionToPrevWC;\n    }\n\n    vec2 thisSegmentLeftWC = vec2(-thisSegmentForwardWC.y, thisSegmentForwardWC.x);\n\n    vec2 leftWC = thisSegmentLeftWC;\n    float expandWidth = width * 0.5;\n\n    // When lines are split at the anti-meridian, the position may be at the\n    // same location as the next or previous position, and we need to handle\n    // that to avoid producing NaNs.\n    if (!czm_equalsEpsilon(prevEC.xyz - positionEC.xyz, vec3(0.0), czm_epsilon1) && !czm_equalsEpsilon(nextEC.xyz - positionEC.xyz, vec3(0.0), czm_epsilon1))\n    {\n        vec2 otherSegmentLeftWC = vec2(-otherSegmentForwardWC.y, otherSegmentForwardWC.x);\n\n        vec2 leftSumWC = thisSegmentLeftWC + otherSegmentLeftWC;\n        float leftSumLength = length(leftSumWC);\n        leftWC = leftSumLength < czm_epsilon6 ? thisSegmentLeftWC : (leftSumWC / leftSumLength);\n\n        // The sine of the angle between the two vectors is given by the formula\n        //         |a x b| = |a||b|sin(theta)\n        // which is\n        //     float sinAngle = length(cross(vec3(leftWC, 0.0), vec3(-thisSegmentForwardWC, 0.0)));\n        // Because the z components of both vectors are zero, the x and y coordinate will be zero.\n        // Therefore, the sine of the angle is just the z component of the cross product.\n        vec2 u = -thisSegmentForwardWC;\n        vec2 v = leftWC;\n        float sinAngle = abs(u.x * v.y - u.y * v.x);\n        expandWidth = clamp(expandWidth / sinAngle, 0.0, width * 2.0);\n    }\n\n    vec2 offset = leftWC * expandDirection * expandWidth * czm_pixelRatio;\n    return vec4(clippedPositionWC.xy + offset, -clippedPositionWC.z, 1.0) * (czm_projection * clippedPositionEC).w;\n}\n\nvec4 getPolylineWindowCoordinates(vec4 position, vec4 previous, vec4 next, float expandDirection, float width, bool usePrevious, out float angle)\n{\n    vec4 positionEC = czm_modelViewRelativeToEye * position;\n    vec4 prevEC = czm_modelViewRelativeToEye * previous;\n    vec4 nextEC = czm_modelViewRelativeToEye * next;\n    return getPolylineWindowCoordinatesEC(positionEC, prevEC, nextEC, expandDirection, width, usePrevious, angle);\n}\n"},53183:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef VECTOR_TILE\nuniform vec4 u_highlightColor;\n#endif\n\nvarying vec2 v_st;\n\nvoid main()\n{\n    czm_materialInput materialInput;\n\n    vec2 st = v_st;\n    st.t = czm_readNonPerspective(st.t, gl_FragCoord.w);\n\n    materialInput.s = st.s;\n    materialInput.st = st;\n    materialInput.str = vec3(st, 0.0);\n\n    czm_material material = czm_getMaterial(materialInput);\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n#ifdef VECTOR_TILE\n    gl_FragColor *= u_highlightColor;\n#endif\n\n    czm_writeLogDepth();\n}\n"},28927:(e,n,t)=>{t.d(n,{Z:()=>o});const o='#ifdef GL_EXT_frag_depth\n#extension GL_EXT_frag_depth : enable\n#endif\n\nvarying vec4 v_startPlaneNormalEcAndHalfWidth;\nvarying vec4 v_endPlaneNormalEcAndBatchId;\nvarying vec4 v_rightPlaneEC; // Technically can compute distance for this here\nvarying vec4 v_endEcAndStartEcX;\nvarying vec4 v_texcoordNormalizationAndStartEcYZ;\n\n#ifdef PER_INSTANCE_COLOR\nvarying vec4 v_color;\n#endif\n\nvoid main(void)\n{\n    float logDepthOrDepth = czm_branchFreeTernary(czm_sceneMode == czm_sceneMode2D, gl_FragCoord.z, czm_unpackDepth(texture2D(czm_globeDepthTexture, gl_FragCoord.xy / czm_viewport.zw)));\n    vec3 ecStart = vec3(v_endEcAndStartEcX.w, v_texcoordNormalizationAndStartEcYZ.zw);\n\n    // Discard for sky\n    if (logDepthOrDepth == 0.0) {\n#ifdef DEBUG_SHOW_VOLUME\n        gl_FragColor = vec4(1.0, 0.0, 0.0, 0.5);\n        return;\n#else // DEBUG_SHOW_VOLUME\n        discard;\n#endif // DEBUG_SHOW_VOLUME\n    }\n\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(gl_FragCoord.xy, logDepthOrDepth);\n    eyeCoordinate /= eyeCoordinate.w;\n\n    float halfMaxWidth = v_startPlaneNormalEcAndHalfWidth.w * czm_metersPerPixel(eyeCoordinate);\n    // Check distance of the eye coordinate against the right-facing plane\n    float widthwiseDistance = czm_planeDistance(v_rightPlaneEC, eyeCoordinate.xyz);\n\n    // Check eye coordinate against the mitering planes\n    float distanceFromStart = czm_planeDistance(v_startPlaneNormalEcAndHalfWidth.xyz, -dot(ecStart, v_startPlaneNormalEcAndHalfWidth.xyz), eyeCoordinate.xyz);\n    float distanceFromEnd = czm_planeDistance(v_endPlaneNormalEcAndBatchId.xyz, -dot(v_endEcAndStartEcX.xyz, v_endPlaneNormalEcAndBatchId.xyz), eyeCoordinate.xyz);\n\n    if (abs(widthwiseDistance) > halfMaxWidth || distanceFromStart < 0.0 || distanceFromEnd < 0.0) {\n#ifdef DEBUG_SHOW_VOLUME\n        gl_FragColor = vec4(1.0, 0.0, 0.0, 0.5);\n        return;\n#else // DEBUG_SHOW_VOLUME\n        discard;\n#endif // DEBUG_SHOW_VOLUME\n    }\n\n    // Check distance of the eye coordinate against start and end planes with normals in the right plane.\n    // For computing unskewed lengthwise texture coordinate.\n    // Can also be used for clipping extremely pointy miters, but in practice unnecessary because of miter breaking.\n\n    // aligned plane: cross the right plane normal with miter plane normal, then cross the result with right again to point it more "forward"\n    vec3 alignedPlaneNormal;\n\n    // start aligned plane\n    alignedPlaneNormal = cross(v_rightPlaneEC.xyz, v_startPlaneNormalEcAndHalfWidth.xyz);\n    alignedPlaneNormal = normalize(cross(alignedPlaneNormal, v_rightPlaneEC.xyz));\n    distanceFromStart = czm_planeDistance(alignedPlaneNormal, -dot(alignedPlaneNormal, ecStart), eyeCoordinate.xyz);\n\n    // end aligned plane\n    alignedPlaneNormal = cross(v_rightPlaneEC.xyz, v_endPlaneNormalEcAndBatchId.xyz);\n    alignedPlaneNormal = normalize(cross(alignedPlaneNormal, v_rightPlaneEC.xyz));\n    distanceFromEnd = czm_planeDistance(alignedPlaneNormal, -dot(alignedPlaneNormal, v_endEcAndStartEcX.xyz), eyeCoordinate.xyz);\n\n#ifdef PER_INSTANCE_COLOR\n    gl_FragColor = czm_gammaCorrect(v_color);\n#else // PER_INSTANCE_COLOR\n    // Clamp - distance to aligned planes may be negative due to mitering,\n    // so fragment texture coordinate might be out-of-bounds.\n    float s = clamp(distanceFromStart / (distanceFromStart + distanceFromEnd), 0.0, 1.0);\n    s = (s * v_texcoordNormalizationAndStartEcYZ.x) + v_texcoordNormalizationAndStartEcYZ.y;\n    float t = (widthwiseDistance + halfMaxWidth) / (2.0 * halfMaxWidth);\n\n    czm_materialInput materialInput;\n\n    materialInput.s = s;\n    materialInput.st = vec2(s, t);\n    materialInput.str = vec3(s, t, 0.0);\n\n    czm_material material = czm_getMaterial(materialInput);\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n#endif // PER_INSTANCE_COLOR\n\n    // Premultiply alpha. Required for classification primitives on translucent globe.\n    gl_FragColor.rgb *= gl_FragColor.a;\n\n    czm_writeDepthClamp();\n}\n'},21359:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec3 v_forwardDirectionEC;\nvarying vec3 v_texcoordNormalizationAndHalfWidth;\nvarying float v_batchId;\n\n#ifdef PER_INSTANCE_COLOR\nvarying vec4 v_color;\n#else\nvarying vec2 v_alignedPlaneDistances;\nvarying float v_texcoordT;\n#endif\n\nfloat rayPlaneDistanceUnsafe(vec3 origin, vec3 direction, vec3 planeNormal, float planeDistance) {\n    // We don't expect the ray to ever be parallel to the plane\n    return (-planeDistance - dot(planeNormal, origin)) / dot(planeNormal, direction);\n}\n\nvoid main(void)\n{\n    vec4 eyeCoordinate = gl_FragCoord;\n    eyeCoordinate /= eyeCoordinate.w;\n\n#ifdef PER_INSTANCE_COLOR\n    gl_FragColor = czm_gammaCorrect(v_color);\n#else // PER_INSTANCE_COLOR\n    // Use distances for planes aligned with segment to prevent skew in dashing\n    float distanceFromStart = rayPlaneDistanceUnsafe(eyeCoordinate.xyz, -v_forwardDirectionEC, v_forwardDirectionEC.xyz, v_alignedPlaneDistances.x);\n    float distanceFromEnd = rayPlaneDistanceUnsafe(eyeCoordinate.xyz, v_forwardDirectionEC, -v_forwardDirectionEC.xyz, v_alignedPlaneDistances.y);\n\n    // Clamp - distance to aligned planes may be negative due to mitering\n    distanceFromStart = max(0.0, distanceFromStart);\n    distanceFromEnd = max(0.0, distanceFromEnd);\n\n    float s = distanceFromStart / (distanceFromStart + distanceFromEnd);\n    s = (s * v_texcoordNormalizationAndHalfWidth.x) + v_texcoordNormalizationAndHalfWidth.y;\n\n    czm_materialInput materialInput;\n\n    materialInput.s = s;\n    materialInput.st = vec2(s, v_texcoordT);\n    materialInput.str = vec3(s, v_texcoordT, 0.0);\n\n    czm_material material = czm_getMaterial(materialInput);\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n#endif // PER_INSTANCE_COLOR\n}\n"},43271:(e,n,t)=>{t.d(n,{Z:()=>o});const o='attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\n\nattribute vec4 startHiAndForwardOffsetX;\nattribute vec4 startLoAndForwardOffsetY;\nattribute vec4 startNormalAndForwardOffsetZ;\nattribute vec4 endNormalAndTextureCoordinateNormalizationX;\nattribute vec4 rightNormalAndTextureCoordinateNormalizationY;\nattribute vec4 startHiLo2D;\nattribute vec4 offsetAndRight2D;\nattribute vec4 startEndNormals2D;\nattribute vec2 texcoordNormalization2D;\n\nattribute float batchId;\n\nvarying vec3 v_forwardDirectionEC;\nvarying vec3 v_texcoordNormalizationAndHalfWidth;\nvarying float v_batchId;\n\n// For materials\n#ifdef WIDTH_VARYING\nvarying float v_width;\n#endif\n#ifdef ANGLE_VARYING\nvarying float v_polylineAngle;\n#endif\n\n#ifdef PER_INSTANCE_COLOR\nvarying vec4 v_color;\n#else\nvarying vec2 v_alignedPlaneDistances;\nvarying float v_texcoordT;\n#endif\n\n// Morphing planes using SLERP or NLERP doesn\'t seem to work, so instead draw the material directly on the shadow volume.\n// Morph views are from very far away and aren\'t meant to be used precisely, so this should be sufficient.\nvoid main()\n{\n    v_batchId = batchId;\n\n    // Start position\n    vec4 posRelativeToEye2D = czm_translateRelativeToEye(vec3(0.0, startHiLo2D.xy), vec3(0.0, startHiLo2D.zw));\n    vec4 posRelativeToEye3D = czm_translateRelativeToEye(startHiAndForwardOffsetX.xyz, startLoAndForwardOffsetY.xyz);\n    vec4 posRelativeToEye = czm_columbusViewMorph(posRelativeToEye2D, posRelativeToEye3D, czm_morphTime);\n    vec3 posEc2D = (czm_modelViewRelativeToEye * posRelativeToEye2D).xyz;\n    vec3 posEc3D = (czm_modelViewRelativeToEye * posRelativeToEye3D).xyz;\n    vec3 startEC = (czm_modelViewRelativeToEye * posRelativeToEye).xyz;\n\n    // Start plane\n    vec4 startPlane2D;\n    vec4 startPlane3D;\n    startPlane2D.xyz = czm_normal * vec3(0.0, startEndNormals2D.xy);\n    startPlane3D.xyz = czm_normal * startNormalAndForwardOffsetZ.xyz;\n    startPlane2D.w = -dot(startPlane2D.xyz, posEc2D);\n    startPlane3D.w = -dot(startPlane3D.xyz, posEc3D);\n\n    // Right plane\n    vec4 rightPlane2D;\n    vec4 rightPlane3D;\n    rightPlane2D.xyz = czm_normal * vec3(0.0, offsetAndRight2D.zw);\n    rightPlane3D.xyz = czm_normal * rightNormalAndTextureCoordinateNormalizationY.xyz;\n    rightPlane2D.w = -dot(rightPlane2D.xyz, posEc2D);\n    rightPlane3D.w = -dot(rightPlane3D.xyz, posEc3D);\n\n    // End position\n    posRelativeToEye2D = posRelativeToEye2D + vec4(0.0, offsetAndRight2D.xy, 0.0);\n    posRelativeToEye3D = posRelativeToEye3D + vec4(startHiAndForwardOffsetX.w, startLoAndForwardOffsetY.w, startNormalAndForwardOffsetZ.w, 0.0);\n    posRelativeToEye = czm_columbusViewMorph(posRelativeToEye2D, posRelativeToEye3D, czm_morphTime);\n    posEc2D = (czm_modelViewRelativeToEye * posRelativeToEye2D).xyz;\n    posEc3D = (czm_modelViewRelativeToEye * posRelativeToEye3D).xyz;\n    vec3 endEC = (czm_modelViewRelativeToEye * posRelativeToEye).xyz;\n    vec3 forwardEc3D = czm_normal * normalize(vec3(startHiAndForwardOffsetX.w, startLoAndForwardOffsetY.w, startNormalAndForwardOffsetZ.w));\n    vec3 forwardEc2D = czm_normal * normalize(vec3(0.0, offsetAndRight2D.xy));\n\n    // End plane\n    vec4 endPlane2D;\n    vec4 endPlane3D;\n    endPlane2D.xyz = czm_normal * vec3(0.0, startEndNormals2D.zw);\n    endPlane3D.xyz = czm_normal * endNormalAndTextureCoordinateNormalizationX.xyz;\n    endPlane2D.w = -dot(endPlane2D.xyz, posEc2D);\n    endPlane3D.w = -dot(endPlane3D.xyz, posEc3D);\n\n    // Forward direction\n    v_forwardDirectionEC = normalize(endEC - startEC);\n\n    vec2 cleanTexcoordNormalization2D;\n    cleanTexcoordNormalization2D.x = abs(texcoordNormalization2D.x);\n    cleanTexcoordNormalization2D.y = czm_branchFreeTernary(texcoordNormalization2D.y > 1.0, 0.0, abs(texcoordNormalization2D.y));\n    vec2 cleanTexcoordNormalization3D;\n    cleanTexcoordNormalization3D.x = abs(endNormalAndTextureCoordinateNormalizationX.w);\n    cleanTexcoordNormalization3D.y = rightNormalAndTextureCoordinateNormalizationY.w;\n    cleanTexcoordNormalization3D.y = czm_branchFreeTernary(cleanTexcoordNormalization3D.y > 1.0, 0.0, abs(cleanTexcoordNormalization3D.y));\n\n    v_texcoordNormalizationAndHalfWidth.xy = mix(cleanTexcoordNormalization2D, cleanTexcoordNormalization3D, czm_morphTime);\n\n#ifdef PER_INSTANCE_COLOR\n    v_color = czm_batchTable_color(batchId);\n#else // PER_INSTANCE_COLOR\n    // For computing texture coordinates\n\n    v_alignedPlaneDistances.x = -dot(v_forwardDirectionEC, startEC);\n    v_alignedPlaneDistances.y = -dot(-v_forwardDirectionEC, endEC);\n#endif // PER_INSTANCE_COLOR\n\n#ifdef WIDTH_VARYING\n    float width = czm_batchTable_width(batchId);\n    float halfWidth = width * 0.5;\n    v_width = width;\n    v_texcoordNormalizationAndHalfWidth.z = halfWidth;\n#else\n    float halfWidth = 0.5 * czm_batchTable_width(batchId);\n    v_texcoordNormalizationAndHalfWidth.z = halfWidth;\n#endif\n\n    // Compute a normal along which to "push" the position out, extending the miter depending on view distance.\n    // Position has already been "pushed" by unit length along miter normal, and miter normals are encoded in the planes.\n    // Decode the normal to use at this specific vertex, push the position back, and then push to where it needs to be.\n    // Since this is morphing, compute both 3D and 2D positions and then blend.\n\n    // ****** 3D ******\n    // Check distance to the end plane and start plane, pick the plane that is closer\n    vec4 positionEc3D = czm_modelViewRelativeToEye * czm_translateRelativeToEye(position3DHigh, position3DLow); // w = 1.0, see czm_computePosition\n    float absStartPlaneDistance = abs(czm_planeDistance(startPlane3D, positionEc3D.xyz));\n    float absEndPlaneDistance = abs(czm_planeDistance(endPlane3D, positionEc3D.xyz));\n    vec3 planeDirection = czm_branchFreeTernary(absStartPlaneDistance < absEndPlaneDistance, startPlane3D.xyz, endPlane3D.xyz);\n    vec3 upOrDown = normalize(cross(rightPlane3D.xyz, planeDirection)); // Points "up" for start plane, "down" at end plane.\n    vec3 normalEC = normalize(cross(planeDirection, upOrDown));         // In practice, the opposite seems to work too.\n\n    // Nudge the top vertex upwards to prevent flickering\n    vec3 geodeticSurfaceNormal = normalize(cross(normalEC, forwardEc3D));\n    geodeticSurfaceNormal *= float(0.0 <= rightNormalAndTextureCoordinateNormalizationY.w && rightNormalAndTextureCoordinateNormalizationY.w <= 1.0);\n    geodeticSurfaceNormal *= MAX_TERRAIN_HEIGHT;\n    positionEc3D.xyz += geodeticSurfaceNormal;\n\n    // Determine if this vertex is on the "left" or "right"\n    normalEC *= sign(endNormalAndTextureCoordinateNormalizationX.w);\n\n    // A "perfect" implementation would push along normals according to the angle against forward.\n    // In practice, just pushing the normal out by halfWidth is sufficient for morph views.\n    positionEc3D.xyz += halfWidth * max(0.0, czm_metersPerPixel(positionEc3D)) * normalEC; // prevent artifacts when czm_metersPerPixel is negative (behind camera)\n\n    // ****** 2D ******\n    // Check distance to the end plane and start plane, pick the plane that is closer\n    vec4 positionEc2D = czm_modelViewRelativeToEye * czm_translateRelativeToEye(position2DHigh.zxy, position2DLow.zxy); // w = 1.0, see czm_computePosition\n    absStartPlaneDistance = abs(czm_planeDistance(startPlane2D, positionEc2D.xyz));\n    absEndPlaneDistance = abs(czm_planeDistance(endPlane2D, positionEc2D.xyz));\n    planeDirection = czm_branchFreeTernary(absStartPlaneDistance < absEndPlaneDistance, startPlane2D.xyz, endPlane2D.xyz);\n    upOrDown = normalize(cross(rightPlane2D.xyz, planeDirection)); // Points "up" for start plane, "down" at end plane.\n    normalEC = normalize(cross(planeDirection, upOrDown));         // In practice, the opposite seems to work too.\n\n    // Nudge the top vertex upwards to prevent flickering\n    geodeticSurfaceNormal = normalize(cross(normalEC, forwardEc2D));\n    geodeticSurfaceNormal *= float(0.0 <= texcoordNormalization2D.y && texcoordNormalization2D.y <= 1.0);\n    geodeticSurfaceNormal *= MAX_TERRAIN_HEIGHT;\n    positionEc2D.xyz += geodeticSurfaceNormal;\n\n    // Determine if this vertex is on the "left" or "right"\n    normalEC *= sign(texcoordNormalization2D.x);\n#ifndef PER_INSTANCE_COLOR\n    // Use vertex\'s sidedness to compute its texture coordinate.\n    v_texcoordT = clamp(sign(texcoordNormalization2D.x), 0.0, 1.0);\n#endif\n\n    // A "perfect" implementation would push along normals according to the angle against forward.\n    // In practice, just pushing the normal out by halfWidth is sufficient for morph views.\n    positionEc2D.xyz += halfWidth * max(0.0, czm_metersPerPixel(positionEc2D)) * normalEC; // prevent artifacts when czm_metersPerPixel is negative (behind camera)\n\n    // Blend for actual position\n    gl_Position = czm_projection * mix(positionEc2D, positionEc3D, czm_morphTime);\n\n#ifdef ANGLE_VARYING\n    // Approximate relative screen space direction of the line.\n    vec2 approxLineDirection = normalize(vec2(v_forwardDirectionEC.x, -v_forwardDirectionEC.y));\n    approxLineDirection.y = czm_branchFreeTernary(approxLineDirection.x == 0.0 && approxLineDirection.y == 0.0, -1.0, approxLineDirection.y);\n    v_polylineAngle = czm_fastApproximateAtan(approxLineDirection.x, approxLineDirection.y);\n#endif\n}\n'},29843:(e,n,t)=>{t.d(n,{Z:()=>o});const o='attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\n\n// In 2D and in 3D, texture coordinate normalization component signs encodes:\n// * X sign - sidedness relative to right plane\n// * Y sign - is negative OR magnitude is greater than 1.0 if vertex is on bottom of volume\n#ifndef COLUMBUS_VIEW_2D\nattribute vec4 startHiAndForwardOffsetX;\nattribute vec4 startLoAndForwardOffsetY;\nattribute vec4 startNormalAndForwardOffsetZ;\nattribute vec4 endNormalAndTextureCoordinateNormalizationX;\nattribute vec4 rightNormalAndTextureCoordinateNormalizationY;\n#else\nattribute vec4 startHiLo2D;\nattribute vec4 offsetAndRight2D;\nattribute vec4 startEndNormals2D;\nattribute vec2 texcoordNormalization2D;\n#endif\n\nattribute float batchId;\n\nvarying vec4 v_startPlaneNormalEcAndHalfWidth;\nvarying vec4 v_endPlaneNormalEcAndBatchId;\nvarying vec4 v_rightPlaneEC;\nvarying vec4 v_endEcAndStartEcX;\nvarying vec4 v_texcoordNormalizationAndStartEcYZ;\n\n// For materials\n#ifdef WIDTH_VARYING\nvarying float v_width;\n#endif\n#ifdef ANGLE_VARYING\nvarying float v_polylineAngle;\n#endif\n\n#ifdef PER_INSTANCE_COLOR\nvarying vec4 v_color;\n#endif\n\nvoid main()\n{\n#ifdef COLUMBUS_VIEW_2D\n    vec3 ecStart = (czm_modelViewRelativeToEye * czm_translateRelativeToEye(vec3(0.0, startHiLo2D.xy), vec3(0.0, startHiLo2D.zw))).xyz;\n\n    vec3 forwardDirectionEC = czm_normal * vec3(0.0, offsetAndRight2D.xy);\n    vec3 ecEnd = forwardDirectionEC + ecStart;\n    forwardDirectionEC = normalize(forwardDirectionEC);\n\n    // Right plane\n    v_rightPlaneEC.xyz = czm_normal * vec3(0.0, offsetAndRight2D.zw);\n    v_rightPlaneEC.w = -dot(v_rightPlaneEC.xyz, ecStart);\n\n    // start plane\n    vec4 startPlaneEC;\n    startPlaneEC.xyz =  czm_normal * vec3(0.0, startEndNormals2D.xy);\n    startPlaneEC.w = -dot(startPlaneEC.xyz, ecStart);\n\n    // end plane\n    vec4 endPlaneEC;\n    endPlaneEC.xyz =  czm_normal * vec3(0.0, startEndNormals2D.zw);\n    endPlaneEC.w = -dot(endPlaneEC.xyz, ecEnd);\n\n    v_texcoordNormalizationAndStartEcYZ.x = abs(texcoordNormalization2D.x);\n    v_texcoordNormalizationAndStartEcYZ.y = texcoordNormalization2D.y;\n\n#else // COLUMBUS_VIEW_2D\n    vec3 ecStart = (czm_modelViewRelativeToEye * czm_translateRelativeToEye(startHiAndForwardOffsetX.xyz, startLoAndForwardOffsetY.xyz)).xyz;\n    vec3 offset = czm_normal * vec3(startHiAndForwardOffsetX.w, startLoAndForwardOffsetY.w, startNormalAndForwardOffsetZ.w);\n    vec3 ecEnd = ecStart + offset;\n\n    vec3 forwardDirectionEC = normalize(offset);\n\n    // start plane\n    vec4 startPlaneEC;\n    startPlaneEC.xyz = czm_normal * startNormalAndForwardOffsetZ.xyz;\n    startPlaneEC.w = -dot(startPlaneEC.xyz, ecStart);\n\n    // end plane\n    vec4 endPlaneEC;\n    endPlaneEC.xyz = czm_normal * endNormalAndTextureCoordinateNormalizationX.xyz;\n    endPlaneEC.w = -dot(endPlaneEC.xyz, ecEnd);\n\n    // Right plane\n    v_rightPlaneEC.xyz = czm_normal * rightNormalAndTextureCoordinateNormalizationY.xyz;\n    v_rightPlaneEC.w = -dot(v_rightPlaneEC.xyz, ecStart);\n\n    v_texcoordNormalizationAndStartEcYZ.x = abs(endNormalAndTextureCoordinateNormalizationX.w);\n    v_texcoordNormalizationAndStartEcYZ.y = rightNormalAndTextureCoordinateNormalizationY.w;\n\n#endif // COLUMBUS_VIEW_2D\n\n    v_endEcAndStartEcX.xyz = ecEnd;\n    v_endEcAndStartEcX.w = ecStart.x;\n    v_texcoordNormalizationAndStartEcYZ.zw = ecStart.yz;\n\n#ifdef PER_INSTANCE_COLOR\n    v_color = czm_batchTable_color(batchId);\n#endif // PER_INSTANCE_COLOR\n\n    // Compute a normal along which to "push" the position out, extending the miter depending on view distance.\n    // Position has already been "pushed" by unit length along miter normal, and miter normals are encoded in the planes.\n    // Decode the normal to use at this specific vertex, push the position back, and then push to where it needs to be.\n    vec4 positionRelativeToEye = czm_computePosition();\n\n    // Check distance to the end plane and start plane, pick the plane that is closer\n    vec4 positionEC = czm_modelViewRelativeToEye * positionRelativeToEye; // w = 1.0, see czm_computePosition\n    float absStartPlaneDistance = abs(czm_planeDistance(startPlaneEC, positionEC.xyz));\n    float absEndPlaneDistance = abs(czm_planeDistance(endPlaneEC, positionEC.xyz));\n    vec3 planeDirection = czm_branchFreeTernary(absStartPlaneDistance < absEndPlaneDistance, startPlaneEC.xyz, endPlaneEC.xyz);\n    vec3 upOrDown = normalize(cross(v_rightPlaneEC.xyz, planeDirection)); // Points "up" for start plane, "down" at end plane.\n    vec3 normalEC = normalize(cross(planeDirection, upOrDown));           // In practice, the opposite seems to work too.\n\n    // Extrude bottom vertices downward for far view distances, like for GroundPrimitives\n    upOrDown = cross(forwardDirectionEC, normalEC);\n    upOrDown = float(czm_sceneMode == czm_sceneMode3D) * upOrDown;\n    upOrDown = float(v_texcoordNormalizationAndStartEcYZ.y > 1.0 || v_texcoordNormalizationAndStartEcYZ.y < 0.0) * upOrDown;\n    upOrDown = min(GLOBE_MINIMUM_ALTITUDE, czm_geometricToleranceOverMeter * length(positionRelativeToEye.xyz)) * upOrDown;\n    positionEC.xyz += upOrDown;\n\n    v_texcoordNormalizationAndStartEcYZ.y = czm_branchFreeTernary(v_texcoordNormalizationAndStartEcYZ.y > 1.0, 0.0, abs(v_texcoordNormalizationAndStartEcYZ.y));\n\n    // Determine distance along normalEC to push for a volume of appropriate width.\n    // Make volumes about double pixel width for a conservative fit - in practice the\n    // extra cost here is minimal compared to the loose volume heights.\n    //\n    // N = normalEC (guaranteed "right-facing")\n    // R = rightEC\n    // p = angle between N and R\n    // w = distance to push along R if R == N\n    // d = distance to push along N\n    //\n    //   N   R\n    //  {  p| }      * cos(p) = dot(N, R) = w / d\n    //  d  |  |w    * d = w / dot(N, R)\n    //    { | }\n    //       o---------- polyline segment ----\x3e\n    //\n    float width = czm_batchTable_width(batchId);\n#ifdef WIDTH_VARYING\n    v_width = width;\n#endif\n\n    v_startPlaneNormalEcAndHalfWidth.xyz = startPlaneEC.xyz;\n    v_startPlaneNormalEcAndHalfWidth.w = width * 0.5;\n\n    v_endPlaneNormalEcAndBatchId.xyz = endPlaneEC.xyz;\n    v_endPlaneNormalEcAndBatchId.w = batchId;\n\n    width = width * max(0.0, czm_metersPerPixel(positionEC)); // width = distance to push along R\n    width = width / dot(normalEC, v_rightPlaneEC.xyz); // width = distance to push along N\n\n    // Determine if this vertex is on the "left" or "right"\n#ifdef COLUMBUS_VIEW_2D\n        normalEC *= sign(texcoordNormalization2D.x);\n#else\n        normalEC *= sign(endNormalAndTextureCoordinateNormalizationX.w);\n#endif\n\n    positionEC.xyz += width * normalEC;\n    gl_Position = czm_depthClamp(czm_projection * positionEC);\n\n#ifdef ANGLE_VARYING\n    // Approximate relative screen space direction of the line.\n    vec2 approxLineDirection = normalize(vec2(forwardDirectionEC.x, -forwardDirectionEC.y));\n    approxLineDirection.y = czm_branchFreeTernary(approxLineDirection.x == 0.0 && approxLineDirection.y == 0.0, -1.0, approxLineDirection.y);\n    v_polylineAngle = czm_fastApproximateAtan(approxLineDirection.x, approxLineDirection.y);\n#endif\n}\n'},90564:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute vec3 position2DHigh;\nattribute vec3 position2DLow;\nattribute vec3 prevPosition3DHigh;\nattribute vec3 prevPosition3DLow;\nattribute vec3 prevPosition2DHigh;\nattribute vec3 prevPosition2DLow;\nattribute vec3 nextPosition3DHigh;\nattribute vec3 nextPosition3DLow;\nattribute vec3 nextPosition2DHigh;\nattribute vec3 nextPosition2DLow;\nattribute vec4 texCoordExpandAndBatchIndex;\n\nvarying vec2  v_st;\nvarying float v_width;\nvarying vec4 v_pickColor;\nvarying float v_polylineAngle;\n\nvoid main()\n{\n    float texCoord = texCoordExpandAndBatchIndex.x;\n    float expandDir = texCoordExpandAndBatchIndex.y;\n    bool usePrev = texCoordExpandAndBatchIndex.z < 0.0;\n    float batchTableIndex = texCoordExpandAndBatchIndex.w;\n\n    vec2 widthAndShow = batchTable_getWidthAndShow(batchTableIndex);\n    float width = widthAndShow.x + 0.5;\n    float show = widthAndShow.y;\n\n    if (width < 1.0)\n    {\n        show = 0.0;\n    }\n\n    vec4 pickColor = batchTable_getPickColor(batchTableIndex);\n\n    vec4 p, prev, next;\n    if (czm_morphTime == 1.0)\n    {\n        p = czm_translateRelativeToEye(position3DHigh.xyz, position3DLow.xyz);\n        prev = czm_translateRelativeToEye(prevPosition3DHigh.xyz, prevPosition3DLow.xyz);\n        next = czm_translateRelativeToEye(nextPosition3DHigh.xyz, nextPosition3DLow.xyz);\n    }\n    else if (czm_morphTime == 0.0)\n    {\n        p = czm_translateRelativeToEye(position2DHigh.zxy, position2DLow.zxy);\n        prev = czm_translateRelativeToEye(prevPosition2DHigh.zxy, prevPosition2DLow.zxy);\n        next = czm_translateRelativeToEye(nextPosition2DHigh.zxy, nextPosition2DLow.zxy);\n    }\n    else\n    {\n        p = czm_columbusViewMorph(\n                czm_translateRelativeToEye(position2DHigh.zxy, position2DLow.zxy),\n                czm_translateRelativeToEye(position3DHigh.xyz, position3DLow.xyz),\n                czm_morphTime);\n        prev = czm_columbusViewMorph(\n                czm_translateRelativeToEye(prevPosition2DHigh.zxy, prevPosition2DLow.zxy),\n                czm_translateRelativeToEye(prevPosition3DHigh.xyz, prevPosition3DLow.xyz),\n                czm_morphTime);\n        next = czm_columbusViewMorph(\n                czm_translateRelativeToEye(nextPosition2DHigh.zxy, nextPosition2DLow.zxy),\n                czm_translateRelativeToEye(nextPosition3DHigh.xyz, nextPosition3DLow.xyz),\n                czm_morphTime);\n    }\n\n    #ifdef DISTANCE_DISPLAY_CONDITION\n        vec3 centerHigh = batchTable_getCenterHigh(batchTableIndex);\n        vec4 centerLowAndRadius = batchTable_getCenterLowAndRadius(batchTableIndex);\n        vec3 centerLow = centerLowAndRadius.xyz;\n        float radius = centerLowAndRadius.w;\n        vec2 distanceDisplayCondition = batchTable_getDistanceDisplayCondition(batchTableIndex);\n\n        float lengthSq;\n        if (czm_sceneMode == czm_sceneMode2D)\n        {\n            lengthSq = czm_eyeHeight2D.y;\n        }\n        else\n        {\n            vec4 center = czm_translateRelativeToEye(centerHigh.xyz, centerLow.xyz);\n            lengthSq = max(0.0, dot(center.xyz, center.xyz) - radius * radius);\n        }\n\n        float nearSq = distanceDisplayCondition.x * distanceDisplayCondition.x;\n        float farSq = distanceDisplayCondition.y * distanceDisplayCondition.y;\n        if (lengthSq < nearSq || lengthSq > farSq)\n        {\n            show = 0.0;\n        }\n    #endif\n\n    float polylineAngle;\n    vec4 positionWC = getPolylineWindowCoordinates(p, prev, next, expandDir, width, usePrev, polylineAngle);\n    gl_Position = czm_viewportOrthographic * positionWC * show;\n\n    v_st.s = texCoord;\n    v_st.t = czm_writeNonPerspective(clamp(expandDir, 0.0, 1.0), gl_Position.w);\n\n    v_width = width;\n    v_pickColor = pickColor;\n    v_polylineAngle = polylineAngle;\n}\n"},81802:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\n\nvarying vec2 v_textureCoordinates;\n\n#ifdef AUTO_EXPOSURE\nuniform sampler2D autoExposure;\n#endif\n\nvoid main()\n{\n    vec4 fragmentColor = texture2D(colorTexture, v_textureCoordinates);\n    vec3 color = fragmentColor.rgb;\n\n#ifdef AUTO_EXPOSURE\n    color /= texture2D(autoExposure, vec2(0.5)).r;\n#endif\n    color = czm_acesTonemapping(color);\n    color = czm_inverseGamma(color);\n\n    gl_FragColor = vec4(color, fragmentColor.a);\n}\n"},23832:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\nuniform sampler2D colorTexture2;\n\nuniform vec2 center;\nuniform float radius;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    vec4 color0 = texture2D(colorTexture, v_textureCoordinates);\n    vec4 color1 = texture2D(colorTexture2, v_textureCoordinates);\n\n    float x = length(gl_FragCoord.xy - center) / radius;\n    float t = smoothstep(0.5, 0.8, x);\n    gl_FragColor = mix(color0 + color1, color1, t);\n}\n"},73519:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D randomTexture;\nuniform sampler2D depthTexture;\nuniform float intensity;\nuniform float bias;\nuniform float lengthCap;\nuniform float stepSize;\nuniform float frustumLength;\n\nvarying vec2 v_textureCoordinates;\n\nvec4 clipToEye(vec2 uv, float depth)\n{\n    vec2 xy = vec2((uv.x * 2.0 - 1.0), ((1.0 - uv.y) * 2.0 - 1.0));\n    vec4 posEC = czm_inverseProjection * vec4(xy, depth, 1.0);\n    posEC = posEC / posEC.w;\n    return posEC;\n}\n\n//Reconstruct Normal Without Edge Removation\nvec3 getNormalXEdge(vec3 posInCamera, float depthU, float depthD, float depthL, float depthR, vec2 pixelSize)\n{\n    vec4 posInCameraUp = clipToEye(v_textureCoordinates - vec2(0.0, pixelSize.y), depthU);\n    vec4 posInCameraDown = clipToEye(v_textureCoordinates + vec2(0.0, pixelSize.y), depthD);\n    vec4 posInCameraLeft = clipToEye(v_textureCoordinates - vec2(pixelSize.x, 0.0), depthL);\n    vec4 posInCameraRight = clipToEye(v_textureCoordinates + vec2(pixelSize.x, 0.0), depthR);\n\n    vec3 up = posInCamera.xyz - posInCameraUp.xyz;\n    vec3 down = posInCameraDown.xyz - posInCamera.xyz;\n    vec3 left = posInCamera.xyz - posInCameraLeft.xyz;\n    vec3 right = posInCameraRight.xyz - posInCamera.xyz;\n\n    vec3 DX = length(left) < length(right) ? left : right;\n    vec3 DY = length(up) < length(down) ? up : down;\n\n    return normalize(cross(DY, DX));\n}\n\nvoid main(void)\n{\n    float depth = czm_readDepth(depthTexture, v_textureCoordinates);\n    vec4 posInCamera = clipToEye(v_textureCoordinates, depth);\n\n    if (posInCamera.z > frustumLength)\n    {\n        gl_FragColor = vec4(1.0);\n        return;\n    }\n\n    vec2 pixelSize = czm_pixelRatio / czm_viewport.zw;\n    float depthU = czm_readDepth(depthTexture, v_textureCoordinates - vec2(0.0, pixelSize.y));\n    float depthD = czm_readDepth(depthTexture, v_textureCoordinates + vec2(0.0, pixelSize.y));\n    float depthL = czm_readDepth(depthTexture, v_textureCoordinates - vec2(pixelSize.x, 0.0));\n    float depthR = czm_readDepth(depthTexture, v_textureCoordinates + vec2(pixelSize.x, 0.0));\n    vec3 normalInCamera = getNormalXEdge(posInCamera.xyz, depthU, depthD, depthL, depthR, pixelSize);\n\n    float ao = 0.0;\n    vec2 sampleDirection = vec2(1.0, 0.0);\n    float gapAngle = 90.0 * czm_radiansPerDegree;\n\n    // RandomNoise\n    float randomVal = texture2D(randomTexture, v_textureCoordinates).x;\n\n    //Loop for each direction\n    for (int i = 0; i < 4; i++)\n    {\n        float newGapAngle = gapAngle * (float(i) + randomVal);\n        float cosVal = cos(newGapAngle);\n        float sinVal = sin(newGapAngle);\n\n        //Rotate Sampling Direction\n        vec2 rotatedSampleDirection = vec2(cosVal * sampleDirection.x - sinVal * sampleDirection.y, sinVal * sampleDirection.x + cosVal * sampleDirection.y);\n        float localAO = 0.0;\n        float localStepSize = stepSize;\n\n        //Loop for each step\n        for (int j = 0; j < 6; j++)\n        {\n            vec2 newCoords = v_textureCoordinates + rotatedSampleDirection * localStepSize * pixelSize;\n\n            //Exception Handling\n            if(newCoords.x > 1.0 || newCoords.y > 1.0 || newCoords.x < 0.0 || newCoords.y < 0.0)\n            {\n                break;\n            }\n\n            float stepDepthInfo = czm_readDepth(depthTexture, newCoords);\n            vec4 stepPosInCamera = clipToEye(newCoords, stepDepthInfo);\n            vec3 diffVec = stepPosInCamera.xyz - posInCamera.xyz;\n            float len = length(diffVec);\n\n            if (len > lengthCap)\n            {\n                break;\n            }\n\n            float dotVal = clamp(dot(normalInCamera, normalize(diffVec)), 0.0, 1.0 );\n            float weight = len / lengthCap;\n            weight = 1.0 - weight * weight;\n\n            if (dotVal < bias)\n            {\n                dotVal = 0.0;\n            }\n\n            localAO = max(localAO, dotVal * weight);\n            localStepSize += stepSize;\n        }\n        ao += localAO;\n    }\n\n    ao /= 4.0;\n    ao = 1.0 - clamp(ao, 0.0, 1.0);\n    ao = pow(ao, intensity);\n    gl_FragColor = vec4(vec3(ao), 1.0);\n}\n"},16836:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\nuniform sampler2D ambientOcclusionTexture;\nuniform bool ambientOcclusionOnly;\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    vec3 color = texture2D(colorTexture, v_textureCoordinates).rgb;\n    vec3 ao = texture2D(ambientOcclusionTexture, v_textureCoordinates).rgb;\n    gl_FragColor.rgb = ambientOcclusionOnly ? ao : ao * color;\n}\n"},91882:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\nuniform float gradations;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    vec3 rgb = texture2D(colorTexture, v_textureCoordinates).rgb;\n#ifdef CZM_SELECTED_FEATURE\n    if (czm_selected()) {\n        gl_FragColor = vec4(rgb, 1.0);\n        return;\n    }\n#endif\n    float luminance = czm_luminance(rgb);\n    float darkness = luminance * gradations;\n    darkness = (darkness - fract(darkness)) / gradations;\n    gl_FragColor = vec4(vec3(darkness), 1.0);\n}\n"},86311:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\nuniform sampler2D bloomTexture;\nuniform bool glowOnly;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    vec4 color = texture2D(colorTexture, v_textureCoordinates);\n\n#ifdef CZM_SELECTED_FEATURE\n    if (czm_selected()) {\n        gl_FragColor = color;\n        return;\n    }\n#endif\n\n    vec4 bloom = texture2D(bloomTexture, v_textureCoordinates);\n    gl_FragColor = glowOnly ? bloom : bloom + color;\n}\n"},1694:(e,n,t)=>{t.d(n,{Z:()=>o});const o='uniform sampler2D colorTexture;\n\nuniform float avgLuminance;\nuniform float threshold;\nuniform float offset;\n\nvarying vec2 v_textureCoordinates;\n\nfloat key(float avg)\n{\n    float guess = 1.5 - (1.5 / (avg * 0.1 + 1.0));\n    return max(0.0, guess) + 0.1;\n}\n\n// See section 9. "The bright-pass filter" of Realtime HDR Rendering\n// http://www.cg.tuwien.ac.at/research/publications/2007/Luksch_2007_RHR/Luksch_2007_RHR-RealtimeHDR%20.pdf\n\nvoid main()\n{\n    vec4 color = texture2D(colorTexture, v_textureCoordinates);\n    vec3 xyz = czm_RGBToXYZ(color.rgb);\n    float luminance = xyz.r;\n\n    float scaledLum = key(avgLuminance) * luminance / avgLuminance;\n    float brightLum = max(scaledLum - threshold, 0.0);\n    float brightness = brightLum / (offset + brightLum);\n\n    xyz.r = brightness;\n    gl_FragColor = vec4(czm_XYZToRGB(xyz), 1.0);\n}\n'},61609:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\nuniform float brightness;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    vec3 rgb = texture2D(colorTexture, v_textureCoordinates).rgb;\n    vec3 target = vec3(0.0);\n    gl_FragColor = vec4(mix(target, rgb, brightness), 1.0);\n}\n"},73655:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\n\n#ifdef DEBUG_SHOW_DEPTH\nuniform sampler2D u_packedTranslucentDepth;\n#endif\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n#ifdef DEBUG_SHOW_DEPTH\n    if (v_textureCoordinates.x < 0.5)\n    {\n        gl_FragColor.rgb = vec3(czm_unpackDepth(texture2D(u_packedTranslucentDepth, v_textureCoordinates)));\n        gl_FragColor.a = 1.0;\n    }\n#else\n    vec4 color = texture2D(colorTexture, v_textureCoordinates);\n\n#ifdef PICK\n    if (color == vec4(0.0))\n    {\n        discard;\n    }\n#else\n    // Reverse premultiplication process to get the correct composited result of the classification primitives\n    color.rgb /= color.a;\n#endif\n    gl_FragColor = color;\n#endif\n}\n"},48461:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\nuniform float contrast;\nuniform float brightness;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    vec3 sceneColor = texture2D(colorTexture, v_textureCoordinates).xyz;\n    sceneColor = czm_RGBToHSB(sceneColor);\n    sceneColor.z += brightness;\n    sceneColor = czm_HSBToRGB(sceneColor);\n\n    float factor = (259.0 * (contrast + 255.0)) / (255.0 * (259.0 - contrast));\n    sceneColor = factor * (sceneColor - vec3(0.5)) + vec3(0.5);\n    gl_FragColor = vec4(sceneColor, 1.0);\n}\n"},31751:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\nuniform sampler2D blurTexture;\nuniform sampler2D depthTexture;\nuniform float focalDistance;\n\nvarying vec2 v_textureCoordinates;\n\nvec4 toEye(vec2 uv, float depth)\n{\n   vec2 xy = vec2((uv.x * 2.0 - 1.0), ((1.0 - uv.y) * 2.0 - 1.0));\n   vec4 posInCamera = czm_inverseProjection * vec4(xy, depth, 1.0);\n   posInCamera = posInCamera / posInCamera.w;\n   return posInCamera;\n}\n\nfloat computeDepthBlur(float depth)\n{\n    float f;\n    if (depth < focalDistance)\n    {\n        f = (focalDistance - depth) / (focalDistance - czm_currentFrustum.x);\n    }\n    else\n    {\n        f = (depth - focalDistance) / (czm_currentFrustum.y - focalDistance);\n        f = pow(f, 0.1);\n    }\n    f *= f;\n    f = clamp(f, 0.0, 1.0);\n    return pow(f, 0.5);\n}\n\nvoid main(void)\n{\n    float depth = czm_readDepth(depthTexture, v_textureCoordinates);\n    vec4 posInCamera = toEye(v_textureCoordinates, depth);\n    float d = computeDepthBlur(-posInCamera.z);\n    gl_FragColor = mix(texture2D(colorTexture, v_textureCoordinates), texture2D(blurTexture, v_textureCoordinates), d);\n}\n"},9957:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D depthTexture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    float depth = czm_readDepth(depthTexture, v_textureCoordinates);\n    gl_FragColor = vec4(vec3(depth), 1.0);\n}\n"},46410:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D u_depthTexture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    float z_window = czm_unpackDepth(texture2D(u_depthTexture, v_textureCoordinates));\n    z_window = czm_reverseLogDepth(z_window);\n    float n_range = czm_depthRange.near;\n    float f_range = czm_depthRange.far;\n    float z_ndc = (2.0 * z_window - n_range - f_range) / (f_range - n_range);\n    float scale = pow(z_ndc * 0.5 + 0.5, 8.0);\n    gl_FragColor = vec4(mix(vec3(0.0), vec3(1.0), scale), 1.0);\n}\n"},63832:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D depthTexture;\nuniform float length;\nuniform vec4 color;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    float directions[3];\n    directions[0] = -1.0;\n    directions[1] = 0.0;\n    directions[2] = 1.0;\n\n    float scalars[3];\n    scalars[0] = 3.0;\n    scalars[1] = 10.0;\n    scalars[2] = 3.0;\n\n    float padx = czm_pixelRatio / czm_viewport.z;\n    float pady = czm_pixelRatio / czm_viewport.w;\n\n#ifdef CZM_SELECTED_FEATURE\n    bool selected = false;\n    for (int i = 0; i < 3; ++i)\n    {\n        float dir = directions[i];\n        selected = selected || czm_selected(vec2(-padx, dir * pady));\n        selected = selected || czm_selected(vec2(padx, dir * pady));\n        selected = selected || czm_selected(vec2(dir * padx, -pady));\n        selected = selected || czm_selected(vec2(dir * padx, pady));\n        if (selected)\n        {\n            break;\n        }\n    }\n    if (!selected)\n    {\n        gl_FragColor = vec4(color.rgb, 0.0);\n        return;\n    }\n#endif\n\n    float horizEdge = 0.0;\n    float vertEdge = 0.0;\n\n    for (int i = 0; i < 3; ++i)\n    {\n        float dir = directions[i];\n        float scale = scalars[i];\n\n        horizEdge -= texture2D(depthTexture, v_textureCoordinates + vec2(-padx, dir * pady)).x * scale;\n        horizEdge += texture2D(depthTexture, v_textureCoordinates + vec2(padx, dir * pady)).x * scale;\n\n        vertEdge -= texture2D(depthTexture, v_textureCoordinates + vec2(dir * padx, -pady)).x * scale;\n        vertEdge += texture2D(depthTexture, v_textureCoordinates + vec2(dir * padx, pady)).x * scale;\n    }\n\n    float len = sqrt(horizEdge * horizEdge + vertEdge * vertEdge);\n    gl_FragColor = vec4(color.rgb, len > length ? color.a : 0.0);\n}\n"},93709:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec2 v_textureCoordinates;\n\nuniform sampler2D colorTexture;\n\nconst float fxaaQualitySubpix = 0.5;\nconst float fxaaQualityEdgeThreshold = 0.125;\nconst float fxaaQualityEdgeThresholdMin = 0.0833;\n\nvoid main()\n{\n    vec2 fxaaQualityRcpFrame = vec2(1.0) / czm_viewport.zw;\n    vec4 color = FxaaPixelShader(\n        v_textureCoordinates,\n        colorTexture,\n        fxaaQualityRcpFrame,\n        fxaaQualitySubpix,\n        fxaaQualityEdgeThreshold,\n        fxaaQualityEdgeThresholdMin);\n    float alpha = texture2D(colorTexture, v_textureCoordinates).a;\n    gl_FragColor = vec4(color.rgb, alpha);\n}\n"},92046:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\n\nvarying vec2 v_textureCoordinates;\n\n#ifdef AUTO_EXPOSURE\nuniform sampler2D autoExposure;\n#endif\n\n// See slides 142 and 143:\n//     http://www.gdcvault.com/play/1012459/Uncharted_2__HDR_Lighting\n\nvoid main()\n{\n    vec4 fragmentColor = texture2D(colorTexture, v_textureCoordinates);\n    vec3 color = fragmentColor.rgb;\n\n#ifdef AUTO_EXPOSURE\n    float exposure = texture2D(autoExposure, vec2(0.5)).r;\n    color /= exposure;\n#endif\n\n\tconst float A = 0.22; // shoulder strength\n\tconst float B = 0.30; // linear strength\n\tconst float C = 0.10; // linear angle\n\tconst float D = 0.20; // toe strength\n\tconst float E = 0.01; // toe numerator\n\tconst float F = 0.30; // toe denominator\n\n\tconst float white = 11.2; // linear white point value\n\n\tvec3 c = ((color * (A * color + C * B) + D * E) / (color * ( A * color + B) + D * F)) - E / F;\n\tfloat w = ((white * (A * white + C * B) + D * E) / (white * ( A * white + B) + D * F)) - E / F;\n\n\tc = czm_inverseGamma(c / w);\n\tgl_FragColor = vec4(c, fragmentColor.a);\n}\n"},9812:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#define SAMPLES 8\n\nuniform float delta;\nuniform float sigma;\nuniform float direction; // 0.0 for x direction, 1.0 for y direction\n\nuniform sampler2D colorTexture;\n\n#ifdef USE_STEP_SIZE\nuniform float stepSize;\n#else\nuniform vec2 step;\n#endif\n\nvarying vec2 v_textureCoordinates;\n\n//  Incremental Computation of the Gaussian:\n//  https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch40.html\n\nvoid main()\n{\n    vec2 st = v_textureCoordinates;\n    vec2 dir = vec2(1.0 - direction, direction);\n\n#ifdef USE_STEP_SIZE\n    vec2 step = vec2(stepSize * (czm_pixelRatio / czm_viewport.zw));\n#else\n    vec2 step = step;\n#endif\n\n    vec3 g;\n    g.x = 1.0 / (sqrt(czm_twoPi) * sigma);\n    g.y = exp((-0.5 * delta * delta) / (sigma * sigma));\n    g.z = g.y * g.y;\n\n    vec4 result = texture2D(colorTexture, st) * g.x;\n    for (int i = 1; i < SAMPLES; ++i)\n    {\n        g.xy *= g.yz;\n\n        vec2 offset = float(i) * dir * step;\n        result += texture2D(colorTexture, st - offset) * g.x;\n        result += texture2D(colorTexture, st + offset) * g.x;\n    }\n\n    gl_FragColor = result;\n}\n"},39979:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\nuniform sampler2D dirtTexture;\nuniform sampler2D starTexture;\nuniform vec2 dirtTextureDimensions;\nuniform float distortion;\nuniform float ghostDispersal;\nuniform float haloWidth;\nuniform float dirtAmount;\nuniform float earthRadius;\nuniform float intensity;\n\nvarying vec2 v_textureCoordinates;\n\n// whether it is in space or not\n// 6500000.0 is empirical value\n#define DISTANCE_TO_SPACE 6500000.0\n\n// return ndc from world coordinate biased earthRadius\nvec4 getNDCFromWC(vec3 WC, float earthRadius)\n{\n    vec4 positionEC = czm_view * vec4(WC, 1.0);\n    positionEC = vec4(positionEC.x + earthRadius, positionEC.y, positionEC.z, 1.0);\n    vec4 positionWC = czm_eyeToWindowCoordinates(positionEC);\n    return czm_viewportOrthographic * vec4(positionWC.xy, -positionWC.z, 1.0);\n}\n\n// Check if current pixel is included Earth\n// if then mask it gradually\nfloat isInEarth(vec2 texcoord, vec2 sceneSize)\n{\n    vec2 NDC = texcoord * 2.0 - 1.0;\n    vec4 earthPosSC = getNDCFromWC(vec3(0.0), 0.0);\n    vec4 earthPosSCEdge = getNDCFromWC(vec3(0.0), earthRadius * 1.5);\n    NDC.xy -= earthPosSC.xy;\n\n    float X = abs(NDC.x) * sceneSize.x;\n    float Y = abs(NDC.y) * sceneSize.y;\n\n    return clamp(0.0, 1.0, max(sqrt(X * X + Y * Y) / max(abs(earthPosSCEdge.x * sceneSize.x), 1.0) - 0.8 , 0.0));\n}\n\n// For Chromatic effect\nvec4 textureDistorted(sampler2D tex, vec2 texcoord, vec2 direction, vec3 distortion, bool isSpace)\n{\n    vec2 sceneSize = czm_viewport.zw;\n    vec3 color;\n    if(isSpace)\n    {\n        color.r = isInEarth(texcoord + direction * distortion.r, sceneSize) * texture2D(tex, texcoord + direction * distortion.r).r;\n        color.g = isInEarth(texcoord + direction * distortion.g, sceneSize) * texture2D(tex, texcoord + direction * distortion.g).g;\n        color.b = isInEarth(texcoord + direction * distortion.b, sceneSize) * texture2D(tex, texcoord + direction * distortion.b).b;\n    }\n    else\n    {\n        color.r = texture2D(tex, texcoord + direction * distortion.r).r;\n        color.g = texture2D(tex, texcoord + direction * distortion.g).g;\n        color.b = texture2D(tex, texcoord + direction * distortion.b).b;\n    }\n    return vec4(clamp(color, 0.0, 1.0), 0.0);\n}\n\nvoid main(void)\n{\n    vec4 originalColor = texture2D(colorTexture, v_textureCoordinates);\n    vec3 rgb = originalColor.rgb;\n    bool isSpace = length(czm_viewerPositionWC.xyz) > DISTANCE_TO_SPACE;\n\n    // Sun position\n    vec4 sunPos = czm_morphTime == 1.0 ? vec4(czm_sunPositionWC, 1.0) : vec4(czm_sunPositionColumbusView.zxy, 1.0);\n    vec4 sunPositionEC = czm_view * sunPos;\n    vec4 sunPositionWC = czm_eyeToWindowCoordinates(sunPositionEC);\n    sunPos = czm_viewportOrthographic * vec4(sunPositionWC.xy, -sunPositionWC.z, 1.0);\n\n    // If sun is not in the screen space, use original color.\n    if(!isSpace || !((sunPos.x >= -1.1 && sunPos.x <= 1.1) && (sunPos.y >= -1.1 && sunPos.y <= 1.1)))\n    {\n        // Lens flare is disabled when not in space until #5932 is fixed.\n        //    https://github.com/CesiumGS/cesium/issues/5932\n        gl_FragColor = originalColor;\n        return;\n    }\n\n    vec2 texcoord = vec2(1.0) - v_textureCoordinates;\n    vec2 pixelSize = czm_pixelRatio / czm_viewport.zw;\n    vec2 invPixelSize = 1.0 / pixelSize;\n    vec3 distortionVec = pixelSize.x * vec3(-distortion, 0.0, distortion);\n\n    // ghost vector to image centre:\n    vec2 ghostVec = (vec2(0.5) - texcoord) * ghostDispersal;\n    vec3 direction = normalize(vec3(ghostVec, 0.0));\n\n    // sample ghosts:\n    vec4 result = vec4(0.0);\n    vec4 ghost = vec4(0.0);\n    for (int i = 0; i < 4; ++i)\n    {\n        vec2 offset = fract(texcoord + ghostVec * float(i));\n        // Only bright spots from the centre of the source image\n        ghost += textureDistorted(colorTexture, offset, direction.xy, distortionVec, isSpace);\n    }\n    result += ghost;\n\n    // sample halo\n    vec2 haloVec = normalize(ghostVec) * haloWidth;\n    float weightForHalo = length(vec2(0.5) - fract(texcoord + haloVec)) / length(vec2(0.5));\n    weightForHalo = pow(1.0 - weightForHalo, 5.0);\n\n    result += textureDistorted(colorTexture, texcoord + haloVec, direction.xy, distortionVec, isSpace) * weightForHalo * 1.5;\n\n    // dirt on lens\n    vec2 dirtTexCoords = (v_textureCoordinates * invPixelSize) / dirtTextureDimensions;\n    if (dirtTexCoords.x > 1.0)\n    {\n        dirtTexCoords.x = mod(floor(dirtTexCoords.x), 2.0) == 1.0 ? 1.0 - fract(dirtTexCoords.x) :  fract(dirtTexCoords.x);\n    }\n    if (dirtTexCoords.y > 1.0)\n    {\n        dirtTexCoords.y = mod(floor(dirtTexCoords.y), 2.0) == 1.0 ? 1.0 - fract(dirtTexCoords.y) :  fract(dirtTexCoords.y);\n    }\n    result += dirtAmount * texture2D(dirtTexture, dirtTexCoords);\n\n    // Rotating starburst texture's coordinate\n    // dot(czm_view[0].xyz, vec3(0.0, 0.0, 1.0)) + dot(czm_view[1].xyz, vec3(0.0, 1.0, 0.0))\n    float camrot = czm_view[0].z + czm_view[1].y;\n    float cosValue = cos(camrot);\n    float sinValue = sin(camrot);\n    mat3 rotation = mat3(\n        cosValue, -sinValue, 0.0,\n        sinValue, cosValue, 0.0,\n        0.0, 0.0, 1.0\n    );\n\n    vec3 st1 = vec3(v_textureCoordinates * 2.0 - vec2(1.0), 1.0);\n    vec3 st2 = vec3((rotation * st1).xy, 1.0);\n    vec3 st3 = st2 * 0.5 + vec3(0.5);\n    vec2 lensStarTexcoord = st3.xy;\n    float weightForLensFlare = length(vec3(sunPos.xy, 0.0));\n    float oneMinusWeightForLensFlare = max(1.0 - weightForLensFlare, 0.0);\n\n    if (!isSpace)\n    {\n        result *= oneMinusWeightForLensFlare * intensity * 0.2;\n    }\n    else\n    {\n        result *= oneMinusWeightForLensFlare * intensity;\n        result *= texture2D(starTexture, lensStarTexcoord) * pow(weightForLensFlare, 1.0) * max((1.0 - length(vec3(st1.xy, 0.0))), 0.0) * 2.0;\n    }\n\n    result += texture2D(colorTexture, v_textureCoordinates);\n\n    gl_FragColor = result;\n}\n"},32914:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\nuniform vec3 white;\n\nvarying vec2 v_textureCoordinates;\n\n#ifdef AUTO_EXPOSURE\nuniform sampler2D autoExposure;\n#endif\n\n// See equation 4:\n//    http://www.cs.utah.edu/~reinhard/cdrom/tonemap.pdf\n\nvoid main()\n{\n    vec4 fragmentColor = texture2D(colorTexture, v_textureCoordinates);\n    vec3 color = fragmentColor.rgb;\n#ifdef AUTO_EXPOSURE\n    float exposure = texture2D(autoExposure, vec2(0.5)).r;\n    color /= exposure;\n#endif\n    color = (color * (1.0 + color / white)) / (1.0 + color);\n    color = czm_inverseGamma(color);\n    gl_FragColor = vec4(color, fragmentColor.a);\n}\n"},56695:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\n\nvarying vec2 v_textureCoordinates;\n\nfloat rand(vec2 co)\n{\n    return fract(sin(dot(co.xy ,vec2(12.9898, 78.233))) * 43758.5453);\n}\n\nvoid main(void)\n{\n    float noiseValue = rand(v_textureCoordinates + sin(czm_frameNumber)) * 0.1;\n    vec3 rgb = texture2D(colorTexture, v_textureCoordinates).rgb;\n    vec3 green = vec3(0.0, 1.0, 0.0);\n    gl_FragColor = vec4((noiseValue + rgb) * green, 1.0);\n}\n"},2312:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    gl_FragColor = texture2D(colorTexture, v_textureCoordinates);\n}\n"},96084:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform highp sampler2D u_depthTexture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    gl_FragColor = czm_packDepth(texture2D(u_depthTexture, v_textureCoordinates).r);\n}\n"},56967:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#extension GL_EXT_frag_depth : enable\n\nuniform sampler2D u_pointCloud_colorGBuffer;\nuniform sampler2D u_pointCloud_depthGBuffer;\nuniform vec2 u_distanceAndEdlStrength;\nvarying vec2 v_textureCoordinates;\n\nvec2 neighborContribution(float log2Depth, vec2 offset)\n{\n    float dist = u_distanceAndEdlStrength.x;\n    vec2 texCoordOrig = v_textureCoordinates + offset * dist;\n    vec2 texCoord0 = v_textureCoordinates + offset * floor(dist);\n    vec2 texCoord1 = v_textureCoordinates + offset * ceil(dist);\n\n    float depthOrLogDepth0 = czm_unpackDepth(texture2D(u_pointCloud_depthGBuffer, texCoord0));\n    float depthOrLogDepth1 = czm_unpackDepth(texture2D(u_pointCloud_depthGBuffer, texCoord1));\n\n    // ignore depth values that are the clear depth\n    if (depthOrLogDepth0 == 0.0 || depthOrLogDepth1 == 0.0) {\n        return vec2(0.0);\n    }\n\n    // interpolate the two adjacent depth values\n    float depthMix = mix(depthOrLogDepth0, depthOrLogDepth1, fract(dist));\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(texCoordOrig, depthMix);\n    return vec2(max(0.0, log2Depth - log2(-eyeCoordinate.z / eyeCoordinate.w)), 1.0);\n}\n\nvoid main()\n{\n    float depthOrLogDepth = czm_unpackDepth(texture2D(u_pointCloud_depthGBuffer, v_textureCoordinates));\n\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(gl_FragCoord.xy, depthOrLogDepth);\n    eyeCoordinate /= eyeCoordinate.w;\n\n    float log2Depth = log2(-eyeCoordinate.z);\n\n    if (depthOrLogDepth == 0.0) // 0.0 is the clear value for the gbuffer\n    {\n        discard;\n    }\n\n    vec4 color = texture2D(u_pointCloud_colorGBuffer, v_textureCoordinates);\n\n    // sample from neighbors left, right, down, up\n    vec2 texelSize = 1.0 / czm_viewport.zw;\n\n    vec2 responseAndCount = vec2(0.0);\n\n    responseAndCount += neighborContribution(log2Depth, vec2(-texelSize.x, 0.0));\n    responseAndCount += neighborContribution(log2Depth, vec2(+texelSize.x, 0.0));\n    responseAndCount += neighborContribution(log2Depth, vec2(0.0, -texelSize.y));\n    responseAndCount += neighborContribution(log2Depth, vec2(0.0, +texelSize.y));\n\n    float response = responseAndCount.x / responseAndCount.y;\n    float strength = u_distanceAndEdlStrength.y;\n    float shade = exp(-response * 300.0 * strength);\n    color.rgb *= shade;\n    gl_FragColor = vec4(color);\n\n    // Input and output depth are the same.\n    gl_FragDepthEXT = depthOrLogDepth;\n}\n"},13597:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\n\nvarying vec2 v_textureCoordinates;\n\n#ifdef AUTO_EXPOSURE\nuniform sampler2D autoExposure;\n#endif\n\n// See equation 3:\n//    http://www.cs.utah.edu/~reinhard/cdrom/tonemap.pdf\n\nvoid main()\n{\n    vec4 fragmentColor = texture2D(colorTexture, v_textureCoordinates);\n    vec3 color = fragmentColor.rgb;\n#ifdef AUTO_EXPOSURE\n    float exposure = texture2D(autoExposure, vec2(0.5)).r;\n    color /= exposure;\n#endif\n    color = color / (1.0 + color);\n    color = czm_inverseGamma(color);\n    gl_FragColor = vec4(color, fragmentColor.a);\n}\n"},63042:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D colorTexture;\nuniform sampler2D silhouetteTexture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main(void)\n{\n    vec4 silhouetteColor = texture2D(silhouetteTexture, v_textureCoordinates);\n    vec4 color = texture2D(colorTexture, v_textureCoordinates);\n    gl_FragColor = mix(color, silhouetteColor, silhouetteColor.a);\n}\n"},42781:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D u_texture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    gl_FragColor = texture2D(u_texture, v_textureCoordinates);\n}\n"},16380:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec4 position;\nattribute float webMercatorT;\n\nuniform vec2 u_textureDimensions;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    v_textureCoordinates = vec2(position.x, webMercatorT);\n    gl_Position = czm_viewportOrthographic * (position * vec4(u_textureDimensions, 1.0, 1.0));\n}\n"},20519:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef GL_EXT_frag_depth\n#extension GL_EXT_frag_depth : enable\n#endif\n\n#ifdef TEXTURE_COORDINATES\n#ifdef SPHERICAL\nvarying vec4 v_sphericalExtents;\n#else // SPHERICAL\nvarying vec2 v_inversePlaneExtents;\nvarying vec4 v_westPlane;\nvarying vec4 v_southPlane;\n#endif // SPHERICAL\nvarying vec3 v_uvMinAndSphericalLongitudeRotation;\nvarying vec3 v_uMaxAndInverseDistance;\nvarying vec3 v_vMaxAndInverseDistance;\n#endif // TEXTURE_COORDINATES\n\n#ifdef PER_INSTANCE_COLOR\nvarying vec4 v_color;\n#endif\n\n#ifdef NORMAL_EC\nvec3 getEyeCoordinate3FromWindowCoordinate(vec2 fragCoord, float logDepthOrDepth) {\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(fragCoord, logDepthOrDepth);\n    return eyeCoordinate.xyz / eyeCoordinate.w;\n}\n\nvec3 vectorFromOffset(vec4 eyeCoordinate, vec2 positiveOffset) {\n    vec2 glFragCoordXY = gl_FragCoord.xy;\n    // Sample depths at both offset and negative offset\n    float upOrRightLogDepth = czm_unpackDepth(texture2D(czm_globeDepthTexture, (glFragCoordXY + positiveOffset) / czm_viewport.zw));\n    float downOrLeftLogDepth = czm_unpackDepth(texture2D(czm_globeDepthTexture, (glFragCoordXY - positiveOffset) / czm_viewport.zw));\n    // Explicitly evaluate both paths\n    // Necessary for multifrustum and for edges of the screen\n    bvec2 upOrRightInBounds = lessThan(glFragCoordXY + positiveOffset, czm_viewport.zw);\n    float useUpOrRight = float(upOrRightLogDepth > 0.0 && upOrRightInBounds.x && upOrRightInBounds.y);\n    float useDownOrLeft = float(useUpOrRight == 0.0);\n    vec3 upOrRightEC = getEyeCoordinate3FromWindowCoordinate(glFragCoordXY + positiveOffset, upOrRightLogDepth);\n    vec3 downOrLeftEC = getEyeCoordinate3FromWindowCoordinate(glFragCoordXY - positiveOffset, downOrLeftLogDepth);\n    return (upOrRightEC - (eyeCoordinate.xyz / eyeCoordinate.w)) * useUpOrRight + ((eyeCoordinate.xyz / eyeCoordinate.w) - downOrLeftEC) * useDownOrLeft;\n}\n#endif // NORMAL_EC\n\nvoid main(void)\n{\n#ifdef REQUIRES_EC\n    float logDepthOrDepth = czm_unpackDepth(texture2D(czm_globeDepthTexture, gl_FragCoord.xy / czm_viewport.zw));\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(gl_FragCoord.xy, logDepthOrDepth);\n#endif\n\n#ifdef REQUIRES_WC\n    vec4 worldCoordinate4 = czm_inverseView * eyeCoordinate;\n    vec3 worldCoordinate = worldCoordinate4.xyz / worldCoordinate4.w;\n#endif\n\n#ifdef TEXTURE_COORDINATES\n    vec2 uv;\n#ifdef SPHERICAL\n    // Treat world coords as a sphere normal for spherical coordinates\n    vec2 sphericalLatLong = czm_approximateSphericalCoordinates(worldCoordinate);\n    sphericalLatLong.y += v_uvMinAndSphericalLongitudeRotation.z;\n    sphericalLatLong.y = czm_branchFreeTernary(sphericalLatLong.y < czm_pi, sphericalLatLong.y, sphericalLatLong.y - czm_twoPi);\n    uv.x = (sphericalLatLong.y - v_sphericalExtents.y) * v_sphericalExtents.w;\n    uv.y = (sphericalLatLong.x - v_sphericalExtents.x) * v_sphericalExtents.z;\n#else // SPHERICAL\n    // Unpack planes and transform to eye space\n    uv.x = czm_planeDistance(v_westPlane, eyeCoordinate.xyz / eyeCoordinate.w) * v_inversePlaneExtents.x;\n    uv.y = czm_planeDistance(v_southPlane, eyeCoordinate.xyz / eyeCoordinate.w) * v_inversePlaneExtents.y;\n#endif // SPHERICAL\n#endif // TEXTURE_COORDINATES\n\n#ifdef PICK\n#ifdef CULL_FRAGMENTS\n    // When classifying translucent geometry, logDepthOrDepth == 0.0\n    // indicates a region that should not be classified, possibly due to there\n    // being opaque pixels there in another buffer.\n    // Check for logDepthOrDepth != 0.0 to make sure this should be classified.\n    if (0.0 <= uv.x && uv.x <= 1.0 && 0.0 <= uv.y && uv.y <= 1.0 || logDepthOrDepth != 0.0) {\n        gl_FragColor.a = 1.0; // 0.0 alpha leads to discard from ShaderSource.createPickFragmentShaderSource\n        czm_writeDepthClamp();\n    }\n#else // CULL_FRAGMENTS\n        gl_FragColor.a = 1.0;\n#endif // CULL_FRAGMENTS\n#else // PICK\n\n#ifdef CULL_FRAGMENTS\n    // When classifying translucent geometry, logDepthOrDepth == 0.0\n    // indicates a region that should not be classified, possibly due to there\n    // being opaque pixels there in another buffer.\n    if (uv.x <= 0.0 || 1.0 <= uv.x || uv.y <= 0.0 || 1.0 <= uv.y || logDepthOrDepth == 0.0) {\n        discard;\n    }\n#endif\n\n#ifdef NORMAL_EC\n    // Compute normal by sampling adjacent pixels in 2x2 block in screen space\n    vec3 downUp = vectorFromOffset(eyeCoordinate, vec2(0.0, 1.0));\n    vec3 leftRight = vectorFromOffset(eyeCoordinate, vec2(1.0, 0.0));\n    vec3 normalEC = normalize(cross(leftRight, downUp));\n#endif\n\n\n#ifdef PER_INSTANCE_COLOR\n\n    vec4 color = czm_gammaCorrect(v_color);\n#ifdef FLAT\n    gl_FragColor = color;\n#else // FLAT\n    czm_materialInput materialInput;\n    materialInput.normalEC = normalEC;\n    materialInput.positionToEyeEC = -eyeCoordinate.xyz;\n    czm_material material = czm_getDefaultMaterial(materialInput);\n    material.diffuse = color.rgb;\n    material.alpha = color.a;\n\n    gl_FragColor = czm_phong(normalize(-eyeCoordinate.xyz), material, czm_lightDirectionEC);\n#endif // FLAT\n\n    // Premultiply alpha. Required for classification primitives on translucent globe.\n    gl_FragColor.rgb *= gl_FragColor.a;\n\n#else // PER_INSTANCE_COLOR\n\n    // Material support.\n    // USES_ is distinct from REQUIRES_, because some things are dependencies of each other or\n    // dependencies for culling but might not actually be used by the material.\n\n    czm_materialInput materialInput;\n\n#ifdef USES_NORMAL_EC\n    materialInput.normalEC = normalEC;\n#endif\n\n#ifdef USES_POSITION_TO_EYE_EC\n    materialInput.positionToEyeEC = -eyeCoordinate.xyz;\n#endif\n\n#ifdef USES_TANGENT_TO_EYE\n    materialInput.tangentToEyeMatrix = czm_eastNorthUpToEyeCoordinates(worldCoordinate, normalEC);\n#endif\n\n#ifdef USES_ST\n    // Remap texture coordinates from computed (approximately aligned with cartographic space) to the desired\n    // texture coordinate system, which typically forms a tight oriented bounding box around the geometry.\n    // Shader is provided a set of reference points for remapping.\n    materialInput.st.x = czm_lineDistance(v_uvMinAndSphericalLongitudeRotation.xy, v_uMaxAndInverseDistance.xy, uv) * v_uMaxAndInverseDistance.z;\n    materialInput.st.y = czm_lineDistance(v_uvMinAndSphericalLongitudeRotation.xy, v_vMaxAndInverseDistance.xy, uv) * v_vMaxAndInverseDistance.z;\n#endif\n\n    czm_material material = czm_getMaterial(materialInput);\n\n#ifdef FLAT\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n#else // FLAT\n    gl_FragColor = czm_phong(normalize(-eyeCoordinate.xyz), material, czm_lightDirectionEC);\n#endif // FLAT\n\n    // Premultiply alpha. Required for classification primitives on translucent globe.\n    gl_FragColor.rgb *= gl_FragColor.a;\n\n#endif // PER_INSTANCE_COLOR\n    czm_writeDepthClamp();\n#endif // PICK\n}\n"},90421:(e,n,t)=>{t.d(n,{Z:()=>o});const o='attribute vec3 position3DHigh;\nattribute vec3 position3DLow;\nattribute float batchId;\n\n#ifdef EXTRUDED_GEOMETRY\nattribute vec3 extrudeDirection;\n\nuniform float u_globeMinimumAltitude;\n#endif // EXTRUDED_GEOMETRY\n\n#ifdef PER_INSTANCE_COLOR\nvarying vec4 v_color;\n#endif // PER_INSTANCE_COLOR\n\n#ifdef TEXTURE_COORDINATES\n#ifdef SPHERICAL\nvarying vec4 v_sphericalExtents;\n#else // SPHERICAL\nvarying vec2 v_inversePlaneExtents;\nvarying vec4 v_westPlane;\nvarying vec4 v_southPlane;\n#endif // SPHERICAL\nvarying vec3 v_uvMinAndSphericalLongitudeRotation;\nvarying vec3 v_uMaxAndInverseDistance;\nvarying vec3 v_vMaxAndInverseDistance;\n#endif // TEXTURE_COORDINATES\n\nvoid main()\n{\n    vec4 position = czm_computePosition();\n\n#ifdef EXTRUDED_GEOMETRY\n    float delta = min(u_globeMinimumAltitude, czm_geometricToleranceOverMeter * length(position.xyz));\n    delta *= czm_sceneMode == czm_sceneMode3D ? 1.0 : 0.0;\n\n    //extrudeDirection is zero for the top layer\n    position = position + vec4(extrudeDirection * delta, 0.0);\n#endif\n\n#ifdef TEXTURE_COORDINATES\n#ifdef SPHERICAL\n    v_sphericalExtents = czm_batchTable_sphericalExtents(batchId);\n    v_uvMinAndSphericalLongitudeRotation.z = czm_batchTable_longitudeRotation(batchId);\n#else // SPHERICAL\n#ifdef COLUMBUS_VIEW_2D\n    vec4 planes2D_high = czm_batchTable_planes2D_HIGH(batchId);\n    vec4 planes2D_low = czm_batchTable_planes2D_LOW(batchId);\n\n    // If the primitive is split across the IDL (planes2D_high.x > planes2D_high.w):\n    // - If this vertex is on the east side of the IDL (position3DLow.y > 0.0, comparison with position3DHigh may produce artifacts)\n    // - existing "east" is on the wrong side of the world, far away (planes2D_high/low.w)\n    // - so set "east" as beyond the eastmost extent of the projection (idlSplitNewPlaneHiLow)\n    vec2 idlSplitNewPlaneHiLow = vec2(EAST_MOST_X_HIGH - (WEST_MOST_X_HIGH - planes2D_high.w), EAST_MOST_X_LOW - (WEST_MOST_X_LOW - planes2D_low.w));\n    bool idlSplit = planes2D_high.x > planes2D_high.w && position3DLow.y > 0.0;\n    planes2D_high.w = czm_branchFreeTernary(idlSplit, idlSplitNewPlaneHiLow.x, planes2D_high.w);\n    planes2D_low.w = czm_branchFreeTernary(idlSplit, idlSplitNewPlaneHiLow.y, planes2D_low.w);\n\n    // - else, if this vertex is on the west side of the IDL (position3DLow.y < 0.0)\n    // - existing "west" is on the wrong side of the world, far away (planes2D_high/low.x)\n    // - so set "west" as beyond the westmost extent of the projection (idlSplitNewPlaneHiLow)\n    idlSplit = planes2D_high.x > planes2D_high.w && position3DLow.y < 0.0;\n    idlSplitNewPlaneHiLow = vec2(WEST_MOST_X_HIGH - (EAST_MOST_X_HIGH - planes2D_high.x), WEST_MOST_X_LOW - (EAST_MOST_X_LOW - planes2D_low.x));\n    planes2D_high.x = czm_branchFreeTernary(idlSplit, idlSplitNewPlaneHiLow.x, planes2D_high.x);\n    planes2D_low.x = czm_branchFreeTernary(idlSplit, idlSplitNewPlaneHiLow.y, planes2D_low.x);\n\n    vec3 southWestCorner = (czm_modelViewRelativeToEye * czm_translateRelativeToEye(vec3(0.0, planes2D_high.xy), vec3(0.0, planes2D_low.xy))).xyz;\n    vec3 northWestCorner = (czm_modelViewRelativeToEye * czm_translateRelativeToEye(vec3(0.0, planes2D_high.x, planes2D_high.z), vec3(0.0, planes2D_low.x, planes2D_low.z))).xyz;\n    vec3 southEastCorner = (czm_modelViewRelativeToEye * czm_translateRelativeToEye(vec3(0.0, planes2D_high.w, planes2D_high.y), vec3(0.0, planes2D_low.w, planes2D_low.y))).xyz;\n#else // COLUMBUS_VIEW_2D\n    // 3D case has smaller "plane extents," so planes encoded as a 64 bit position and 2 vec3s for distances/direction\n    vec3 southWestCorner = (czm_modelViewRelativeToEye * czm_translateRelativeToEye(czm_batchTable_southWest_HIGH(batchId), czm_batchTable_southWest_LOW(batchId))).xyz;\n    vec3 northWestCorner = czm_normal * czm_batchTable_northward(batchId) + southWestCorner;\n    vec3 southEastCorner = czm_normal * czm_batchTable_eastward(batchId) + southWestCorner;\n#endif // COLUMBUS_VIEW_2D\n\n    vec3 eastWard = southEastCorner - southWestCorner;\n    float eastExtent = length(eastWard);\n    eastWard /= eastExtent;\n\n    vec3 northWard = northWestCorner - southWestCorner;\n    float northExtent = length(northWard);\n    northWard /= northExtent;\n\n    v_westPlane = vec4(eastWard, -dot(eastWard, southWestCorner));\n    v_southPlane = vec4(northWard, -dot(northWard, southWestCorner));\n    v_inversePlaneExtents = vec2(1.0 / eastExtent, 1.0 / northExtent);\n#endif // SPHERICAL\n    vec4 uvMinAndExtents = czm_batchTable_uvMinAndExtents(batchId);\n    vec4 uMaxVmax = czm_batchTable_uMaxVmax(batchId);\n\n    v_uMaxAndInverseDistance = vec3(uMaxVmax.xy, uvMinAndExtents.z);\n    v_vMaxAndInverseDistance = vec3(uMaxVmax.zw, uvMinAndExtents.w);\n    v_uvMinAndSphericalLongitudeRotation.xy = uvMinAndExtents.xy;\n#endif // TEXTURE_COORDINATES\n\n#ifdef PER_INSTANCE_COLOR\n    v_color = czm_batchTable_color(batchId);\n#endif\n\n    gl_Position = czm_depthClamp(czm_modelViewProjectionRelativeToEye * position);\n}\n'},67277:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef GL_EXT_frag_depth\n#extension GL_EXT_frag_depth : enable\n#endif\n\n#ifdef VECTOR_TILE\nuniform vec4 u_highlightColor;\n#endif\n\nvoid main(void)\n{\n#ifdef VECTOR_TILE\n    gl_FragColor = czm_gammaCorrect(u_highlightColor);\n#else\n    gl_FragColor = vec4(1.0);\n#endif\n    czm_writeDepthClamp();\n}\n"},97409:(e,n,t)=>{t.d(n,{Z:()=>o});const o="float interpolateByDistance(vec4 nearFarScalar, float distance)\n{\n    float startDistance = nearFarScalar.x;\n    float startValue = nearFarScalar.y;\n    float endDistance = nearFarScalar.z;\n    float endValue = nearFarScalar.w;\n    float t = clamp((distance - startDistance) / (endDistance - startDistance), 0.0, 1.0);\n    return mix(startValue, endValue, t);\n}\n\nvec3 getLightDirection(vec3 positionWC)\n{\n    float lightEnum = u_radiiAndDynamicAtmosphereColor.z;\n    vec3 lightDirection =\n        positionWC * float(lightEnum == 0.0) +\n        czm_lightDirectionWC * float(lightEnum == 1.0) +\n        czm_sunDirectionWC * float(lightEnum == 2.0);\n    return normalize(lightDirection);\n}\n\nvoid computeAtmosphereScattering(vec3 positionWC, vec3 lightDirection, out vec3 rayleighColor, out vec3 mieColor, out float opacity, out float underTranslucentGlobe)\n{\n    float ellipsoidRadiiDifference = czm_ellipsoidRadii.x - czm_ellipsoidRadii.z;\n\n    // Adjustment to the atmosphere radius applied based on the camera height.\n    float distanceAdjustMin = czm_ellipsoidRadii.x / 4.0;\n    float distanceAdjustMax = czm_ellipsoidRadii.x;\n    float distanceAdjustModifier = ellipsoidRadiiDifference / 2.0;\n    float distanceAdjust = distanceAdjustModifier * clamp((czm_eyeHeight - distanceAdjustMin) / (distanceAdjustMax - distanceAdjustMin), 0.0, 1.0);\n\n    // Since atmosphere scattering assumes the atmosphere is a spherical shell, we compute an inner radius of the atmosphere best fit \n    // for the position on the ellipsoid.\n    float radiusAdjust = (ellipsoidRadiiDifference / 4.0) + distanceAdjust;\n    float atmosphereInnerRadius = (length(czm_viewerPositionWC) - czm_eyeHeight) - radiusAdjust;\n\n    // Setup the primary ray: from the camera position to the vertex position.\n    vec3 cameraToPositionWC = positionWC - czm_viewerPositionWC;\n    vec3 cameraToPositionWCDirection = normalize(cameraToPositionWC);\n    czm_ray primaryRay = czm_ray(czm_viewerPositionWC, cameraToPositionWCDirection);\n\n    underTranslucentGlobe = 0.0;\n\n    // Brighten the sky atmosphere under the Earth's atmosphere when translucency is enabled.\n    #if defined(GLOBE_TRANSLUCENT)\n\n        // Check for intersection with the inner radius of the atmopshere.\n        czm_raySegment primaryRayEarthIntersect = czm_raySphereIntersectionInterval(primaryRay, vec3(0.0), atmosphereInnerRadius + radiusAdjust);\n        if (primaryRayEarthIntersect.start > 0.0 && primaryRayEarthIntersect.stop > 0.0) {\n            \n            // Compute position on globe.\n            vec3 direction = normalize(positionWC);\n            czm_ray ellipsoidRay = czm_ray(positionWC, -direction);\n            czm_raySegment ellipsoidIntersection = czm_rayEllipsoidIntersectionInterval(ellipsoidRay, vec3(0.0), czm_ellipsoidInverseRadii);\n            vec3 onEarth = positionWC - (direction * ellipsoidIntersection.start);\n\n            // Control the color using the camera angle.\n            float angle = dot(normalize(czm_viewerPositionWC), normalize(onEarth));\n\n            // Control the opacity using the distance from Earth.\n            opacity = interpolateByDistance(vec4(0.0, 1.0, czm_ellipsoidRadii.x, 0.0), length(czm_viewerPositionWC - onEarth));\n            vec3 horizonColor = vec3(0.1, 0.2, 0.3);\n            vec3 nearColor = vec3(0.0);\n\n            rayleighColor = mix(nearColor, horizonColor, exp(-angle) * opacity);\n            \n            // Set the traslucent flag to avoid alpha adjustment in computeFinalColor funciton.\n            underTranslucentGlobe = 1.0;\n            return;\n        }\n    #endif\n\n    computeScattering(\n        primaryRay,\n        length(cameraToPositionWC),\n        lightDirection,\n        atmosphereInnerRadius,\n        rayleighColor,\n        mieColor,\n        opacity\n    );\n\n    // Alter the opacity based on how close the viewer is to the ground.\n    // (0.0 = At edge of atmosphere, 1.0 = On ground)\n    float cameraHeight = czm_eyeHeight + atmosphereInnerRadius;\n    float atmosphereOuterRadius = atmosphereInnerRadius + ATMOSPHERE_THICKNESS;\n    opacity = clamp((atmosphereOuterRadius - cameraHeight) / (atmosphereOuterRadius - atmosphereInnerRadius), 0.0, 1.0);\n\n    // Alter alpha based on time of day (0.0 = night , 1.0 = day)\n    float nightAlpha = (u_radiiAndDynamicAtmosphereColor.z != 0.0) ? clamp(dot(normalize(positionWC), lightDirection), 0.0, 1.0) : 1.0;\n    opacity *= pow(nightAlpha, 0.5);\n}\n"},57847:(e,n,t)=>{t.d(n,{Z:()=>o});const o="varying vec3 v_outerPositionWC;\n\nuniform vec3 u_hsbShift;\n\n#ifndef PER_FRAGMENT_ATMOSPHERE\nvarying vec3 v_mieColor;\nvarying vec3 v_rayleighColor;\nvarying float v_opacity;\nvarying float v_translucent;\n#endif\n\nvoid main (void)\n{\n    vec3 lightDirection = getLightDirection(v_outerPositionWC);\n   \n    vec3 mieColor;\n    vec3 rayleighColor;\n    float opacity;\n    float translucent;\n\n    #ifdef PER_FRAGMENT_ATMOSPHERE\n        computeAtmosphereScattering(\n            v_outerPositionWC,\n            lightDirection,\n            rayleighColor,\n            mieColor,\n            opacity,\n            translucent\n        );\n    #else\n        mieColor = v_mieColor;\n        rayleighColor = v_rayleighColor;\n        opacity = v_opacity;\n        translucent = v_translucent;\n    #endif\n\n    vec4 color = computeAtmosphereColor(v_outerPositionWC, lightDirection, rayleighColor, mieColor, opacity);\n\n    #ifndef HDR\n        color.rgb = czm_acesTonemapping(color.rgb);\n        color.rgb = czm_inverseGamma(color.rgb);\n    #endif\n\n    #ifdef COLOR_CORRECT\n        // Convert rgb color to hsb\n        vec3 hsb = czm_RGBToHSB(color.rgb);\n        // Perform hsb shift\n        hsb.x += u_hsbShift.x; // hue\n        hsb.y = clamp(hsb.y + u_hsbShift.y, 0.0, 1.0); // saturation\n        hsb.z = hsb.z > czm_epsilon7 ? hsb.z + u_hsbShift.z : 0.0; // brightness\n        // Convert shifted hsb back to rgb\n        color.rgb = czm_HSBToRGB(hsb);\n    #endif\n\n    // For the parts of the sky atmosphere that are not behind a translucent globe,\n    // we mix in the default opacity so that the sky atmosphere still appears at distance.\n    // This is needed because the opacity in the sky atmosphere is initially adjusted based\n    // on the camera height.\n    if (translucent == 0.0) {\n        color.a = mix(color.b, 1.0, color.a) * smoothstep(0.0, 1.0, czm_morphTime);\n    }\n\n    gl_FragColor = color;\n}\n"},97854:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec4 position;\n\nvarying vec3 v_outerPositionWC;\n\n#ifndef PER_FRAGMENT_ATMOSPHERE\nvarying vec3 v_mieColor;\nvarying vec3 v_rayleighColor;\nvarying float v_opacity;\nvarying float v_translucent;\n#endif\n\nvoid main(void)\n{\n    vec4 positionWC = czm_model * position;\n    vec3 lightDirection = getLightDirection(positionWC.xyz);\n\n    #ifndef PER_FRAGMENT_ATMOSPHERE\n        computeAtmosphereScattering(\n            positionWC.xyz,\n            lightDirection,\n            v_rayleighColor,\n            v_mieColor,\n            v_opacity,\n            v_translucent\n        );\n    #endif\n    \n    v_outerPositionWC = positionWC.xyz;\n    gl_Position = czm_modelViewProjection * position;\n}\n"},46047:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform samplerCube u_cubeMap;\n\nvarying vec3 v_texCoord;\n\nvoid main()\n{\n    vec4 color = textureCube(u_cubeMap, normalize(v_texCoord));\n    gl_FragColor = vec4(czm_gammaCorrect(color).rgb, czm_morphTime);\n}\n"},46014:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec3 position;\n\nvarying vec3 v_texCoord;\n\nvoid main()\n{\n    vec3 p = czm_viewRotation * (czm_temeToPseudoFixed * (czm_entireFrustum.y * position));\n    gl_Position = czm_projection * vec4(p, 1.0);\n    v_texCoord = position.xyz;\n}\n"},29799:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform sampler2D u_texture;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    vec4 color = texture2D(u_texture, v_textureCoordinates);\n    gl_FragColor = czm_gammaCorrect(color);\n}\n"},5058:(e,n,t)=>{t.d(n,{Z:()=>o});const o="uniform float u_radiusTS;\n\nvarying vec2 v_textureCoordinates;\n\nvec2 rotate(vec2 p, vec2 direction)\n{\n    return vec2(p.x * direction.x - p.y * direction.y, p.x * direction.y + p.y * direction.x);\n}\n\nvec4 addBurst(vec2 position, vec2 direction, float lengthScalar)\n{\n    vec2 rotatedPosition = rotate(position, direction) * vec2(25.0, 0.75);\n    float radius = length(rotatedPosition) * lengthScalar;\n    float burst = 1.0 - smoothstep(0.0, 0.55, radius);\n    return vec4(burst);\n}\n\nvoid main()\n{\n    float lengthScalar = 2.0 / sqrt(2.0);\n    vec2 position = v_textureCoordinates - vec2(0.5);\n    float radius = length(position) * lengthScalar;\n    float surface = step(radius, u_radiusTS);\n    vec4 color = vec4(vec2(1.0), surface + 0.2, surface);\n\n    float glow = 1.0 - smoothstep(0.0, 0.55, radius);\n    color.ba += mix(vec2(0.0), vec2(1.0), glow) * 0.75;\n\n    vec4 burst = vec4(0.0);\n\n    // The following loop has been manually unrolled for speed, to\n    // avoid sin() and cos().\n    //\n    //for (float i = 0.4; i < 3.2; i += 1.047) {\n    //    vec2 direction = vec2(sin(i), cos(i));\n    //    burst += 0.4 * addBurst(position, direction, lengthScalar);\n    //\n    //    direction = vec2(sin(i - 0.08), cos(i - 0.08));\n    //    burst += 0.3 * addBurst(position, direction, lengthScalar);\n    //}\n\n    burst += 0.4 * addBurst(position, vec2(0.38942,  0.92106), lengthScalar);  // angle == 0.4\n    burst += 0.4 * addBurst(position, vec2(0.99235,  0.12348), lengthScalar);  // angle == 0.4 + 1.047\n    burst += 0.4 * addBurst(position, vec2(0.60327, -0.79754), lengthScalar);  // angle == 0.4 + 1.047 * 2.0\n\n    burst += 0.3 * addBurst(position, vec2(0.31457,  0.94924), lengthScalar);  // angle == 0.4 - 0.08\n    burst += 0.3 * addBurst(position, vec2(0.97931,  0.20239), lengthScalar);  // angle == 0.4 + 1.047 - 0.08\n    burst += 0.3 * addBurst(position, vec2(0.66507, -0.74678), lengthScalar);  // angle == 0.4 + 1.047 * 2.0 - 0.08\n\n    // End of manual loop unrolling.\n\n    color += clamp(burst, vec4(0.0), vec4(1.0)) * 0.15;\n\n    gl_FragColor = clamp(color, vec4(0.0), vec4(1.0));\n}\n"},19219:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec2 direction;\n\nuniform float u_size;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main() \n{\n    vec4 position;\n    if (czm_morphTime == 1.0)\n    {\n        position = vec4(czm_sunPositionWC, 1.0);\n    }\n    else\n    {\n        position = vec4(czm_sunPositionColumbusView.zxy, 1.0);\n    }\n    \n    vec4 positionEC = czm_view * position;\n    vec4 positionWC = czm_eyeToWindowCoordinates(positionEC);\n    \n    vec2 halfSize = vec2(u_size * 0.5);\n    halfSize *= ((direction * 2.0) - 1.0);\n    \n    gl_Position = czm_viewportOrthographic * vec4(positionWC.xy + halfSize, -positionWC.z, 1.0);\n    \n    v_textureCoordinates = direction;\n}\n"},4491:(e,n,t)=>{t.d(n,{Z:()=>o});const o="#ifdef GL_EXT_frag_depth\n#extension GL_EXT_frag_depth : enable\n#endif\n\nvarying vec4 v_startPlaneEC;\nvarying vec4 v_endPlaneEC;\nvarying vec4 v_rightPlaneEC;\nvarying float v_halfWidth;\nvarying vec3 v_volumeUpEC;\n\nuniform vec4 u_highlightColor;\nvoid main()\n{\n    float logDepthOrDepth = czm_branchFreeTernary(czm_sceneMode == czm_sceneMode2D, gl_FragCoord.z, czm_unpackDepth(texture2D(czm_globeDepthTexture, gl_FragCoord.xy / czm_viewport.zw)));\n\n    // Discard for sky\n    if (logDepthOrDepth == 0.0) {\n#ifdef DEBUG_SHOW_VOLUME\n        gl_FragColor = vec4(0.0, 0.0, 1.0, 0.5);\n        return;\n#else // DEBUG_SHOW_VOLUME\n        discard;\n#endif // DEBUG_SHOW_VOLUME\n    }\n\n    vec4 eyeCoordinate = czm_windowToEyeCoordinates(gl_FragCoord.xy, logDepthOrDepth);\n    eyeCoordinate /= eyeCoordinate.w;\n\n    float halfMaxWidth = v_halfWidth * czm_metersPerPixel(eyeCoordinate);\n\n    // Expand halfMaxWidth if direction to camera is almost perpendicular with the volume's up direction\n    halfMaxWidth += halfMaxWidth * (1.0 - dot(-normalize(eyeCoordinate.xyz), v_volumeUpEC));\n\n    // Check distance of the eye coordinate against the right-facing plane\n    float widthwiseDistance = czm_planeDistance(v_rightPlaneEC, eyeCoordinate.xyz);\n\n    // Check eye coordinate against the mitering planes\n    float distanceFromStart = czm_planeDistance(v_startPlaneEC, eyeCoordinate.xyz);\n    float distanceFromEnd = czm_planeDistance(v_endPlaneEC, eyeCoordinate.xyz);\n\n    if (abs(widthwiseDistance) > halfMaxWidth || distanceFromStart < 0.0 || distanceFromEnd < 0.0) {\n#ifdef DEBUG_SHOW_VOLUME\n        gl_FragColor = vec4(logDepthOrDepth, 0.0, 0.0, 0.5);\n        return;\n#else // DEBUG_SHOW_VOLUME\n        discard;\n#endif // DEBUG_SHOW_VOLUME\n    }\n    gl_FragColor = u_highlightColor;\n\n    czm_writeDepthClamp();\n}\n"},21761:(e,n,t)=>{t.d(n,{Z:()=>o});const o='attribute vec3 startEllipsoidNormal;\nattribute vec3 endEllipsoidNormal;\nattribute vec4 startPositionAndHeight;\nattribute vec4 endPositionAndHeight;\nattribute vec4 startFaceNormalAndVertexCorner;\nattribute vec4 endFaceNormalAndHalfWidth;\nattribute float a_batchId;\n\nuniform mat4 u_modifiedModelView;\nuniform vec2 u_minimumMaximumVectorHeights;\n\nvarying vec4 v_startPlaneEC;\nvarying vec4 v_endPlaneEC;\nvarying vec4 v_rightPlaneEC;\nvarying float v_halfWidth;\nvarying vec3 v_volumeUpEC;\n\nvoid main()\n{\n    // vertex corner IDs\n    //          3-----------7\n    //         /|   left   /|\n    //        / | 1       / |\n    //       2-----------6  5  end\n    //       | /         | /\n    // start |/  right   |/\n    //       0-----------4\n    //\n    float isEnd = floor(startFaceNormalAndVertexCorner.w * 0.251); // 0 for front, 1 for end\n    float isTop = floor(startFaceNormalAndVertexCorner.w * mix(0.51, 0.19, isEnd)); // 0 for bottom, 1 for top\n\n    vec3 forward = endPositionAndHeight.xyz - startPositionAndHeight.xyz;\n    vec3 right = normalize(cross(forward, startEllipsoidNormal));\n\n    vec4 position = vec4(startPositionAndHeight.xyz, 1.0);\n    position.xyz += forward * isEnd;\n\n    v_volumeUpEC = czm_normal * normalize(cross(right, forward));\n\n    // Push for volume height\n    float offset;\n    vec3 ellipsoidNormal = mix(startEllipsoidNormal, endEllipsoidNormal, isEnd);\n\n    // offset height to create volume\n    offset = mix(startPositionAndHeight.w, endPositionAndHeight.w, isEnd);\n    offset = mix(u_minimumMaximumVectorHeights.y, u_minimumMaximumVectorHeights.x, isTop) - offset;\n    position.xyz += offset * ellipsoidNormal;\n\n    // move from RTC to EC\n    position = u_modifiedModelView * position;\n    right = czm_normal * right;\n\n    // Push for width in a direction that is in the start or end plane and in a plane with right\n    // N = normalEC ("right-facing" direction for push)\n    // R = right\n    // p = angle between N and R\n    // w = distance to push along R if R == N\n    // d = distance to push along N\n    //\n    //   N   R\n    //  {  p| }      * cos(p) = dot(N, R) = w / d\n    //  d  |  |w    * d = w / dot(N, R)\n    //    { | }\n    //       o---------- polyline segment ----\x3e\n    //\n    vec3 scratchNormal = mix(-startFaceNormalAndVertexCorner.xyz, endFaceNormalAndHalfWidth.xyz, isEnd);\n    scratchNormal = cross(scratchNormal, mix(startEllipsoidNormal, endEllipsoidNormal, isEnd));\n    vec3 miterPushNormal = czm_normal * normalize(scratchNormal);\n\n    offset = 2.0 * endFaceNormalAndHalfWidth.w * max(0.0, czm_metersPerPixel(position)); // offset = widthEC\n    offset = offset / dot(miterPushNormal, right);\n    position.xyz += miterPushNormal * (offset * sign(0.5 - mod(startFaceNormalAndVertexCorner.w, 2.0)));\n\n    gl_Position = czm_depthClamp(czm_projection * position);\n\n    position = u_modifiedModelView * vec4(startPositionAndHeight.xyz, 1.0);\n    vec3 startNormalEC = czm_normal * startFaceNormalAndVertexCorner.xyz;\n    v_startPlaneEC = vec4(startNormalEC, -dot(startNormalEC, position.xyz));\n    v_rightPlaneEC = vec4(right, -dot(right, position.xyz));\n\n    position = u_modifiedModelView * vec4(endPositionAndHeight.xyz, 1.0);\n    vec3 endNormalEC = czm_normal * endFaceNormalAndHalfWidth.xyz;\n    v_endPlaneEC = vec4(endNormalEC, -dot(endNormalEC, position.xyz));\n    v_halfWidth = endFaceNormalAndHalfWidth.w;\n}\n'},39755:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec4 currentPosition;\nattribute vec4 previousPosition;\nattribute vec4 nextPosition;\nattribute vec2 expandAndWidth;\nattribute float a_batchId;\n\nuniform mat4 u_modifiedModelView;\n\nvoid main()\n{\n    float expandDir = expandAndWidth.x;\n    float width = abs(expandAndWidth.y) + 0.5;\n    bool usePrev = expandAndWidth.y < 0.0;\n\n    vec4 p = u_modifiedModelView * currentPosition;\n    vec4 prev = u_modifiedModelView * previousPosition;\n    vec4 next = u_modifiedModelView * nextPosition;\n\n    float angle;\n    vec4 positionWC = getPolylineWindowCoordinatesEC(p, prev, next, expandDir, width, usePrev, angle);\n    gl_Position = czm_viewportOrthographic * positionWC;\n}\n"},21875:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec3 position;\nattribute float a_batchId;\n\nuniform mat4 u_modifiedModelViewProjection;\n\nvoid main()\n{\n    gl_Position = czm_depthClamp(u_modifiedModelViewProjection * vec4(position, 1.0));\n}\n"},53247:(e,n,t)=>{t.d(n,{Z:()=>o});const o="\nvarying vec2 v_textureCoordinates;\n\nvoid main()\n{\n    czm_materialInput materialInput;\n    \n    materialInput.s = v_textureCoordinates.s;\n    materialInput.st = v_textureCoordinates;\n    materialInput.str = vec3(v_textureCoordinates, 0.0);\n    materialInput.normalEC = vec3(0.0, 0.0, -1.0);\n    \n    czm_material material = czm_getMaterial(materialInput);\n\n    gl_FragColor = vec4(material.diffuse + material.emission, material.alpha);\n}\n"},42713:(e,n,t)=>{t.d(n,{Z:()=>o});const o="attribute vec4 position;\nattribute vec2 textureCoordinates;\n\nvarying vec2 v_textureCoordinates;\n\nvoid main() \n{\n    gl_Position = position;\n    v_textureCoordinates = textureCoordinates;\n}\n"}}]);